<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Proportions | An Introduction to Statistics</title>
  <meta name="description" content="Chapter 11 Proportions | An Introduction to Statistics" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Proportions | An Introduction to Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Proportions | An Introduction to Statistics" />
  
  
  

<meta name="author" content="Drs C. Paxton, L. Burt, C. Donovan and L. Scott-Hayward" />


<meta name="date" content="2021-10-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="power.html"/>
<link rel="next" href="tableofcounts.html"/>
<script src="book_assets/header-attrs-2.11/header-attrs.js"></script>
<script src="book_assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="book_assets/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="book_assets/anchor-sections-1.0.1/anchor-sections.js"></script>
<script language="javascript">
    function toggle(id) {
        var ele = document.getElementById("toggleText" + id);
        var text = document.getElementById("displayText" + id);
        var buttonText = text.innerHTML.replace("Show ", "");
        buttonText = buttonText.replace("Hide ", "");
        if(ele.style.display == "block") {
            ele.style.display = "none";
            text.innerHTML = "Show " + buttonText;
        } else {
            ele.style.display = "block";
            text.innerHTML = "Hide " + buttonText;
        }
    }
</script>

<script language="javascript">
    function openCode(evt, codeName, id) {
        var i, tabcontent, tablinks;
        tabcontent = document.getElementsByClassName("tabcontent" + id);
        for (i = 0; i < tabcontent.length; i++) {
            tabcontent[i].style.display = "none";
        }
        tablinks = document.getElementsByClassName("tablinks" + id);
        for (i = 0; i < tablinks.length; i++) {
            tablinks[i].className = tablinks[i].className.replace(" active", "");
        }
        document.getElementById(codeName).style.display = "block";
        evt.currentTarget.className += " active";
    }
</script>

<script language="javascript">
    function hide(id){
        document.getElementById(id).style.display = "none";
    }
</script>
</script>

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<a href="https://www.st-andrews.ac.uk/mathematics-statistics/"><img src="standard-vertical-black.png" width="180"></a>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#computer-practicals"><i class="fa fa-check"></i>Computer practicals</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introchapt.html"><a href="introchapt.html"><i class="fa fa-check"></i><b>1</b> Thinking About Numbers</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introchapt.html"><a href="introchapt.html#INTintro"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="introchapt.html"><a href="introchapt.html#why-use-statistics"><i class="fa fa-check"></i><b>1.2</b> Why use statistics?</a></li>
<li class="chapter" data-level="1.3" data-path="introchapt.html"><a href="introchapt.html#why-model"><i class="fa fa-check"></i><b>1.3</b> Why model?</a></li>
<li class="chapter" data-level="1.4" data-path="introchapt.html"><a href="introchapt.html#examples-of-statistical-claims"><i class="fa fa-check"></i><b>1.4</b> Examples of statistical claims</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introchapt.html"><a href="introchapt.html#coffee-may-reverse-alzheimers"><i class="fa fa-check"></i><b>1.4.1</b> Coffee ‘may reverse Alzheimer’s’</a></li>
<li class="chapter" data-level="1.4.2" data-path="introchapt.html"><a href="introchapt.html#abundance-of-prized-sturgeon"><i class="fa fa-check"></i><b>1.4.2</b> Abundance of prized sturgeon</a></li>
<li class="chapter" data-level="1.4.3" data-path="introchapt.html"><a href="introchapt.html#extrapolating-sprinting-speed"><i class="fa fa-check"></i><b>1.4.3</b> Extrapolating sprinting speed</a></li>
<li class="chapter" data-level="1.4.4" data-path="introchapt.html"><a href="introchapt.html#mmr-innoculation-and-autism"><i class="fa fa-check"></i><b>1.4.4</b> MMR innoculation and autism</a></li>
<li class="chapter" data-level="1.4.5" data-path="introchapt.html"><a href="introchapt.html#two-sid-deaths-in-same-family"><i class="fa fa-check"></i><b>1.4.5</b> Two SID deaths in same family</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introchapt.html"><a href="introchapt.html#SUMintro"><i class="fa fa-check"></i><b>1.5</b> Summary</a></li>
<li class="chapter" data-level="1.6" data-path="introchapt.html"><a href="introchapt.html#ANSintro"><i class="fa fa-check"></i><b>1.6</b> Answers</a></li>
</ul></li>
<li class="part"><span><b>I Data Collection and Visualisation</b></span></li>
<li class="chapter" data-level="2" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>2</b> Data collection and Sampling</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sampling.html"><a href="sampling.html#INTsamp"><i class="fa fa-check"></i><b>2.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="sampling.html"><a href="sampling.html#terminology"><i class="fa fa-check"></i><b>2.1.1</b> Terminology</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="sampling.html"><a href="sampling.html#what-is-sampling-and-why-do-it"><i class="fa fa-check"></i><b>2.2</b> What is sampling and why do it?</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="sampling.html"><a href="sampling.html#precision-accuracy-and-bias"><i class="fa fa-check"></i><b>2.2.1</b> Precision, accuracy and bias</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="sampling.html"><a href="sampling.html#three-types-of-data-collection"><i class="fa fa-check"></i><b>2.3</b> Three types of data collection</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="sampling.html"><a href="sampling.html#common-but-unwise-data-collection-strategies"><i class="fa fa-check"></i><b>2.3.1</b> Common, but unwise, data collection strategies</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="sampling.html"><a href="sampling.html#simple-sampling-approaches"><i class="fa fa-check"></i><b>2.4</b> Simple sampling approaches</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="sampling.html"><a href="sampling.html#simple-random-sample"><i class="fa fa-check"></i><b>2.4.1</b> Simple random sample</a></li>
<li class="chapter" data-level="2.4.2" data-path="sampling.html"><a href="sampling.html#systematic-samples"><i class="fa fa-check"></i><b>2.4.2</b> Systematic samples</a></li>
<li class="chapter" data-level="2.4.3" data-path="sampling.html"><a href="sampling.html#stratified-random-samples"><i class="fa fa-check"></i><b>2.4.3</b> Stratified random samples</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="sampling.html"><a href="sampling.html#sampling-biases"><i class="fa fa-check"></i><b>2.5</b> Sampling biases</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="sampling.html"><a href="sampling.html#non-sampling-error"><i class="fa fa-check"></i><b>2.5.1</b> Non-sampling error</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="sampling.html"><a href="sampling.html#experiments"><i class="fa fa-check"></i><b>2.6</b> Experiments</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="sampling.html"><a href="sampling.html#randomised-experiments"><i class="fa fa-check"></i><b>2.6.1</b> Randomised experiments</a></li>
<li class="chapter" data-level="2.6.2" data-path="sampling.html"><a href="sampling.html#components-of-an-experimental-design"><i class="fa fa-check"></i><b>2.6.2</b> Components of an experimental design</a></li>
<li class="chapter" data-level="2.6.3" data-path="sampling.html"><a href="sampling.html#controls"><i class="fa fa-check"></i><b>2.6.3</b> Controls</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="sampling.html"><a href="sampling.html#observational-studies"><i class="fa fa-check"></i><b>2.7</b> Observational Studies</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="sampling.html"><a href="sampling.html#types-of-observational-study"><i class="fa fa-check"></i><b>2.7.1</b> Types of observational study</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="sampling.html"><a href="sampling.html#observational-studies-vs-experiments"><i class="fa fa-check"></i><b>2.8</b> Observational studies vs experiments</a></li>
<li class="chapter" data-level="2.9" data-path="sampling.html"><a href="sampling.html#SUMsamp"><i class="fa fa-check"></i><b>2.9</b> Summary</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="sampling.html"><a href="sampling.html#learning-objectives"><i class="fa fa-check"></i><b>2.9.1</b> Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="sampling.html"><a href="sampling.html#ANSsamp"><i class="fa fa-check"></i><b>2.10</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="describedata.html"><a href="describedata.html"><i class="fa fa-check"></i><b>3</b> Describing data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="describedata.html"><a href="describedata.html#INTdata"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="describedata.html"><a href="describedata.html#types-of-data"><i class="fa fa-check"></i><b>3.2</b> Types of data</a></li>
<li class="chapter" data-level="3.3" data-path="describedata.html"><a href="describedata.html#frequency-distributions"><i class="fa fa-check"></i><b>3.3</b> Frequency distributions</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="describedata.html"><a href="describedata.html#doing-this-in-r-2"><i class="fa fa-check"></i><b>3.3.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="describedata.html"><a href="describedata.html#numerical-summaries"><i class="fa fa-check"></i><b>3.4</b> Numerical summaries</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="describedata.html"><a href="describedata.html#population-mean"><i class="fa fa-check"></i><b>3.4.1</b> Population mean</a></li>
<li class="chapter" data-level="3.4.2" data-path="describedata.html"><a href="describedata.html#sample-mean"><i class="fa fa-check"></i><b>3.4.2</b> Sample mean</a></li>
<li class="chapter" data-level="3.4.3" data-path="describedata.html"><a href="describedata.html#sample-median"><i class="fa fa-check"></i><b>3.4.3</b> Sample median</a></li>
<li class="chapter" data-level="3.4.4" data-path="describedata.html"><a href="describedata.html#range"><i class="fa fa-check"></i><b>3.4.4</b> Range</a></li>
<li class="chapter" data-level="3.4.5" data-path="describedata.html"><a href="describedata.html#percentiles"><i class="fa fa-check"></i><b>3.4.5</b> Percentiles</a></li>
<li class="chapter" data-level="3.4.6" data-path="describedata.html"><a href="describedata.html#population-variance"><i class="fa fa-check"></i><b>3.4.6</b> Population variance</a></li>
<li class="chapter" data-level="3.4.7" data-path="describedata.html"><a href="describedata.html#sample-variance-and-standard-deviation"><i class="fa fa-check"></i><b>3.4.7</b> Sample variance and standard deviation</a></li>
<li class="chapter" data-level="3.4.8" data-path="describedata.html"><a href="describedata.html#numerical-summaries-in-r"><i class="fa fa-check"></i><b>3.4.8</b> Numerical summaries in R</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="describedata.html"><a href="describedata.html#visual-summaries"><i class="fa fa-check"></i><b>3.5</b> Visual summaries</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="describedata.html"><a href="describedata.html#bar-charts"><i class="fa fa-check"></i><b>3.5.1</b> Bar charts</a></li>
<li class="chapter" data-level="3.5.2" data-path="describedata.html"><a href="describedata.html#pie-charts"><i class="fa fa-check"></i><b>3.5.2</b> Pie charts</a></li>
<li class="chapter" data-level="3.5.3" data-path="describedata.html"><a href="describedata.html#histograms"><i class="fa fa-check"></i><b>3.5.3</b> Histograms</a></li>
<li class="chapter" data-level="3.5.4" data-path="describedata.html"><a href="describedata.html#boxplots"><i class="fa fa-check"></i><b>3.5.4</b> Boxplots</a></li>
<li class="chapter" data-level="3.5.5" data-path="describedata.html"><a href="describedata.html#basic-plots-in-r"><i class="fa fa-check"></i><b>3.5.5</b> Basic plots in R</a></li>
<li class="chapter" data-level="3.5.6" data-path="describedata.html"><a href="describedata.html#other-plots"><i class="fa fa-check"></i><b>3.5.6</b> Other plots</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="describedata.html"><a href="describedata.html#summarising-the-relationship-between-two-variables"><i class="fa fa-check"></i><b>3.6</b> Summarising the relationship between two variables</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="describedata.html"><a href="describedata.html#cross-tabulation"><i class="fa fa-check"></i><b>3.6.1</b> Cross-tabulation</a></li>
<li class="chapter" data-level="3.6.2" data-path="describedata.html"><a href="describedata.html#side-by-side-boxplots"><i class="fa fa-check"></i><b>3.6.2</b> Side-by-side boxplots</a></li>
<li class="chapter" data-level="3.6.3" data-path="describedata.html"><a href="describedata.html#scatter-plot"><i class="fa fa-check"></i><b>3.6.3</b> Scatter plot</a></li>
<li class="chapter" data-level="3.6.4" data-path="describedata.html"><a href="describedata.html#quilt-plots"><i class="fa fa-check"></i><b>3.6.4</b> Quilt plots</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="describedata.html"><a href="describedata.html#handy-hints-when-including-tables-and-plots-into-reports"><i class="fa fa-check"></i><b>3.7</b> Handy hints when including tables and plots into reports</a></li>
<li class="chapter" data-level="3.8" data-path="describedata.html"><a href="describedata.html#SUMdata"><i class="fa fa-check"></i><b>3.8</b> Summary</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="describedata.html"><a href="describedata.html#learning-outcomes"><i class="fa fa-check"></i><b>3.8.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="describedata.html"><a href="describedata.html#ANSdata"><i class="fa fa-check"></i><b>3.9</b> Answers</a></li>
</ul></li>
<li class="part"><span><b>II Probability and Distributions</b></span></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html#INTprob"><i class="fa fa-check"></i><b>4.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="probability.html"><a href="probability.html#random-phenomena-and-uncertain-outcomes"><i class="fa fa-check"></i><b>4.1.1</b> Random phenomena and uncertain outcomes</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="probability.html"><a href="probability.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>4.2</b> Sample spaces and events</a></li>
<li class="chapter" data-level="4.3" data-path="probability.html"><a href="probability.html#definition-of-probability-and-3-axioms"><i class="fa fa-check"></i><b>4.3</b> Definition of Probability and 3 Axioms</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="probability.html"><a href="probability.html#probability-1"><i class="fa fa-check"></i><b>4.3.1</b> Probability</a></li>
<li class="chapter" data-level="4.3.2" data-path="probability.html"><a href="probability.html#three-axioms"><i class="fa fa-check"></i><b>4.3.2</b> Three Axioms</a></li>
<li class="chapter" data-level="4.3.3" data-path="probability.html"><a href="probability.html#three-results-of-the-axioms"><i class="fa fa-check"></i><b>4.3.3</b> Three results of the Axioms</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="probability.html"><a href="probability.html#independence-and-the-multiplication-rule"><i class="fa fa-check"></i><b>4.4</b> Independence and the Multiplication Rule</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="probability.html"><a href="probability.html#testing-for-independence"><i class="fa fa-check"></i><b>4.4.1</b> Testing for Independence</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="probability.html"><a href="probability.html#conditional-probabilities"><i class="fa fa-check"></i><b>4.5</b> Conditional probabilities</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="probability.html"><a href="probability.html#independence-revisited"><i class="fa fa-check"></i><b>4.5.1</b> Independence revisited</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="probability.html"><a href="probability.html#tree-diagrams"><i class="fa fa-check"></i><b>4.6</b> Tree Diagrams</a></li>
<li class="chapter" data-level="4.7" data-path="probability.html"><a href="probability.html#marginal-and-joint-probabilities"><i class="fa fa-check"></i><b>4.7</b> Marginal and joint probabilities</a></li>
<li class="chapter" data-level="4.8" data-path="probability.html"><a href="probability.html#SUMprob"><i class="fa fa-check"></i><b>4.8</b> Summary</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="probability.html"><a href="probability.html#learning-outcomes-1"><i class="fa fa-check"></i><b>4.8.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="probability.html"><a href="probability.html#ANSprob"><i class="fa fa-check"></i><b>4.9</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discreterv.html"><a href="discreterv.html"><i class="fa fa-check"></i><b>5</b> Discrete random variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discreterv.html"><a href="discreterv.html#INTdiscrv"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="discreterv.html"><a href="discreterv.html#discrete-random-variables"><i class="fa fa-check"></i><b>5.2</b> Discrete random variables</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="discreterv.html"><a href="discreterv.html#probability-mass-function"><i class="fa fa-check"></i><b>5.2.1</b> Probability mass function</a></li>
<li class="chapter" data-level="5.2.2" data-path="discreterv.html"><a href="discreterv.html#cumulative-distribution-function"><i class="fa fa-check"></i><b>5.2.2</b> Cumulative distribution function</a></li>
<li class="chapter" data-level="5.2.3" data-path="discreterv.html"><a href="discreterv.html#expectation"><i class="fa fa-check"></i><b>5.2.3</b> Expectation</a></li>
<li class="chapter" data-level="5.2.4" data-path="discreterv.html"><a href="discreterv.html#variance"><i class="fa fa-check"></i><b>5.2.4</b> Variance</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="discreterv.html"><a href="discreterv.html#special-discrete-distributions"><i class="fa fa-check"></i><b>5.3</b> Special discrete distributions</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="discreterv.html"><a href="discreterv.html#bernoulli-distribution"><i class="fa fa-check"></i><b>5.3.1</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="5.3.2" data-path="discreterv.html"><a href="discreterv.html#binomial-distribution"><i class="fa fa-check"></i><b>5.3.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="5.3.3" data-path="discreterv.html"><a href="discreterv.html#poisdist"><i class="fa fa-check"></i><b>5.3.3</b> Poisson distribution</a></li>
<li class="chapter" data-level="5.3.4" data-path="discreterv.html"><a href="discreterv.html#comparison-of-binomial-and-poisson-distributions"><i class="fa fa-check"></i><b>5.3.4</b> Comparison of binomial and Poisson distributions?</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="discreterv.html"><a href="discreterv.html#SUMdiscrv"><i class="fa fa-check"></i><b>5.4</b> Summary</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="discreterv.html"><a href="discreterv.html#learning-outcomes-2"><i class="fa fa-check"></i><b>5.4.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="discreterv.html"><a href="discreterv.html#ANSdiscrv"><i class="fa fa-check"></i><b>5.5</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="contrv.html"><a href="contrv.html"><i class="fa fa-check"></i><b>6</b> Continuous random variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="contrv.html"><a href="contrv.html#INTcontrv"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="contrv.html"><a href="contrv.html#continuous-random-variables"><i class="fa fa-check"></i><b>6.2</b> Continuous random variables</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="contrv.html"><a href="contrv.html#probability-density-function"><i class="fa fa-check"></i><b>6.2.1</b> Probability density function</a></li>
<li class="chapter" data-level="6.2.2" data-path="contrv.html"><a href="contrv.html#cumulative-distribution-function-1"><i class="fa fa-check"></i><b>6.2.2</b> Cumulative distribution function</a></li>
<li class="chapter" data-level="6.2.3" data-path="contrv.html"><a href="contrv.html#expectation-and-variance-1"><i class="fa fa-check"></i><b>6.2.3</b> Expectation and variance</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="contrv.html"><a href="contrv.html#special-continuous-distributions"><i class="fa fa-check"></i><b>6.3</b> Special continuous distributions</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="contrv.html"><a href="contrv.html#normal-distribution"><i class="fa fa-check"></i><b>6.3.1</b> normal distribution</a></li>
<li class="chapter" data-level="6.3.2" data-path="contrv.html"><a href="contrv.html#standard-normal-distribution"><i class="fa fa-check"></i><b>6.3.2</b> Standard normal distribution</a></li>
<li class="chapter" data-level="6.3.3" data-path="contrv.html"><a href="contrv.html#simple-transformations-of-random-variables"><i class="fa fa-check"></i><b>6.3.3</b> Simple transformations of random variables</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="contrv.html"><a href="contrv.html#SUMcontrv"><i class="fa fa-check"></i><b>6.4</b> Summary</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="contrv.html"><a href="contrv.html#learning-outcomes-3"><i class="fa fa-check"></i><b>6.4.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="contrv.html"><a href="contrv.html#ANScontrv"><i class="fa fa-check"></i><b>6.5</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="CIformean.html"><a href="CIformean.html"><i class="fa fa-check"></i><b>7</b> Confidence intervals for sample means</a>
<ul>
<li class="chapter" data-level="7.1" data-path="CIformean.html"><a href="CIformean.html#INTci"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="CIformean.html"><a href="CIformean.html#uncertainty-of-the-sample-mean"><i class="fa fa-check"></i><b>7.2</b> Uncertainty of the sample mean</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="CIformean.html"><a href="CIformean.html#precision-of-the-sample-mean"><i class="fa fa-check"></i><b>7.2.1</b> Precision of the sample mean</a></li>
<li class="chapter" data-level="7.2.2" data-path="CIformean.html"><a href="CIformean.html#confidence-interval-with-known-sigma"><i class="fa fa-check"></i><b>7.2.2</b> Confidence interval with known <span class="math inline">\(\sigma\)</span></a></li>
<li class="chapter" data-level="7.2.3" data-path="CIformean.html"><a href="CIformean.html#confidence-interval-with-unknown-sigma"><i class="fa fa-check"></i><b>7.2.3</b> Confidence interval with unknown <span class="math inline">\(\sigma\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="CIformean.html"><a href="CIformean.html#difference-between-two-group-means"><i class="fa fa-check"></i><b>7.3</b> Difference between two group means</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="CIformean.html"><a href="CIformean.html#assuming-equal-standard-deviations-of-the-two-groups"><i class="fa fa-check"></i><b>7.3.1</b> Assuming equal standard deviations of the two groups</a></li>
<li class="chapter" data-level="7.3.2" data-path="CIformean.html"><a href="CIformean.html#assuming-unequal-standard-deviations-of-the-two-groups"><i class="fa fa-check"></i><b>7.3.2</b> Assuming unequal standard deviations of the two groups</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="CIformean.html"><a href="CIformean.html#empirical-bootstrap-based-confidence-intervals"><i class="fa fa-check"></i><b>7.4</b> Empirical (bootstrap-based) confidence intervals</a></li>
<li class="chapter" data-level="7.5" data-path="CIformean.html"><a href="CIformean.html#confidence-intervals-for-other-sample-statistics"><i class="fa fa-check"></i><b>7.5</b> Confidence intervals for other sample statistics</a></li>
<li class="chapter" data-level="7.6" data-path="CIformean.html"><a href="CIformean.html#SUMci"><i class="fa fa-check"></i><b>7.6</b> Summary</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="CIformean.html"><a href="CIformean.html#learning-outcomes-4"><i class="fa fa-check"></i><b>7.6.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="CIformean.html"><a href="CIformean.html#ANSci"><i class="fa fa-check"></i><b>7.7</b> Answers</a></li>
</ul></li>
<li class="part"><span><b>III Hypothesis Testing</b></span></li>
<li class="chapter" data-level="8" data-path="hypothtests.html"><a href="hypothtests.html"><i class="fa fa-check"></i><b>8</b> Hypothesis Tests</a>
<ul>
<li class="chapter" data-level="8.1" data-path="hypothtests.html"><a href="hypothtests.html#INThyp"><i class="fa fa-check"></i><b>8.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="hypothtests.html"><a href="hypothtests.html#types-of-hypotheses"><i class="fa fa-check"></i><b>8.1.1</b> Types of hypotheses</a></li>
<li class="chapter" data-level="8.1.2" data-path="hypothtests.html"><a href="hypothtests.html#how-do-hypothesis-tests-work"><i class="fa fa-check"></i><b>8.1.2</b> How do hypothesis tests work?</a></li>
<li class="chapter" data-level="8.1.3" data-path="hypothtests.html"><a href="hypothtests.html#one-sample-t-test"><i class="fa fa-check"></i><b>8.1.3</b> One sample <span class="math inline">\(t\)</span> test</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="hypothtests.html"><a href="hypothtests.html#two-sample-t-test"><i class="fa fa-check"></i><b>8.2</b> Two sample <span class="math inline">\(t\)</span> test</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="hypothtests.html"><a href="hypothtests.html#doing-this-in-r-13"><i class="fa fa-check"></i><b>8.2.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="hypothtests.html"><a href="hypothtests.html#paired-t-test"><i class="fa fa-check"></i><b>8.3</b> Paired <span class="math inline">\(t\)</span> test</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="hypothtests.html"><a href="hypothtests.html#doing-this-in-r-14"><i class="fa fa-check"></i><b>8.3.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="hypothtests.html"><a href="hypothtests.html#t-test-assumptions"><i class="fa fa-check"></i><b>8.4</b> <span class="math inline">\(t\)</span> test assumptions</a></li>
<li class="chapter" data-level="8.5" data-path="hypothtests.html"><a href="hypothtests.html#non-parametric-alternative-to-t-tests"><i class="fa fa-check"></i><b>8.5</b> Non-parametric alternative to <span class="math inline">\(t\)</span> tests</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="hypothtests.html"><a href="hypothtests.html#mann-whitney-wilcoxon-test"><i class="fa fa-check"></i><b>8.5.1</b> Mann-Whitney-Wilcoxon test</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="hypothtests.html"><a href="hypothtests.html#practical-significance-versus-statistical-significance"><i class="fa fa-check"></i><b>8.6</b> Practical significance versus statistical significance</a></li>
<li class="chapter" data-level="8.7" data-path="hypothtests.html"><a href="hypothtests.html#SUMhyp"><i class="fa fa-check"></i><b>8.7</b> Summary</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="hypothtests.html"><a href="hypothtests.html#learning-outcomes-5"><i class="fa fa-check"></i><b>8.7.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="hypothtests.html"><a href="hypothtests.html#ANShyp"><i class="fa fa-check"></i><b>8.8</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>9</b> Analysis of Variance</a>
<ul>
<li class="chapter" data-level="9.1" data-path="anova.html"><a href="anova.html#INTanova"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="anova.html"><a href="anova.html#multiple-comparisons"><i class="fa fa-check"></i><b>9.2</b> Multiple comparisons</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="anova.html"><a href="anova.html#type-i-and-type-ii-error"><i class="fa fa-check"></i><b>9.2.1</b> Type I and Type II error</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="anova.html"><a href="anova.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>9.3</b> ANalysis Of VAriance (ANOVA)</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="anova.html"><a href="anova.html#f-test-statistic-for-anova"><i class="fa fa-check"></i><b>9.3.1</b> <span class="math inline">\(F\)</span> test statistic for ANOVA</a></li>
<li class="chapter" data-level="9.3.2" data-path="anova.html"><a href="anova.html#calculating-an-anova-table"><i class="fa fa-check"></i><b>9.3.2</b> Calculating an ANOVA table</a></li>
<li class="chapter" data-level="9.3.3" data-path="anova.html"><a href="anova.html#f-distribution"><i class="fa fa-check"></i><b>9.3.3</b> <span class="math inline">\(F\)</span> distribution</a></li>
<li class="chapter" data-level="9.3.4" data-path="anova.html"><a href="anova.html#doing-this-in-r-16"><i class="fa fa-check"></i><b>9.3.4</b> Doing this in R</a></li>
<li class="chapter" data-level="9.3.5" data-path="anova.html"><a href="anova.html#assumptions"><i class="fa fa-check"></i><b>9.3.5</b> Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="anova.html"><a href="anova.html#identifying-differences-and-more-on-multiple-comparisons"><i class="fa fa-check"></i><b>9.4</b> Identifying differences (and more on multiple comparisons)</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="anova.html"><a href="anova.html#bonferroni-correction"><i class="fa fa-check"></i><b>9.4.1</b> Bonferroni correction</a></li>
<li class="chapter" data-level="9.4.2" data-path="anova.html"><a href="anova.html#sidak-adjustment"><i class="fa fa-check"></i><b>9.4.2</b> Sidak adjustment</a></li>
<li class="chapter" data-level="9.4.3" data-path="anova.html"><a href="anova.html#tukeys-honest-significant-difference-hsd"><i class="fa fa-check"></i><b>9.4.3</b> Tukey’s Honest Significant Difference (HSD)</a></li>
<li class="chapter" data-level="9.4.4" data-path="anova.html"><a href="anova.html#multiple-comparison-controversy"><i class="fa fa-check"></i><b>9.4.4</b> Multiple comparison controversy</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="anova.html"><a href="anova.html#alternative-tests-to-anova"><i class="fa fa-check"></i><b>9.5</b> Alternative tests to ANOVA</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="anova.html"><a href="anova.html#doing-this-in-r-18"><i class="fa fa-check"></i><b>9.5.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="anova.html"><a href="anova.html#SUManova"><i class="fa fa-check"></i><b>9.6</b> Summary</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="anova.html"><a href="anova.html#learning-outcomes-6"><i class="fa fa-check"></i><b>9.6.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="anova.html"><a href="anova.html#ANSanova"><i class="fa fa-check"></i><b>9.7</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="power.html"><a href="power.html"><i class="fa fa-check"></i><b>10</b> Statistical Power</a>
<ul>
<li class="chapter" data-level="10.1" data-path="power.html"><a href="power.html#INTpower"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="power.html"><a href="power.html#a-motivating-example---environmental-impact-assessment"><i class="fa fa-check"></i><b>10.2</b> A motivating example - Environmental impact assessment</a></li>
<li class="chapter" data-level="10.3" data-path="power.html"><a href="power.html#calculating-power"><i class="fa fa-check"></i><b>10.3</b> Calculating power</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="power.html"><a href="power.html#increasing-the-power"><i class="fa fa-check"></i><b>10.3.1</b> Increasing the power</a></li>
<li class="chapter" data-level="10.3.2" data-path="power.html"><a href="power.html#power-by-simulation"><i class="fa fa-check"></i><b>10.3.2</b> Power by simulation</a></li>
<li class="chapter" data-level="10.3.3" data-path="power.html"><a href="power.html#multiple-comparisons-1"><i class="fa fa-check"></i><b>10.3.3</b> Multiple comparisons</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="power.html"><a href="power.html#SUMpower"><i class="fa fa-check"></i><b>10.4</b> Summary</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="power.html"><a href="power.html#learning-objectives-1"><i class="fa fa-check"></i><b>10.4.1</b> Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="power.html"><a href="power.html#ANSpower"><i class="fa fa-check"></i><b>10.5</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="proportions.html"><a href="proportions.html"><i class="fa fa-check"></i><b>11</b> Proportions</a>
<ul>
<li class="chapter" data-level="11.1" data-path="proportions.html"><a href="proportions.html#INTprop"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="proportions.html"><a href="proportions.html#confidence-intervals"><i class="fa fa-check"></i><b>11.2</b> Confidence intervals</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="proportions.html"><a href="proportions.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>11.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="11.2.2" data-path="proportions.html"><a href="proportions.html#confidence-intervals-large-sample-sizes"><i class="fa fa-check"></i><b>11.2.2</b> Confidence intervals: large sample sizes</a></li>
<li class="chapter" data-level="11.2.3" data-path="proportions.html"><a href="proportions.html#confidence-intervals-small-sample-sizes"><i class="fa fa-check"></i><b>11.2.3</b> Confidence intervals: small sample sizes</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="proportions.html"><a href="proportions.html#comparing-two-proportions-the-z-test"><i class="fa fa-check"></i><b>11.3</b> Comparing two proportions: the <span class="math inline">\(z\)</span> test</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="proportions.html"><a href="proportions.html#testing-for-no-difference-between-groups"><i class="fa fa-check"></i><b>11.3.1</b> Testing for ‘no difference’ between groups</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="proportions.html"><a href="proportions.html#ci-for-the-difference-between-population-proportions-p_1-p_2"><i class="fa fa-check"></i><b>11.4</b> CI for the difference between population proportions, (<span class="math inline">\(p_1-p_2\)</span>)</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="proportions.html"><a href="proportions.html#choosing-the-appropriate-standard-error-when-comparing-proportions"><i class="fa fa-check"></i><b>11.4.1</b> Choosing the appropriate standard error when comparing proportions</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="proportions.html"><a href="proportions.html#odds-ratios"><i class="fa fa-check"></i><b>11.5</b> Odds ratios</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="proportions.html"><a href="proportions.html#calculating-the-odds-of-success"><i class="fa fa-check"></i><b>11.5.1</b> Calculating the odds of success</a></li>
<li class="chapter" data-level="11.5.2" data-path="proportions.html"><a href="proportions.html#calculating-the-odds-of-success-for-2-x-2-tables"><i class="fa fa-check"></i><b>11.5.2</b> Calculating the odds of success for 2 x 2 tables</a></li>
<li class="chapter" data-level="11.5.3" data-path="proportions.html"><a href="proportions.html#calculating-the-odds-ratio"><i class="fa fa-check"></i><b>11.5.3</b> Calculating the odds ratio</a></li>
<li class="chapter" data-level="11.5.4" data-path="proportions.html"><a href="proportions.html#confidence-intervals-for-odds-ratios"><i class="fa fa-check"></i><b>11.5.4</b> Confidence intervals for odds ratios</a></li>
<li class="chapter" data-level="11.5.5" data-path="proportions.html"><a href="proportions.html#final-note-on-odds-ratios"><i class="fa fa-check"></i><b>11.5.5</b> Final note on odds ratios</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="proportions.html"><a href="proportions.html#SUMprop"><i class="fa fa-check"></i><b>11.6</b> Summary</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="proportions.html"><a href="proportions.html#learning-outcomes-7"><i class="fa fa-check"></i><b>11.6.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="proportions.html"><a href="proportions.html#ANSprop"><i class="fa fa-check"></i><b>11.7</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="tableofcounts.html"><a href="tableofcounts.html"><i class="fa fa-check"></i><b>12</b> Tables of counts</a>
<ul>
<li class="chapter" data-level="12.1" data-path="tableofcounts.html"><a href="tableofcounts.html#introduction"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="tableofcounts.html"><a href="tableofcounts.html#chi2-goodness-of-fit-test"><i class="fa fa-check"></i><b>12.2</b> <span class="math inline">\(\chi^2\)</span> goodness-of-fit test</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="tableofcounts.html"><a href="tableofcounts.html#doing-this-in-r-22"><i class="fa fa-check"></i><b>12.2.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="tableofcounts.html"><a href="tableofcounts.html#chi2-test-of-independence"><i class="fa fa-check"></i><b>12.3</b> <span class="math inline">\(\chi^2\)</span> test of independence</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="tableofcounts.html"><a href="tableofcounts.html#doing-this-in-r-23"><i class="fa fa-check"></i><b>12.3.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="tableofcounts.html"><a href="tableofcounts.html#test-assumptions"><i class="fa fa-check"></i><b>12.4</b> Test assumptions</a></li>
<li class="chapter" data-level="12.5" data-path="tableofcounts.html"><a href="tableofcounts.html#summary"><i class="fa fa-check"></i><b>12.5</b> Summary</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="tableofcounts.html"><a href="tableofcounts.html#learning-outcomes-8"><i class="fa fa-check"></i><b>12.5.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="tableofcounts.html"><a href="tableofcounts.html#answers"><i class="fa fa-check"></i><b>12.6</b> Answers</a></li>
</ul></li>
<li class="part"><span><b>IV Regression and Linear Models</b></span></li>
<li class="chapter" data-level="13" data-path="correg.html"><a href="correg.html"><i class="fa fa-check"></i><b>13</b> Correlation and Regression</a>
<ul>
<li class="chapter" data-level="13.1" data-path="correg.html"><a href="correg.html#introcorreg"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="correg.html"><a href="correg.html#correlation"><i class="fa fa-check"></i><b>13.2</b> Correlation</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="correg.html"><a href="correg.html#significance-of-r"><i class="fa fa-check"></i><b>13.2.1</b> Significance of <span class="math inline">\(r\)</span></a></li>
<li class="chapter" data-level="13.2.2" data-path="correg.html"><a href="correg.html#correlation-and-causation"><i class="fa fa-check"></i><b>13.2.2</b> Correlation and causation</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="correg.html"><a href="correg.html#regression"><i class="fa fa-check"></i><b>13.3</b> Regression</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="correg.html"><a href="correg.html#exploratory-data-analysis-1"><i class="fa fa-check"></i><b>13.3.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="13.3.2" data-path="correg.html"><a href="correg.html#model-specification"><i class="fa fa-check"></i><b>13.3.2</b> Model specification</a></li>
<li class="chapter" data-level="13.3.3" data-path="correg.html"><a href="correg.html#which-straight-line-to-choose"><i class="fa fa-check"></i><b>13.3.3</b> Which straight line to choose?</a></li>
<li class="chapter" data-level="13.3.4" data-path="correg.html"><a href="correg.html#fitting-the-model-the-details"><i class="fa fa-check"></i><b>13.3.4</b> Fitting the model: the details</a></li>
<li class="chapter" data-level="13.3.5" data-path="correg.html"><a href="correg.html#predictions"><i class="fa fa-check"></i><b>13.3.5</b> Predictions</a></li>
<li class="chapter" data-level="13.3.6" data-path="correg.html"><a href="correg.html#the-variance-estimate"><i class="fa fa-check"></i><b>13.3.6</b> The variance estimate</a></li>
<li class="chapter" data-level="13.3.7" data-path="correg.html"><a href="correg.html#introduction-to-the-matrix-form"><i class="fa fa-check"></i><b>13.3.7</b> Introduction to the matrix form</a></li>
<li class="chapter" data-level="13.3.8" data-path="correg.html"><a href="correg.html#regression-in-practise"><i class="fa fa-check"></i><b>13.3.8</b> Regression in practise</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="correg.html"><a href="correg.html#SUMcorreg"><i class="fa fa-check"></i><b>13.4</b> Summary</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="correg.html"><a href="correg.html#learning-outcomes-9"><i class="fa fa-check"></i><b>13.4.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="correg.html"><a href="correg.html#ANScorreg"><i class="fa fa-check"></i><b>13.5</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="introlm.html"><a href="introlm.html"><i class="fa fa-check"></i><b>14</b> Introduction to the linear model</a>
<ul>
<li class="chapter" data-level="14.1" data-path="introlm.html"><a href="introlm.html#INTlm"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="introlm.html"><a href="introlm.html#the-linear-model-as-a-t-test"><i class="fa fa-check"></i><b>14.2</b> The linear model as a <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="14.3" data-path="introlm.html"><a href="introlm.html#the-linear-model-as-analysis-of-variance"><i class="fa fa-check"></i><b>14.3</b> The linear model as analysis of variance</a></li>
<li class="chapter" data-level="14.4" data-path="introlm.html"><a href="introlm.html#simple-linear-regression-again"><i class="fa fa-check"></i><b>14.4</b> Simple linear regression (again)</a></li>
<li class="chapter" data-level="14.5" data-path="introlm.html"><a href="introlm.html#model-performance"><i class="fa fa-check"></i><b>14.5</b> Model performance</a></li>
<li class="chapter" data-level="14.6" data-path="introlm.html"><a href="introlm.html#multiple-regression"><i class="fa fa-check"></i><b>14.6</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="introlm.html"><a href="introlm.html#the-eia-data-again"><i class="fa fa-check"></i><b>14.6.1</b> The EIA data again</a></li>
<li class="chapter" data-level="14.6.2" data-path="introlm.html"><a href="introlm.html#model-specification-1"><i class="fa fa-check"></i><b>14.6.2</b> Model specification</a></li>
<li class="chapter" data-level="14.6.3" data-path="introlm.html"><a href="introlm.html#types-of-covariates"><i class="fa fa-check"></i><b>14.6.3</b> Types of covariates</a></li>
<li class="chapter" data-level="14.6.4" data-path="introlm.html"><a href="introlm.html#model-fitting"><i class="fa fa-check"></i><b>14.6.4</b> Model fitting</a></li>
<li class="chapter" data-level="14.6.5" data-path="introlm.html"><a href="introlm.html#parameter-interpretation"><i class="fa fa-check"></i><b>14.6.5</b> Parameter Interpretation</a></li>
<li class="chapter" data-level="14.6.6" data-path="introlm.html"><a href="introlm.html#parameter-uncertainty"><i class="fa fa-check"></i><b>14.6.6</b> Parameter uncertainty</a></li>
<li class="chapter" data-level="14.6.7" data-path="introlm.html"><a href="introlm.html#confidence-intervals-cis-on-parameters"><i class="fa fa-check"></i><b>14.6.7</b> Confidence intervals (CIs) on parameters</a></li>
<li class="chapter" data-level="14.6.8" data-path="introlm.html"><a href="introlm.html#hypothesis-testing"><i class="fa fa-check"></i><b>14.6.8</b> Hypothesis testing</a></li>
<li class="chapter" data-level="14.6.9" data-path="introlm.html"><a href="introlm.html#model-performance-1"><i class="fa fa-check"></i><b>14.6.9</b> Model performance</a></li>
<li class="chapter" data-level="14.6.10" data-path="introlm.html"><a href="introlm.html#more-covariates-of-mixed-types"><i class="fa fa-check"></i><b>14.6.10</b> More covariates of mixed types</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="introlm.html"><a href="introlm.html#the-matrix-interpretation-of-a-linear-model"><i class="fa fa-check"></i><b>14.7</b> The matrix interpretation of a linear model</a>
<ul>
<li class="chapter" data-level="14.7.1" data-path="introlm.html"><a href="introlm.html#dummy-variables"><i class="fa fa-check"></i><b>14.7.1</b> Dummy variables</a></li>
<li class="chapter" data-level="14.7.2" data-path="introlm.html"><a href="introlm.html#combining-factors-and-continuous-variables"><i class="fa fa-check"></i><b>14.7.2</b> Combining factors and continuous variables</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="introlm.html"><a href="introlm.html#SUMlm"><i class="fa fa-check"></i><b>14.8</b> Summary</a>
<ul>
<li class="chapter" data-level="14.8.1" data-path="introlm.html"><a href="introlm.html#learning-objectives-2"><i class="fa fa-check"></i><b>14.8.1</b> Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="14.9" data-path="introlm.html"><a href="introlm.html#ANSlm"><i class="fa fa-check"></i><b>14.9</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="modelselection.html"><a href="modelselection.html"><i class="fa fa-check"></i><b>15</b> Model selection</a>
<ul>
<li class="chapter" data-level="15.1" data-path="modelselection.html"><a href="modelselection.html#INTmodsel"><i class="fa fa-check"></i><b>15.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="modelselection.html"><a href="modelselection.html#criteria-for-model-selection"><i class="fa fa-check"></i><b>15.1.1</b> Criteria for model selection</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="modelselection.html"><a href="modelselection.html#collinearity"><i class="fa fa-check"></i><b>15.2</b> Collinearity</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="modelselection.html"><a href="modelselection.html#variance-inflation-factors"><i class="fa fa-check"></i><b>15.2.1</b> Variance inflation factors</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="modelselection.html"><a href="modelselection.html#p-value-based-model-selection-the-f-test"><i class="fa fa-check"></i><b>15.3</b> <span class="math inline">\(p\)</span>-value based model selection: the <span class="math inline">\(F\)</span>-test</a></li>
<li class="chapter" data-level="15.4" data-path="modelselection.html"><a href="modelselection.html#relative-model-fit"><i class="fa fa-check"></i><b>15.4</b> Relative model fit</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="modelselection.html"><a href="modelselection.html#akaikes-information-criterion-aic"><i class="fa fa-check"></i><b>15.4.1</b> Akaike’s Information Criterion (AIC)</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="modelselection.html"><a href="modelselection.html#other-methods-of-model-selection"><i class="fa fa-check"></i><b>15.5</b> Other methods of model selection</a></li>
<li class="chapter" data-level="15.6" data-path="modelselection.html"><a href="modelselection.html#automated-variable-selection"><i class="fa fa-check"></i><b>15.6</b> Automated variable selection</a>
<ul>
<li class="chapter" data-level="15.6.1" data-path="modelselection.html"><a href="modelselection.html#stepwise-selection"><i class="fa fa-check"></i><b>15.6.1</b> Stepwise selection</a></li>
<li class="chapter" data-level="15.6.2" data-path="modelselection.html"><a href="modelselection.html#all-possible-subsets-selection"><i class="fa fa-check"></i><b>15.6.2</b> All possible subsets selection</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="modelselection.html"><a href="modelselection.html#example-model-selection-with-the-medical-data"><i class="fa fa-check"></i><b>15.7</b> Example: model selection with the medical data</a>
<ul>
<li class="chapter" data-level="15.7.1" data-path="modelselection.html"><a href="modelselection.html#model-specification-3"><i class="fa fa-check"></i><b>15.7.1</b> Model specification</a></li>
<li class="chapter" data-level="15.7.2" data-path="modelselection.html"><a href="modelselection.html#interpreting-the-parameter-estimates"><i class="fa fa-check"></i><b>15.7.2</b> Interpreting the parameter estimates</a></li>
<li class="chapter" data-level="15.7.3" data-path="modelselection.html"><a href="modelselection.html#what-should-be-in-the-model"><i class="fa fa-check"></i><b>15.7.3</b> What ‘should’ be in the model?</a></li>
<li class="chapter" data-level="15.7.4" data-path="modelselection.html"><a href="modelselection.html#what-terms-are-significant"><i class="fa fa-check"></i><b>15.7.4</b> What terms are significant?</a></li>
<li class="chapter" data-level="15.7.5" data-path="modelselection.html"><a href="modelselection.html#more-automated-methods"><i class="fa fa-check"></i><b>15.7.5</b> More automated methods</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="modelselection.html"><a href="modelselection.html#SUMmodsel"><i class="fa fa-check"></i><b>15.8</b> Summary</a>
<ul>
<li class="chapter" data-level="15.8.1" data-path="modelselection.html"><a href="modelselection.html#learning-objectives-3"><i class="fa fa-check"></i><b>15.8.1</b> Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="15.9" data-path="modelselection.html"><a href="modelselection.html#ANSmodsel"><i class="fa fa-check"></i><b>15.9</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="interac.html"><a href="interac.html"><i class="fa fa-check"></i><b>16</b> Interactions and the Linear Model</a>
<ul>
<li class="chapter" data-level="16.1" data-path="interac.html"><a href="interac.html#INTinterac"><i class="fa fa-check"></i><b>16.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="interac.html"><a href="interac.html#fitting-different-models"><i class="fa fa-check"></i><b>16.1.1</b> Fitting different models</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="interac.html"><a href="interac.html#fitting-interaction-terms"><i class="fa fa-check"></i><b>16.2</b> Fitting interaction terms</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="interac.html"><a href="interac.html#specifying-interactions-in-model-formulae"><i class="fa fa-check"></i><b>16.2.1</b> Specifying interactions in model formulae</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="interac.html"><a href="interac.html#interactions-in-practise"><i class="fa fa-check"></i><b>16.3</b> Interactions in practise</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="interac.html"><a href="interac.html#eia-data"><i class="fa fa-check"></i><b>16.3.1</b> EIA data</a></li>
<li class="chapter" data-level="16.3.2" data-path="interac.html"><a href="interac.html#medical-data"><i class="fa fa-check"></i><b>16.3.2</b> Medical data</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="interac.html"><a href="interac.html#model-selection-and-interactions"><i class="fa fa-check"></i><b>16.4</b> Model selection and interactions</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="interac.html"><a href="interac.html#backwards-selection-in-the-eia-data-set"><i class="fa fa-check"></i><b>16.4.1</b> Backwards selection in the EIA data set</a></li>
<li class="chapter" data-level="16.4.2" data-path="interac.html"><a href="interac.html#backwards-selection-in-the-medical-data-set"><i class="fa fa-check"></i><b>16.4.2</b> Backwards selection in the medical data set</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="interac.html"><a href="interac.html#SUMinterac"><i class="fa fa-check"></i><b>16.5</b> Summary</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="interac.html"><a href="interac.html#learning-objectives-4"><i class="fa fa-check"></i><b>16.5.1</b> Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="interac.html"><a href="interac.html#ANSinterac"><i class="fa fa-check"></i><b>16.6</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>17</b> Prediction from the linear model</a>
<ul>
<li class="chapter" data-level="17.1" data-path="prediction.html"><a href="prediction.html#INTpred"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="prediction.html"><a href="prediction.html#prediction-1"><i class="fa fa-check"></i><b>17.2</b> Prediction</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="prediction.html"><a href="prediction.html#doing-this-in-r-27"><i class="fa fa-check"></i><b>17.2.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="prediction.html"><a href="prediction.html#uncertainty-in-the-prediction"><i class="fa fa-check"></i><b>17.3</b> Uncertainty in the prediction</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="prediction.html"><a href="prediction.html#doing-this-in-r-28"><i class="fa fa-check"></i><b>17.3.1</b> Doing this in R</a></li>
<li class="chapter" data-level="17.3.2" data-path="prediction.html"><a href="prediction.html#confidence-intervals-for-the-line"><i class="fa fa-check"></i><b>17.3.2</b> Confidence intervals for the line</a></li>
<li class="chapter" data-level="17.3.3" data-path="prediction.html"><a href="prediction.html#prediction-intervals"><i class="fa fa-check"></i><b>17.3.3</b> Prediction intervals</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="prediction.html"><a href="prediction.html#prediction-in-multiple-regression"><i class="fa fa-check"></i><b>17.4</b> Prediction in multiple regression</a></li>
<li class="chapter" data-level="17.5" data-path="prediction.html"><a href="prediction.html#SUMpred"><i class="fa fa-check"></i><b>17.5</b> Summary</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="prediction.html"><a href="prediction.html#learning-objectives-5"><i class="fa fa-check"></i><b>17.5.1</b> Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="prediction.html"><a href="prediction.html#ANSpred"><i class="fa fa-check"></i><b>17.6</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="diagnostics.html"><a href="diagnostics.html"><i class="fa fa-check"></i><b>18</b> Linear model diagnostics</a>
<ul>
<li class="chapter" data-level="18.1" data-path="diagnostics.html"><a href="diagnostics.html#INTdiag"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="diagnostics.html"><a href="diagnostics.html#predictive-power"><i class="fa fa-check"></i><b>18.2</b> Predictive power</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="diagnostics.html"><a href="diagnostics.html#signal-versus-noise"><i class="fa fa-check"></i><b>18.2.1</b> Signal versus noise</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="diagnostics.html"><a href="diagnostics.html#model-assumptions"><i class="fa fa-check"></i><b>18.3</b> Model assumptions</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="diagnostics.html"><a href="diagnostics.html#normality-assumption"><i class="fa fa-check"></i><b>18.3.1</b> Normality assumption</a></li>
<li class="chapter" data-level="18.3.2" data-path="diagnostics.html"><a href="diagnostics.html#assessing-constant-error-variance"><i class="fa fa-check"></i><b>18.3.2</b> Assessing constant error variance</a></li>
<li class="chapter" data-level="18.3.3" data-path="diagnostics.html"><a href="diagnostics.html#assessing-independence"><i class="fa fa-check"></i><b>18.3.3</b> Assessing independence</a></li>
<li class="chapter" data-level="18.3.4" data-path="diagnostics.html"><a href="diagnostics.html#pseudoreplication"><i class="fa fa-check"></i><b>18.3.4</b> Pseudoreplication</a></li>
<li class="chapter" data-level="18.3.5" data-path="diagnostics.html"><a href="diagnostics.html#linearity-in-the-model-for-the-signal"><i class="fa fa-check"></i><b>18.3.5</b> Linearity in the model for the signal</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="diagnostics.html"><a href="diagnostics.html#example-diagnostics-with-the-medical-data"><i class="fa fa-check"></i><b>18.4</b> Example: Diagnostics with the medical data</a></li>
<li class="chapter" data-level="18.5" data-path="diagnostics.html"><a href="diagnostics.html#partial-residual-plots"><i class="fa fa-check"></i><b>18.5</b> Partial residual plots</a>
<ul>
<li class="chapter" data-level="18.5.1" data-path="diagnostics.html"><a href="diagnostics.html#doing-this-in-r-30"><i class="fa fa-check"></i><b>18.5.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="diagnostics.html"><a href="diagnostics.html#interaction-terms"><i class="fa fa-check"></i><b>18.6</b> Interaction Terms</a></li>
<li class="chapter" data-level="18.7" data-path="diagnostics.html"><a href="diagnostics.html#SUMdiag"><i class="fa fa-check"></i><b>18.7</b> Summary</a>
<ul>
<li class="chapter" data-level="18.7.1" data-path="diagnostics.html"><a href="diagnostics.html#learning-outcomes-10"><i class="fa fa-check"></i><b>18.7.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="18.8" data-path="diagnostics.html"><a href="diagnostics.html#ANSdiag"><i class="fa fa-check"></i><b>18.8</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="nextsteps.html"><a href="nextsteps.html"><i class="fa fa-check"></i><b>19</b> The Next Steps</a>
<ul>
<li class="chapter" data-level="19.1" data-path="nextsteps.html"><a href="nextsteps.html#INTnext"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="nextsteps.html"><a href="nextsteps.html#solving-the-assumptional-problems"><i class="fa fa-check"></i><b>19.2</b> Solving the assumptional problems</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="nextsteps.html"><a href="nextsteps.html#example-the-eia-data"><i class="fa fa-check"></i><b>19.2.1</b> Example: The EIA data</a></li>
<li class="chapter" data-level="19.2.2" data-path="nextsteps.html"><a href="nextsteps.html#oddly-distributed-residuals"><i class="fa fa-check"></i><b>19.2.2</b> Oddly distributed residuals</a></li>
<li class="chapter" data-level="19.2.3" data-path="nextsteps.html"><a href="nextsteps.html#non-independence"><i class="fa fa-check"></i><b>19.2.3</b> Non-independence</a></li>
<li class="chapter" data-level="19.2.4" data-path="nextsteps.html"><a href="nextsteps.html#non-linearity"><i class="fa fa-check"></i><b>19.2.4</b> Non-linearity</a></li>
<li class="chapter" data-level="19.2.5" data-path="nextsteps.html"><a href="nextsteps.html#bootstrapping"><i class="fa fa-check"></i><b>19.2.5</b> Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="nextsteps.html"><a href="nextsteps.html#summary-1"><i class="fa fa-check"></i><b>19.3</b> Summary</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="nextsteps.html"><a href="nextsteps.html#learning-outcomes-11"><i class="fa fa-check"></i><b>19.3.1</b> Learning outcomes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="notation.html"><a href="notation.html"><i class="fa fa-check"></i><b>20</b> Notation {-}</a>
<ul>
<li class="chapter" data-level="20.1" data-path="notation.html"><a href="notation.html#summation"><i class="fa fa-check"></i><b>20.1</b> Summation</a></li>
<li class="chapter" data-level="20.2" data-path="notation.html"><a href="notation.html#factorial"><i class="fa fa-check"></i><b>20.2</b> Factorial</a></li>
<li class="chapter" data-level="20.3" data-path="notation.html"><a href="notation.html#combinations"><i class="fa fa-check"></i><b>20.3</b> Combinations</a></li>
<li class="chapter" data-level="20.4" data-path="notation.html"><a href="notation.html#multiplication"><i class="fa fa-check"></i><b>20.4</b> Multiplication</a></li>
<li class="chapter" data-level="20.5" data-path="notation.html"><a href="notation.html#integration"><i class="fa fa-check"></i><b>20.5</b> Integration</a></li>
<li class="chapter" data-level="20.6" data-path="notation.html"><a href="notation.html#matrix-multiplication"><i class="fa fa-check"></i><b>20.6</b> Matrix multiplication</a></li>
<li class="chapter" data-level="20.7" data-path="notation.html"><a href="notation.html#absolute-values"><i class="fa fa-check"></i><b>20.7</b> Absolute values</a></li>
<li class="chapter" data-level="20.8" data-path="notation.html"><a href="notation.html#pi"><i class="fa fa-check"></i><b>20.8</b> <span class="math inline">\(\pi\)</span></a></li>
<li class="chapter" data-level="20.9" data-path="notation.html"><a href="notation.html#exponential-function-e"><i class="fa fa-check"></i><b>20.9</b> Exponential function, <span class="math inline">\(e\)</span></a></li>
<li class="chapter" data-level="20.10" data-path="notation.html"><a href="notation.html#intervals"><i class="fa fa-check"></i><b>20.10</b> Intervals</a></li>
<li class="chapter" data-level="20.11" data-path="notation.html"><a href="notation.html#axes-on-plots"><i class="fa fa-check"></i><b>20.11</b> Axes on plots</a></li>
<li class="chapter" data-level="20.12" data-path="notation.html"><a href="notation.html#probability-2"><i class="fa fa-check"></i><b>20.12</b> Probability</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="proportions" class="section level1" number="11">
<h1><span class="header-section-number">Chapter 11</span> Proportions</h1>
<!-- \begin{tcolorbox}

\end{tcolorbox}-->
<p><em>There is no excellent beauty that hath not some strangeness in the proportion.</em>
Sir Francis Bacon <span class="citation">(<a href="#ref-Bacon1696" role="doc-biblioref">1696</a>)</span></p>
<div id="INTprop" class="section level2" number="11.1">
<h2><span class="header-section-number">11.1</span> Introduction</h2>
<p>Data often come as counts or frequencies which can be transformed to proportions. For example, imagine a survey where at each of several locations, the presence or absence of one or more birds is noted. The proportion of locations where a bird was located can be obtained from</p>
<p><span class="math display">\[\textrm{proportion of bird locations} = \frac{\textrm{number of locations where one or more birds are seen}}{\textrm{total number of locations}}\]</span></p>
<p>We can use the observed proportion to estimate the probability of seeing one or more birds at a particular locality, <span class="math inline">\(x\)</span>, out of the number of trials, <span class="math inline">\(n\)</span>, to estimate the probability of success, <span class="math inline">\(p\)</span>:</p>
<p><span class="math display">\[\hat p = \frac{x}{n}\]</span></p>
<p>Hence, we estimate the true underlying probability <span class="math inline">\(p\)</span> with the sample proportion <span class="math inline">\(\hat p\)</span>. If different locations had been sampled, then the observed proportion of locations where a bird was detected would likely change. There is some uncertainty associated with the sample proportions. Therefore in this chapter we consider:</p>
<ul>
<li>confidence intervals for proportions</li>
<li>confidence intervals for a difference in proportions and</li>
<li>a hypothesis test for a proportion.</li>
</ul>
<p>Proportions and probabilities are similar in that they are both bounded by 0 and 1 and the terms are often used interchangeably, not least because the sample proportion is frequently used to estimate the underlying (but unknown) population probability of success.</p>
<p>In some cases, looking at the difference between proportions is not possible or relevant and so a ratio is obtained - this is called an odds ratio and discussed at the end of this chapter.</p>
</div>
<div id="confidence-intervals" class="section level2" number="11.2">
<h2><span class="header-section-number">11.2</span> Confidence intervals</h2>
<p>To illustrate the formulation of CI for a proportion, we can consider the bird survey mentioned above. Imagine the birds were surveyed at three different time periods (perhaps before (which we will call phase A), during (phase B) and after (phase C) the building of a windfarm. There are two obvious questions of interest: in what proportion of localities will a bird be seen and what is the difference in the proportion of birds seen between the phases?</p>
<p>To estimate the proportion of localities with birds in this region assume that the number of locations where a bird was detected <span class="math inline">\(x\)</span> is a random variable from a binomial distribution with known <span class="math inline">\(n\)</span> (fixed number of trials, i.e. all sampling locations) and unknown <span class="math inline">\(p\)</span> (probability of success).</p>
<p>We will estimate the proportion of ‘successful’ observations, <span class="math inline">\(p\)</span>, from the number of observations with sightings (‘successes’) and the total number of observations (`trials’).</p>
<p>Recall, there are 4 conditions of the binomial distribution:</p>
<ol style="list-style-type: decimal">
<li>two outcomes for each trial,</li>
<li>the same probability of success for each trial,</li>
<li>a fixed number of trials,</li>
<li>independence of trials.</li>
</ol>
<p><strong>Q11.1</strong> How realistic are these conditions for the wind farm data?</p>
<div id="exploratory-data-analysis" class="section level3" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Exploratory data analysis</h3>
<p>Trained observers recorded the presence or absence of birds at each spatial location:</p>
<ul>
<li>when birds were seen in some defined location a presence (success) was recorded</li>
<li>and when birds were not seen it was recorded as an absence (failure).</li>
</ul>
<p>We estimate the probability of sighting an animal using:</p>
<p><span class="math display">\[\hat{p}=\frac{\text{number of successes}}{\text{number of trials}} \]</span></p>
<p>which in the wind farm data, as mentioned in the introduction, translates to:</p>
<span class="math display">\[\hat p = \frac{\textrm{number of observations where one or more birds were seen}}{\textrm{total number of observations}}\]</span>
For each phase we have the number of successful observations and the number of observations in total (Table <a href="proportions.html#tab:phasetab">11.1</a>). <br/><br />

<caption>
<span id="tab:phasetab">Table 11.1: </span> Number of presence (1) or absence (0) observations in phases A, B and C in the building of a windfarm.
</caption>
<table style="width:50%;">
<colgroup>
<col width="16%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">A</th>
<th align="center">B</th>
<th align="center">C</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>0</strong></td>
<td align="center">10335</td>
<td align="center">12495</td>
<td align="center">5436</td>
</tr>
<tr class="even">
<td align="center"><strong>1</strong></td>
<td align="center">1143</td>
<td align="center">1633</td>
<td align="center">460</td>
</tr>
<tr class="odd">
<td align="center"><strong>Total</strong></td>
<td align="center">11478</td>
<td align="center">14128</td>
<td align="center">5896</td>
</tr>
</tbody>
</table>
<p><br/>
From this summary information we estimate the sighting probabilities in each phase as follows:</p>
<p><span class="math display">\[\hat p_{A} = \frac{1143}{11478} = 0.0996 \quad; \quad \hat p_{B} = \frac{1633}{14128} = 0.1156 \quad ; \quad \hat p_{C} = \frac{460}{5896} = 0.0780\]</span>
We can estimate similar probabilities for each year and month (Figure <a href="proportions.html#fig:barplotfig2">11.1</a>) of the survey. The before period was from 2000 to 2002 inclusive, the during period was 2003 and 2007 and the after period was 2011.</p>
<!--out.width='.6\\linewidth',-->
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:barplotfig2"></span>
<img src="IntroStats_files/figure-html/barplotfig2-1.png" alt="Barplot showing the mean sightings probability for every year/month combination. N.B.Not all months are labelled" width="480" />
<p class="caption">
Figure 11.1: Barplot showing the mean sightings probability for every year/month combination. N.B.Not all months are labelled
</p>
</div>
<p>From this information (Figure <a href="proportions.html#fig:barplotfig2">11.1</a>) we see that:</p>
<ul>
<li>the proportion of sighting a bird appears to be higher in phase B compared with the phases A and C,</li>
<li>and the proportion of sighting a bird tends to be highest in January-March of each year.</li>
</ul>
<p>While some patterns are apparent, it is difficult to tell if the observed differences are genuine differences across phases and/or year-month combinations or if these differences are due to sampling error; would these differences have been seen even if the true underlying (but unknown) probability of sighting for all phases (and/or year-month combinations) was the same? To assess the uncertainty associated with a sample proportion, we build a confidence interval and the formulation of the interval depends on the number of trials, <span class="math inline">\(n\)</span>, and on the value of <span class="math inline">\(p\)</span>.</p>
</div>
<div id="confidence-intervals-large-sample-sizes" class="section level3" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> Confidence intervals: large sample sizes</h3>
<p>While the number of successes from the number of trials is assumed to be a binomial random variable, the sample proportions (estimates for <span class="math inline">\(p\)</span>; <span class="math inline">\(\hat{p}\)</span>) are normally distributed about the true (underlying) population proportion if the number of trials is <strong>large</strong>. Therefore, confidence intervals (CIs) for proportions are constructed in a similar way to CIs for large samples of normal data. For large samples, the sample porportion is approximately normally distributed:</p>
<p><span class="math display">\[\hat{p} \sim normal \left(p, se({p})\right)\]</span>
However, since we never know <span class="math inline">\(p\)</span>, we use the sample proportion <span class="math inline">\(\hat p\)</span>, thus, the standard deviation of the sample proportion (the standard error) can be found using:</p>
<p><span class="math display">\[se(\hat{p})=\sqrt{\frac{\hat p (1-\hat p)}{n}}\]</span>
Just as with means we can create 95% confidence interval on the proportions.</p>
<p>To find a <strong>95% confidence interval</strong> for <span class="math inline">\(p\)</span> we use a familiar structure:
<span class="math display">\[\begin{align*}
          \textrm{estimate}~~ &amp;\pm z_{1-\frac{\alpha}{2}} \times~~ \textrm{standard error}\\
          \hat{p} &amp; \pm 1.96 \times \sqrt{\frac{\hat{p} (1-\hat{p})}{n}}
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\alpha=0.05\)</span> for a 95% CI, hence <span class="math inline">\(z_{0.025}\)</span>.</p>
<div id="how-large-is-large-enough" class="section level4" number="11.2.2.1">
<h4><span class="header-section-number">11.2.2.1</span> How large is large enough?</h4>
<p>To assume these estimates are approximately normally distributed about <span class="math inline">\(p\)</span> we require large samples. As the number of trials increases, the distribution becomes more and more like the normal distribution until the sample size is so large that the distribution is exactly normally distributed - it has reached a limit, or asymptote, hence, these CI are sometimes called ‘asymptotic’ confidence intervals. However, the required sample size changes with <span class="math inline">\(\hat{p}\)</span>.</p>
<p>The minimum sample sizes for different values of <span class="math inline">\(\hat p\)</span> are given in Table <a href="proportions.html#tab:samplesizeprop">11.2</a>. Thus if p is very small 0.05 or large 0.95, a sample size of at least 960 would be required in order to assume that the proportion is normally distributed.:</p>
<caption>
<span id="tab:samplesizeprop">Table 11.2: </span> Sample sizes for to assume large-sample properties for proportions
</caption>
<table>
<thead>
<tr class="header">
<th align="center">Value for <span class="math inline">\(\hat{p}\)</span></th>
<th align="center">0.05</th>
<th align="center">0.1</th>
<th align="center">0.15</th>
<th align="center">0.2</th>
<th align="center">0.25</th>
<th align="center">0.3</th>
<th align="center">0.35</th>
<th align="center">0.4</th>
<th align="center">0.45</th>
<th align="center">0.5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Minimum <span class="math inline">\(n\)</span></td>
<td align="center">960</td>
<td align="center">400</td>
<td align="center">220</td>
<td align="center">125</td>
<td align="center">76</td>
<td align="center">47</td>
<td align="center">23</td>
<td align="center">13</td>
<td align="center">11</td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="center">Value for <span class="math inline">\(\hat{p}\)</span></td>
<td align="center">0.95</td>
<td align="center">0.9</td>
<td align="center">0.85</td>
<td align="center">0.8</td>
<td align="center">0.75</td>
<td align="center">0.7</td>
<td align="center">0.65</td>
<td align="center">0.6</td>
<td align="center">0.55</td>
<td align="center">0.5</td>
</tr>
</tbody>
</table>
<p><strong>Example</strong> We are going to build 95% CIs for the proportion of sighting birds in phases A, B and C. The total number of sampled locations (<span class="math inline">\(n\)</span>) for each phase is greater than 1000 and so results based on these large-sample properties should be valid.</p>
<p>The CI for Phase A is constructed as follows: we estimated <span class="math inline">\(p_A\)</span> previously, <span class="math inline">\(\hat p_A = 0.0996\)</span> and the standard error is given by:</p>
<p><span class="math display">\[se(\hat{p_A})=\sqrt{\frac{\hat{p_A}(1-\hat{p_A})}{n}}=
          \sqrt{\frac{0.0996(1-0.0996)}{11478}}=  0.0028\]</span></p>
<p><span class="math display">\[\begin{align*}
95\%~ \textrm{CI}=&amp;\hat{p} \pm z_{0.025} \times se(\hat{p})\\
=&amp;0.0996 \pm 1.96 \times 0.0028\\
=&amp; (0.0941,0.1051)
\end{align*}\]</span></p>
<p>Based on these results we can be 95% confident that the proportion of locations with a bird in Phase <em>A</em> is somewhere between 0.094 (9.4%) and 0.105 (10.5%).</p>
<p>We find 95% CI for the proportions in phases B and C and thus can say,</p>
<ul>
<li><p>with 95% confidence we estimate the proportion of a location with a bird in this region in Phase B to be somewhere between 0.11, 0.121</p></li>
<li><p>with 95% confidence we estimate the proportion of a location with a bird in this region in Phase C to be somewhere between 0.071, 0.085.</p></li>
</ul>
</div>
<div id="doing-this-in-r-19" class="section level4" number="11.2.2.2">
<h4><span class="header-section-number">11.2.2.2</span> Doing this in R</h4>
<p>To calculate these confidence intervals in R, an additional package is required <code>Hmisc</code> <span class="citation">(<a href="#ref-R-Hmisc" role="doc-biblioref">Harrell 2021</a>)</span>:</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="proportions.html#cb242-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load package</span></span>
<span id="cb242-2"><a href="proportions.html#cb242-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Hmisc)</span>
<span id="cb242-3"><a href="proportions.html#cb242-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% CI using asymptotic normal approximation; x=number of successes; </span></span>
<span id="cb242-4"><a href="proportions.html#cb242-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   n=number of trials</span></span>
<span id="cb242-5"><a href="proportions.html#cb242-5" aria-hidden="true" tabindex="-1"></a><span class="fu">binconf</span>(<span class="at">x=</span><span class="dv">1143</span>, <span class="at">n=</span><span class="dv">11478</span>, <span class="at">alpha=</span><span class="fl">0.05</span>, <span class="at">method=</span><span class="st">&quot;asymptotic&quot;</span>)</span></code></pre></div>
<pre><code>   PointEst      Lower     Upper
 0.09958181 0.09410374 0.1050599</code></pre>
</div>
</div>
<div id="confidence-intervals-small-sample-sizes" class="section level3" number="11.2.3">
<h3><span class="header-section-number">11.2.3</span> Confidence intervals: small sample sizes</h3>
<p>For ‘small’ samples (less than those in the table above) when <span class="math inline">\(p\)</span> is close to zero or one, assuming the proportions are normally distributed is not valid.</p>
<p>To illustrate this we calculate the 95% CI for <span class="math inline">\(\hat p=0.1\)</span> and <span class="math inline">\(n=10\)</span>.</p>
<p><span class="math display">\[se(\hat p) = \sqrt{\frac{0.1 (1-0.1)}{10}} = 0.0949\]</span></p>
<p>Hence, the CI is given by</p>
<p><span class="math display">\[0.1 \pm 1.96*0.0949\]</span>
<span class="math display">\[0.1 \pm 0.1859 \]</span>
<span class="math display">\[-0.086 \quad ; \quad 0.286 \]</span></p>
<p>The lower limit is less than 0 and a proportion cannot be negative. Therefore, a different formulation is required for small sample sizes.</p>
<p>The literature suggests that <strong>Wilson intervals</strong> are preferred in these cases <span class="citation">(<a href="#ref-Agresti1998" role="doc-biblioref">Agresti and Coull 1998</a>)</span>. This has a rather more complicated formula:</p>
<p><span class="math display">\[\frac{1}{1+{\frac{1}{n}}z^{2}}\left[{\hat {p}}+{\frac{1}{2n}}z^{2}\pm z{\sqrt{{\frac {1}{n}}{\hat{p}}\left(1-{\hat{p}}\right)+{\frac {1}{4n^{2}}}z^{2}}}\right]\]</span>
(and so we will be using <code>R</code> to calculate these values.)</p>
<p>This approach ensures that the confidence interval limits never extend below zero or above one.</p>
<p>For example, Table <a href="proportions.html#tab:compwilson">11.3</a> the asymptotic (i.e. using the normal distribution) and Wilson confidence intervals are calculated when we have one success and 10 trials (i.e. <span class="math inline">\(p=0.1\)</span>):</p>
<caption>
<span id="tab:compwilson">Table 11.3: </span> Comparison of Wilson and asymptotic confidence intervals
</caption>
<table style="width:69%;">
<colgroup>
<col width="23%" />
<col width="15%" />
<col width="15%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">PointEst</th>
<th align="center">Lower</th>
<th align="center">Upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Wilson</strong></td>
<td align="center">0.1</td>
<td align="center">0.005129</td>
<td align="center">0.4042</td>
</tr>
<tr class="even">
<td align="center"><strong>Asymptotic</strong></td>
<td align="center">0.1</td>
<td align="center">-0.08594</td>
<td align="center">0.2859</td>
</tr>
</tbody>
</table>
<p>The lower limit for the confidence interval based on the normal distribution is negative - an inplausible value for a proportion.</p>
<p>According to our table of ‘what is large,’ when <span class="math inline">\(\hat{p} = 0.1\)</span>, we should have a sample size of more than 400 to use the method based on the normal distribution.</p>
<p>If we increase the number of trials to 1000, (and the number of success to 100 so that <span class="math inline">\(\hat{p}=0.1\)</span>), then the asymptotic normal distribution-based interval no longer gives impossible values.</p>
<table style="width:67%;">
<colgroup>
<col width="23%" />
<col width="15%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">PointEst</th>
<th align="center">Lower</th>
<th align="center">Upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Wilson</strong></td>
<td align="center">0.1</td>
<td align="center">0.08291</td>
<td align="center">0.1202</td>
</tr>
<tr class="even">
<td align="center"><strong>Asymptotic</strong></td>
<td align="center">0.1</td>
<td align="center">0.08141</td>
<td align="center">0.1186</td>
</tr>
</tbody>
</table>
<p>However, note that for very small estimates of <span class="math inline">\(p\)</span>, Wilson intervals are still preferred even if the number of trials is large.</p>
<p>For our wind farm data, the Wilson intervals for the proportions of locations are givein in Table <a href="proportions.html#tab:compphases">11.4</a>:</p>
<caption>
<span id="tab:compphases">Table 11.4: </span> Comparison of Wilson confidence intervals for the windfarm phases
</caption>
<table style="width:54%;">
<colgroup>
<col width="11%" />
<col width="15%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Phase</th>
<th align="center">PointEst</th>
<th align="center">Lower</th>
<th align="center">Upper</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">A</td>
<td align="center">0.09958</td>
<td align="center">0.09424</td>
<td align="center">0.1052</td>
</tr>
<tr class="even">
<td align="center">B</td>
<td align="center">0.1156</td>
<td align="center">0.1104</td>
<td align="center">0.121</td>
</tr>
<tr class="odd">
<td align="center">C</td>
<td align="center">0.07802</td>
<td align="center">0.07144</td>
<td align="center">0.08514</td>
</tr>
</tbody>
</table>
<p>These are very similar to the CI we calculated earlier; this is not surprising since the numbers of trials are so large.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:barplotcifig"></span>
<img src="IntroStats_files/figure-html/barplotcifig-1.png" alt="Barplot showing the mean sightings probability for each of the three phases. The black lines are 95\% Wilsons confidence intervals." width="480" />
<p class="caption">
Figure 11.2: Barplot showing the mean sightings probability for each of the three phases. The black lines are 95% Wilsons confidence intervals.
</p>
</div>
<div id="doing-this-in-r-20" class="section level4" number="11.2.3.1">
<h4><span class="header-section-number">11.2.3.1</span> Doing this in R</h4>
<p>Wilson confidence intervals are obtained by specifying <code>method="wilson</code>.</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="proportions.html#cb244-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Wilson&#39;s CI for p=0.1 and number of trials is 10</span></span>
<span id="cb244-2"><a href="proportions.html#cb244-2" aria-hidden="true" tabindex="-1"></a><span class="fu">binconf</span>(<span class="at">x=</span><span class="dv">1</span>, <span class="at">n=</span><span class="dv">10</span>, <span class="at">alpha=</span><span class="fl">0.05</span>, <span class="at">method=</span><span class="st">&quot;wilson&quot;</span>)</span></code></pre></div>
<pre><code> PointEst       Lower   Upper
      0.1 0.005129329 0.40415</code></pre>
</div>
</div>
</div>
<div id="comparing-two-proportions-the-z-test" class="section level2" number="11.3">
<h2><span class="header-section-number">11.3</span> Comparing two proportions: the <span class="math inline">\(z\)</span> test</h2>
<p>In this section we compare two proportions and again use the wind farm data as a motivating example.</p>
<p>While there appears to be some differences across phases based on the results obtained so far, in order to statistically answer questions about changes in proportions over time, we need to formally test for differences between the groups (e.g. between phases or between different years or months).</p>
<p>Rather than use confidence intervals, which give a range of likely values for each parameter, we test for <strong>no difference</strong> between the two parameter values and evaluate the strength of evidence against this null hypothesis. We <strong>formally</strong> compare two proportions with a hypothesis test, which uses the normal distribution as the reference distribution (known as a <span class="math inline">\(z\)</span> test).</p>
<p>So for example, we examine if there have been changes between phases in the wndfarm data by comparing the differences we have observed between phases with the sorts of differences we would expect to see even if no genuine changes have occurred.</p>
<div id="testing-for-no-difference-between-groups" class="section level3" number="11.3.1">
<h3><span class="header-section-number">11.3.1</span> Testing for ‘no difference’ between groups</h3>
<p>In order to test the research hypothesis that sighting proportions were different in phase A (<span class="math inline">\(p_{A}\)</span>) and phase C (<span class="math inline">\(p_{C}\)</span>) we take the following steps:</p>
<ul>
<li>We test this research hypothesis using the (skeptical) null hypothesis of no difference (<span class="math inline">\(H_0\)</span>) and a `two-sided’ alternative hypothesis (<span class="math inline">\(H_1\)</span>) of either a positive or negative difference:</li>
</ul>
<p><span class="math display">\[H_0: p_{A}-p_{C}=0\]</span></p>
<p><span class="math display">\[H_1: p_{A}-p_{C} \neq 0\]</span></p>
<ul>
<li><p>We evaluate the null hypothesis by considering what we would expect to see if the null hypothesis is true. For example,</p>
<ul>
<li>if there has been no difference in sighting probabilities between phases then we would expect to see small differences in the sighting rates across phases.</li>
<li>small differences like these (based on sampling variability alone) provide us with the background for comparison with the differences we did observe across phases.</li>
</ul></li>
<li><p>We compare our data-estimate (i.e. the difference between <span class="math inline">\(p_{A}\)</span> and <span class="math inline">\(p_{C}\)</span>) with the hypothesised value (for no difference, or zero, in this case):</p></li>
</ul>
<p><span class="math display">\[\textrm{data-estimate} - \textrm{hypothesised value}\]</span></p>
<ul>
<li>Our data-estimate for the difference between the proportions is:</li>
</ul>
<ul>
<li><p>the hypothesised value is 0, therefore our estimate is 0.0216 units.</p></li>
<li><p>While the point estimate (of 0.0216) is useful, we know that if we had taken data from slightly different locations or at slightly different times we would have obtained a different set of data and so we need to consider the uncertainty in our estimate.</p></li>
<li><p>The uncertainty in the estimate of the difference between the proportions can be quantified by the <strong>standard error of the difference</strong>:</p></li>
</ul>
<p><span class="math display">\[\begin{align*}
se(\hat{p}_A-\hat{p}_C)=&amp;\sqrt{\frac{\hat{p}_A(1-\hat{p}_A)}{n_A}+\frac{\hat{p}_C(1-\hat{p}_C)}{n_C}}\\
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
=&amp; \sqrt{\frac{0.0996(1-0.0996)}{11478}+\frac{0.078(1-0.078)}{5896}}\\
= &amp;   0.004\\
\end{align*}\]</span></p>
<p>This method of calculating the uncertainty in our estimate (the standard error formula) requires these sample proportions are independent.</p>
<p>Do you think this is realistic in this case?</p>
<div id="how-does-our-estimate-compare-with-the-differences-we-might-expect" class="section level4" number="11.3.1.1">
<h4><span class="header-section-number">11.3.1.1</span> How does our estimate compare with the differences we might expect?</h4>
<p>Once we have quantified the uncertainty about our estimate we can represent the difference seen between sample proportions as a ratio of the standard error.</p>
<p><span class="math display">\[\text{test statistic} = \frac{\text{difference - hypothesised value}}{\text{standard error}}\]</span></p>
<p>This puts our estimate for the difference into perspective:</p>
<ul>
<li><p>small differences can look large if the standard error is small (and our estimate has high precision/low uncertainty) and</p></li>
<li><p>large differences can look small (if our estimate has low precision/high uncertainty).</p></li>
</ul>
<p>In our example, even an apparently small difference is actually large when we consider the high precision/low uncertainty about the estimate:</p>
<p><span class="math display">\[\begin{align*}
\textrm{test statistic} =&amp;\frac{\textrm{difference-hypothesised value}}{\textrm{standard error}}\\
=&amp; \frac{0.022}{0.004} = 
4.82\\
\end{align*}\]</span></p>
<p>This estimate is in excess of 4 standard errors above zero. This can be seen in Figure <a href="proportions.html#fig:ztestplot">11.3</a>; where the test statistic is compared to the reference distribution i.e. a distribution that we might expect to see (because of sampling variability) even if there is no underlying difference in the values of the true proportions.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ztestplot"></span>
<img src="IntroStats_files/figure-html/ztestplot-1.png" alt="Reference distribution for the $z$ test: the  differences between proportions that would be expected if $p_1=p_2$. The dotted line indicates the test statistic." width="480" />
<p class="caption">
Figure 11.3: Reference distribution for the <span class="math inline">\(z\)</span> test: the differences between proportions that would be expected if <span class="math inline">\(p_1=p_2\)</span>. The dotted line indicates the test statistic.
</p>
</div>
<ul>
<li><p>From here we can evaluate the chance of getting a value at least as extreme as 4.82 when <span class="math inline">\(H_0\)</span> is true and there was <strong>no difference</strong> in proportions across phases.</p></li>
<li><p>We do this using the normal distribution as a reference distribution because it turns out that when there are no differences across phases, the test statistic has a normal distribution with <span class="math inline">\(\mu=0\)</span> and <span class="math inline">\(\sigma=1\)</span>. This distribution is known as the <strong>standard normal distribution</strong> or <strong><span class="math inline">\(z\)</span> distribution</strong> (Chapter <a href="hypothtests.html#hypothtests">8</a>).</p></li>
<li><p>We use this reference distribution as a comparison with our observed test statistic.</p></li>
</ul>
<p>In this case, we find the chance of seeing a difference like this (or one more extreme) is very small: the probability is <span class="math inline">\(10^{-6}\)</span>.</p>
<p><strong>What can we conclude?</strong></p>
<p>We have <strong>strong evidence</strong> for a difference between the proportions of locations where birds were detected in phase A and phase C.</p>
<p>We can reject the null hypothesis of no difference between proportions in phase A and phase C at the 1% level.</p>
<ul>
<li>Specifically, the probability of sighting a bird in Phase C appears to be significantly lower than in Phase A.</li>
</ul>
</div>
</div>
</div>
<div id="ci-for-the-difference-between-population-proportions-p_1-p_2" class="section level2" number="11.4">
<h2><span class="header-section-number">11.4</span> CI for the difference between population proportions, (<span class="math inline">\(p_1-p_2\)</span>)</h2>
<p>In the wind farm example we are interested in asking if there are differences across phases.</p>
<p>We can calculate the <strong>confidence interval for the difference in two proportions</strong> in the standard way:</p>
<p><span class="math display">\[\textrm{difference between sample proportions} \pm z\textrm{-multiplier} \times \textrm{standard error of the difference}\]</span></p>
<p><span class="math display">\[(\hat p_1-\hat p_2) \pm z_{1-\frac{\alpha}{2}} \times se(\hat p_1-\hat p_2)\]</span></p>
<p>However, the choice of formula for the standard error of the difference between two proportions can be important.</p>
<ul>
<li><p>For instance, it might be unrealistic to assume independence between samples and so the standard error formula used previously (situation A - see later) might be inappropriate.</p></li>
<li><p>For this reason (and in lots of other situations) we may need to use a different formula to calculate the standard error, which acknowledges that both sample proportions are estimated from a common sample.</p></li>
</ul>
<p>In our example, it is possible that the proportions of locations where birds were detected in each phase are not independent because the two phases are likely to ‘share’ animals. Similarly, the locations within each phase may not be independent, in that if there are birds in one location, birds may be more likely to be in nearby locations.</p>
<hr />
<div id="choosing-the-appropriate-standard-error-when-comparing-proportions" class="section level3" number="11.4.1">
<h3><span class="header-section-number">11.4.1</span> Choosing the appropriate standard error when comparing proportions</h3>
<p>When comparing proportions difference sorts of sampling situations can arise. This means that different standard errors should be used. The sampling situations we consider here are:</p>
<ul>
<li><p>Situation A - the proportions originate from independent samples.</p></li>
<li><p>Situation B - the same sample gives rise to two (or more) proportions where the same individual can only choose one of the options (or can only contribute to ONE of the proportions being considered).</p></li>
<li><p>Situation C - the same sample but an individual can choose more than one category (or can contribute to BOTH of the proportions being considered).</p></li>
</ul>
<div id="situation-a-proportions-from-independent-samples" class="section level4" number="11.4.1.1">
<h4><span class="header-section-number">11.4.1.1</span> Situation A: Proportions from independent samples</h4>
<p><strong>Example</strong> A random sample of 1000 people born in New Zealand is compared to a random sample of 1000 people born in Scotland, e.g. a respondent can’t belong to both populations.</p>
<p><span class="math display">\[se(p_1-p_2) = \sqrt{\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2}}\]</span></p>
</div>
<div id="situation-b-one-sample-of-size-n-several-response-categories" class="section level4" number="11.4.1.2">
<h4><span class="header-section-number">11.4.1.2</span> Situation B: One sample of size <span class="math inline">\(n\)</span>, several response categories</h4>
<p><strong>Example</strong> A random sample of Scots are asked who they are going to vote for in the next election, e.g. one group of respondents slot into only ONE category and the proportions add to 1.</p>
<p><span class="math display">\[se(p_1-p_2) =\sqrt{\frac{p_1+ p_2-(p_1-p_2)^2}{n}}\]</span></p>
</div>
<div id="situation-c-one-sample-of-size-n-many-yesno-items" class="section level4" number="11.4.1.3">
<h4><span class="header-section-number">11.4.1.3</span> Situation C: One sample of size <span class="math inline">\(n\)</span>, many “Yes/No” items</h4>
<p><strong>Example</strong> A random sample of Scots are asked:
1. Do you watch rugby?
2. Do you like beer?
3. Do you like licorice?
e.g. one group of respondents can slot into MORE THAN ONE category.</p>
<p><span class="math display">\[se(p_1-p_2) = \sqrt{\frac{Min(p_1 + p_2,  q_1 + q_2)-(p_1-p_2)^2}{n}}\]</span></p>
<p>where <span class="math inline">\(q_1 = 1-p_1\)</span> and <span class="math inline">\(q_2 = 1-p_2\)</span> and <span class="math inline">\(Min(a, b)\)</span> denotes selecting the minimum from <span class="math inline">\(a\)</span> or <span class="math inline">\(b\)</span>.</p>
<p>The following graphics from Wild &amp; Seber<span class="citation">(<a href="#ref-wildgaf" role="doc-biblioref">1999</a>)</span> may help visualise these situations.</p>
</div>
<div id="choosing-different-standard-errors" class="section level4" number="11.4.1.4">
<h4><span class="header-section-number">11.4.1.4</span> Choosing different standard errors</h4>
<p>As an illustration of which standard error to choose, we consider the data from an international study carried out in 1998. The study was designed to measure people’s reactions to their health care system. A summary of the results are shown in Table <a href="proportions.html#tab:choosingsamplesit">11.5</a>:</p>
<caption>
<span id="tab:choosingsamplesit">Table 11.5: </span> esults from a 1998 study which surveyed 1000 people each from 5 countries
about their health care system. Table entry is the percentage (%) agreeing to the statement.
</caption>
<table>
<thead>
<tr class="header">
<th align="center">Statement</th>
<th align="center">Australia</th>
<th align="center">Canada</th>
<th align="center">N.Z.</th>
<th align="center">U.K.</th>
<th align="center">U.S.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Difficulties getting needed care</td>
<td align="center">15</td>
<td align="center">20</td>
<td align="center">18</td>
<td align="center">15</td>
<td align="center">28</td>
</tr>
<tr class="even">
<td align="center">Recent changes will harm quality</td>
<td align="center">28</td>
<td align="center">46</td>
<td align="center">38</td>
<td align="center">12</td>
<td align="center">18</td>
</tr>
<tr class="odd">
<td align="center">System should be rebuilt</td>
<td align="center">30</td>
<td align="center">23</td>
<td align="center">32</td>
<td align="center">14</td>
<td align="center">33</td>
</tr>
<tr class="even">
<td align="center">No bills not covered by insurance</td>
<td align="center">7</td>
<td align="center">27</td>
<td align="center">12</td>
<td align="center">44</td>
<td align="center">8</td>
</tr>
<tr class="odd">
<td align="center">Sample size</td>
<td align="center">1000</td>
<td align="center">1000</td>
<td align="center">1000</td>
<td align="center">1000</td>
<td align="center">1000</td>
</tr>
<tr class="even">
<td align="center">Health care expenditure (USD per person)</td>
<td align="center">1805</td>
<td align="center">2095</td>
<td align="center">1352</td>
<td align="center">1347</td>
<td align="center">4090</td>
</tr>
</tbody>
</table>
<p><strong>1.</strong> We want to compare the 30% of Australians agreeing to the “System should be rebuilt” with the 23% of Canadians agreeing to the same statement; which sampling situation is appropriate, A, B or C?</p>
<ul>
<li><p><strong>Situation A</strong> is appropriate; we have two independent samples of people from different countries.</p></li>
<li><p>Using the percentages, the proportions of interest are <span class="math inline">\(\hat p_1 = \frac{300}{1000} = 0.3\)</span>; <span class="math inline">\(\hat p_2 = \frac{230}{1000} = 0.23\)</span></p></li>
<li><p>The standard error for the difference between these proportions is obtained using the formula</p></li>
</ul>
<p><span class="math display">\[se(p_1-p_2) = \sqrt{\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2}}\]</span>
<span class="math display">\[se(\hat p_1-\hat p_2) = \sqrt{\frac{0.30(1-0.30)}{1000}+\frac{0.23(1-0.23)}{1000}}=0.0197\]</span></p>
<p><strong>2.</strong> The respondents could choose: ‘agree’ ‘disagree’ or ‘don’t know’ to the statements in the table above. If we compared the proportion of Canadians who agreed “Recent changes will harm quality” with those Canadians who disagreed with that statement (which was 15%), which sampling situation applies A, B or C?</p>
<ul>
<li><p><strong>Situation B</strong> is appropriate. We have one sample of Canadians who either agree or disagree (or don’t know) with this statement.</p></li>
<li><p><span class="math inline">\(\hat p_1 = \frac{460}{1000} = 0.46\)</span>; <span class="math inline">\(\hat p_2 = 0.15\)</span></p></li>
<li><p>The standard error for the difference between these proportions is obtained using the formula</p></li>
</ul>
<p><span class="math display">\[se(p_1-p_2) =\sqrt{\frac{p_1+ p_2-(p_1-p_2)^2}{n}}\]</span></p>
<p><span class="math display">\[se(\hat p_1-\hat p_2) =\sqrt{\frac{0.46+ 0.15-(0.46-0.15)^2}{1000}}=0.022\]</span></p>
<p><strong>3.</strong> If we wanted to compare the proportion of people in the U.K. agreeing to “Difficulties getting needed care” and agreeing to “System should be rebuilt” what sampling situation would apply, A, B or C?</p>
<ul>
<li><p><strong>Situation C</strong> is appropriate. The same set of people are being asked (we have one sample) and they can agree with both these statements.</p></li>
<li><p><span class="math inline">\(\hat p_1 = \frac{15}{100} = 0.15\)</span>; <span class="math inline">\(\hat p_2 = \frac{14}{100} = 0.14\)</span></p></li>
<li><p>The standard error for the difference between these proportions is obtained using the formula</p></li>
</ul>
<p><span class="math display">\[se(p_1-p_2) = \sqrt{\frac{Min(p_1 + p_2, q_1 + q_2)-(p_1-p_2)^2}{n}}\]</span></p>
<ul>
<li><span class="math inline">\(\hat q_1 = 1 - \hat p_1 = 1 - 0.15 = 0.85\)</span>; <span class="math inline">\(\hat q_2 = 1 - \hat p_2 = 0.86\)</span></li>
</ul>
<p><span class="math display">\[se(p_1-p_2) = \sqrt{\frac{Min(0.15 + 0.14, 0.85 + 0.86)-(0.15-0.14)^2}{1000}}\]</span>
<span class="math display">\[se(p_1-p_2) = \sqrt{\frac{Min(0.29, 1.71)-(0.15-0.14)^2}{1000}}\]</span></p>
<p><span class="math display">\[= \sqrt{\frac{0.29 - (0.15-0.14)^2}{1000}} = 0.017 \]</span></p>
<p>An example of the differences between the confidence intervals calculated using the different standard error formulae for situations (A, B or C) can be seen below.</p>
<p><strong>Q11.2</strong> A survey was undertaken to ascertain the favourite film genre of undergraduates from the University of St Andrews (and only one genre could be chosen). The results were as follows: romantic comedies 13%, musicals 8%, science-fiction/fantasy 22%, romance 27%, westerns 5%, war 8%, horror 9%, other 8%. What sampling situation (i.e. A-C) best reflects this situation?</p>
<p><strong>Q11.3</strong> If, from the same survey, the proportion of first year students who like romantic comedies is compared to the proportion of second year students who like romantic comedies, what sampling situation is this?</p>
<p><strong>Q11.4</strong> If, instead of being asked to choose one favourite genre, the students can choose a number of genre they enjoy from a list, which may lead to, for example, 53% of students who said they liked romantic comedies etc. What sampling situation would this be?</p>
</div>
</div>
</div>
<div id="odds-ratios" class="section level2" number="11.5">
<h2><span class="header-section-number">11.5</span> Odds ratios</h2>
<p>In this section we calculate an odds ratio (OR) to quantify the extent of the association between two groups. An odds ratio is a relative measure of effect, which allows, for example, the comparison of an intervention group of a study relative to a control, or placebo, group. Therefore they are most often used in medicine to identify potential causes of disease or ascertain the effect of a treatment.</p>
<p>We need first to define what are meant by statistical odds.</p>
<p>Note: Statistical odds are not quite the same as betting odds. Betting odds are the probability of an event taking place which allow the prospective winnings to be calculated if the event happens. Statistical odds express relative probabilities.</p>
<div id="calculating-the-odds-of-success" class="section level3" number="11.5.1">
<h3><span class="header-section-number">11.5.1</span> Calculating the odds of success</h3>
<p>The <strong>odds of success</strong> are defined to be:</p>
<p><span class="math display">\[odds=\frac{p(\textrm{success})}{p(\textrm{failure})} = \frac{p}{1-p}\]</span></p>
<p>Hence, if <span class="math inline">\(p=0.8\)</span>, the odds of success are</p>
<p><span class="math display">\[odds=\frac{p}{1-p}=\frac{0.8}{1-0.8}=\frac{0.8}{0.2}=4\]</span></p>
<p>A few points to note about odds:</p>
<ul>
<li>Odds are never negative.</li>
<li>When the odds are greater than 1, then success is more likely than failure.</li>
<li>When the odds of success=4 (for example), success is four times as likely as a failure; we expect 4 successes for every one failure.</li>
<li>When the odds of success is <span class="math inline">\(\frac{1}{4}=0.25\)</span>, failure is four times as likely as a success; we expect to see one success for every 4 failures.</li>
</ul>
<p>Note: Statistical odds are not quite the same as betting odds. Betting odds are the probability of an event taking place which allow the prospective winnings to be calculated if the event happens. Statistical odds express relative probabilities.</p>
<p>We can rearrange the formula above to obtain the probability of success from the odds:</p>
<p><span class="math display">\[p=\frac{\textrm{odds}}{\textrm{odds+1}}\]</span>
and so if the odds is 4, then</p>
<p><span class="math display">\[p=\frac{4}{(4+1)}=\frac{4}{5}=0.8\]</span>.</p>
</div>
<div id="calculating-the-odds-of-success-for-2-x-2-tables" class="section level3" number="11.5.2">
<h3><span class="header-section-number">11.5.2</span> Calculating the odds of success for 2 x 2 tables</h3>
<p>In the wind farm example we are interested in comparing the odds of detecting at least one bird at a location in phase A compared with phase C. To calculate the odds of success in each of phase A and phase C we</p>
<ul>
<li><p>view the data as a 2 x 2 table, and</p></li>
<li><p>calculate the odds of success for each row of this table.</p></li>
</ul>
<table style="width:46%;">
<colgroup>
<col width="13%" />
<col width="11%" />
<col width="9%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">Sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>A</strong></td>
<td align="center">10335</td>
<td align="center">1143</td>
<td align="center">11478</td>
</tr>
<tr class="even">
<td align="center"><strong>C</strong></td>
<td align="center">5436</td>
<td align="center">460</td>
<td align="center">5896</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sum</strong></td>
<td align="center">15771</td>
<td align="center">1603</td>
<td align="center">17374</td>
</tr>
</tbody>
</table>
<p>For the phase A (first row) we start by finding the sighting probability:<br />
<span class="math display">\[\hat p_A=\frac{1143}{1.1478\times 10^{4}}=0.1\]</span></p>
<p>and from there we can find the odds of success:</p>
<p><span class="math display">\[\textrm{odds}_A =\frac{\hat p_A}{(1-\hat p_A)}=\frac{0.1}{(1 - 0.1)}= 0.111\]</span></p>
<p>The odds for phase A are less than 1 which means that the probability of detecting a bird is much lower than the probability of not detecting a bird:</p>
<ul>
<li>failure (absence) is more likely than success (presence).</li>
</ul>
<p>We perform the same calculations for phase C. The probability of a bird is:</p>
<p><span class="math display">\[\hat p_C=\frac{460}{5896}=0.078\]</span></p>
<p>The odds of success is:</p>
<p><span class="math display">\[\textrm{odds}_C = \frac{\hat p_C}{(1-\hat p_C)}= 0.084621\]</span></p>
<p>The odds for phase C are also less than 1 which means that the probability of bird presence is much lower than the probability of bird absence.</p>
<ul>
<li>failure (absence) is more likely than success (failure).</li>
</ul>
</div>
<div id="calculating-the-odds-ratio" class="section level3" number="11.5.3">
<h3><span class="header-section-number">11.5.3</span> Calculating the odds ratio</h3>
<p>The the relevant odds known, the odds ratio can then be calculated:</p>
<ul>
<li><p>the numerator is the odds in the intervention arm/group 1</p></li>
<li><p>the denominator is the odds in the control arm/group 2</p></li>
</ul>
<p>If the <strong>outcome is the same</strong> in both groups, the <strong>ratio will be 1</strong>: this implies there is no difference between the two arms (groups) of the study.</p>
<p>However:</p>
<ul>
<li><p>if the OR is <span class="math inline">\(&gt; 1\)</span> the intervention is better than the control.</p></li>
<li><p>if the OR is <span class="math inline">\(&lt; 1\)</span> the control is better than the intervention.</p></li>
</ul>
<p>For example, in the wind farm data, the two groups could be the presence (or absence) of animals seen A and C the wind farm development.</p>
<p>So in the medical study of TEON, we might be interested in the presence, or absence, of blindness in people who are either Vitamin D deficient or have acceptable Vitamin D levels.</p>
<p>Whatever the situation, we must calculate the <strong>odds of success</strong> for each of the two groups.</p>
<p>We can find the ratio of these two values (a so-called <strong>odds ratio</strong>).</p>
<ul>
<li>We do this following the procedure stated earlier, the ‘intervention’ is the numerator:</li>
</ul>
<p><span class="math display">\[\theta=\frac{\text{odds}_C}{\text{odds}_A}=\frac{\hat{p}_C/(1-\hat{p}_C)}{\hat{p}_A/(1-\hat{p}_A)}=\frac{(460 / 5896) / (1-(460/ 5896))}{(1143 / 1.1478\times 10^{4}) / (1-(1143 / 1.1478\times 10^{4})}= 0.085/ 0.111= 0.765\]</span></p>
<p>Remember:</p>
<ul>
<li><p>If the OR is <span class="math inline">\(&gt; 1\)</span> the intervention is better than the control.</p></li>
<li><p>If the OR is <span class="math inline">\(&lt; 1\)</span> the control is better than the intervention.</p></li>
</ul>
<p>In our example, the OR is <span class="math inline">\(&lt;1\)</span> so the odds of seeing something in phase C (intervention group) is lower than the odds of seeing something in phase A (control group) as this ratio is less than 1.</p>
<ul>
<li>If the reverse was true, the odds ratio (<span class="math inline">\(\theta\)</span>) would be greater than 1 but can never be zero or negative.</li>
</ul>
</div>
<div id="confidence-intervals-for-odds-ratios" class="section level3" number="11.5.4">
<h3><span class="header-section-number">11.5.4</span> Confidence intervals for odds ratios</h3>
<p>While the odds ratio calculated above is based on our sample estimates for the two proportions, and thus constitutes our `best guess’ for the odds ratio (<span class="math inline">\(\hat{\theta}\)</span>), this value will change from survey to survey and so it is often useful to construct a 95% confidence interval for the odds ratio.</p>
<p>Previously we have used the normal and <span class="math inline">\(t\)</span>-distributions to construct confidence intervals, however, these are poor choices to use for confidence intervals based around the odds ratio because, unless the sample size is large, the sampling distribution for the odds ratio (<span class="math inline">\(\theta\)</span>) is highly skewed.</p>
<ul>
<li><p>For example, even if the true, and unknown, odds ratio is 1 the estimate cannot be much smaller (since it can never be zero or negative) but it can often be much higher just due to chance.</p></li>
<li><p>This means the estimates are not guaranteed to be symmetrically distributed about the true odds ratio.</p></li>
</ul>
<!--\begin{figure}[htbp]
\centering
\includegraphics[width=4in]{screenshots/L24shinypic1.png}
\includegraphics[width=4in]{screenshots/L24shinypic2.png}
\caption{Odds ratios in action\label{L24shinypic}}
\end{figure} -->
<p>For this reason, the <strong>log of the odds ratio</strong> is used as the centre of the associated confidence intervals since these estimates tend to be more symmetrical.</p>
<p>Specifically, the log of the odds ratio estimates tend to be approximately normal with a mean of <span class="math inline">\(\log(\theta)\)</span> and a <strong>standard error</strong> of:</p>
<p><span class="math display">\[se_{OR}=\sqrt{\frac{1}{n_{11}}+\frac{1}{n_{12}}+\frac{1}{n_{21}}+\frac{1}{n_{22}}}\]</span></p>
<p>where <span class="math inline">\(n_{11}...n_{22}\)</span> are based on the number of observations in each group/outcome category.</p>
<p>We can construct the 95% confidence interval for <span class="math inline">\(\log\theta\)</span> using the estimate for <span class="math inline">\(\log\hat{\theta}\)</span>. We can then get values back on the raw odds ratio scale by ‘undoing’ this log function using the exponential function.</p>
<ul>
<li><p>For example, if we apply the log function to the value of 2 we get: log(2)=0.693</p></li>
<li><p>and we can undo this function by applying the exponential function: exp(0.693)=2.</p></li>
</ul>
<p>A large-sample, <strong>confidence interval for log of the odds ratio</strong> can be found using:</p>
<p><span class="math display">\[\log(\hat{\theta}) \pm z_{1-\alpha/2} \times se_{OR}\]</span></p>
<p>we can then exponentiate the upper and lower limits of this interval to obtain a confidence interval for the odds ratio.</p>
<p><strong>Example</strong> Back to our wind farm example, entries from the centre of the following table provide the numbers of observations, <span class="math inline">\(n_{11}\)</span> etc.:</p>
<table style="width:46%;">
<colgroup>
<col width="13%" />
<col width="11%" />
<col width="9%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">Sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>A</strong></td>
<td align="center">10335</td>
<td align="center">1143</td>
<td align="center">11478</td>
</tr>
<tr class="even">
<td align="center"><strong>C</strong></td>
<td align="center">5436</td>
<td align="center">460</td>
<td align="center">5896</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sum</strong></td>
<td align="center">15771</td>
<td align="center">1603</td>
<td align="center">17374</td>
</tr>
</tbody>
</table>
<p>So in this case, comparing phases A and C means these values are:</p>
<ul>
<li>the value for row 1 of interest in the table and in column 1: <span class="math inline">\(n_{11}=10335\)</span></li>
<li>the value for row 1 of interest in the table and in column 2: <span class="math inline">\(n_{12}=1143\)</span></li>
<li>the value for row 2 of interest in the table and in column 1: <span class="math inline">\(n_{21}=5436\)</span></li>
<li>the value for row 2 of interest in the table and in column 2: <span class="math inline">\(n_{21}=460\)</span></li>
</ul>
<p>Therefore, the standard error of the odds ratio is:</p>
<p><span class="math display">\[se_{OR}=\sqrt{\frac{1}{1.0335\times 10^{4}}+\frac{1}{1143}+\frac{1}{5436}+\frac{1}{460}}=0.058\]</span></p>
<ul>
<li>As is typical, the standard error decreases as the cell counts increase. For instance, if all cell entries were 10,000 the new <span class="math inline">\(se_{OR}\)</span> would be just 0.02.</li>
</ul>
<p>In our example, the estimated odds ratio is: 0.765 and we are interested in whether this could be a 1:1 ratio and therefore even odds.
A 95% confidence interval for this ratio is:</p>
<p><span class="math display">\[\log(0.765) \pm 1.960 \times 0.058\]</span></p>
<p>which returns a lower limit of -0.381 and an upper limit of -0.155.</p>
<p>These upper and lower limits are exponentiated:</p>
<p><span class="math display">\[\big(\text{exp}(-0.381),  \text{exp}(-0.155)\big)\]</span>
to give</p>
<ul>
<li><p>This result tells us that an odds ratio value of 1 is not a plausible value for the odds and so the odds in phase A appear to be genuinely higher than in phase C.</p></li>
<li><p>Additionally, with 95% confidence we estimate the odds of presence of a bird in phase A compared with phase C appears to be somewhere between 0.683 and 0.857.</p></li>
</ul>
<div id="doing-this-in-r-21" class="section level4" number="11.5.4.1">
<h4><span class="header-section-number">11.5.4.1</span> Doing this in R</h4>
<p>The package <code>epitools</code> - epidemiology tools <span class="citation">(<a href="#ref-R-epitools" role="doc-biblioref">Aragon 2020</a>)</span> is used for calculating odds ratios.</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="proportions.html#cb246-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create object containing the number of successes (presence) and failures (absence)</span></span>
<span id="cb246-2"><a href="proportions.html#cb246-2" aria-hidden="true" tabindex="-1"></a>counts <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1143</span>, <span class="dv">10335</span>, <span class="dv">460</span>, <span class="dv">5436</span>)</span>
<span id="cb246-3"><a href="proportions.html#cb246-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to a matrix</span></span>
<span id="cb246-4"><a href="proportions.html#cb246-4" aria-hidden="true" tabindex="-1"></a>matcounts <span class="ot">&lt;-</span> <span class="fu">matrix</span>(counts, <span class="at">nrow=</span><span class="dv">2</span>, <span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb246-5"><a href="proportions.html#cb246-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Add row and column names</span></span>
<span id="cb246-6"><a href="proportions.html#cb246-6" aria-hidden="true" tabindex="-1"></a><span class="fu">dimnames</span>(matcounts) <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="st">&quot;Phase&quot;</span><span class="ot">=</span><span class="fu">c</span>(<span class="st">&quot;A&quot;</span>,<span class="st">&quot;C&quot;</span>), <span class="st">&quot;AnimalsSeen&quot;</span><span class="ot">=</span><span class="fu">c</span>(<span class="st">&quot;Presence&quot;</span>,<span class="st">&quot;Absence&quot;</span>))</span>
<span id="cb246-7"><a href="proportions.html#cb246-7" aria-hidden="true" tabindex="-1"></a>matcounts</span></code></pre></div>
<pre><code>     AnimalsSeen
Phase Presence Absence
    A     1143   10335
    C      460    5436</code></pre>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="proportions.html#cb248-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load package</span></span>
<span id="cb248-2"><a href="proportions.html#cb248-2" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(epitools)</span>
<span id="cb248-3"><a href="proportions.html#cb248-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Odds ratio and CI</span></span>
<span id="cb248-4"><a href="proportions.html#cb248-4" aria-hidden="true" tabindex="-1"></a>OR <span class="ot">&lt;-</span> <span class="fu">oddsratio</span>(matcounts, <span class="at">method=</span><span class="st">&#39;wald&#39;</span>, <span class="at">rev=</span><span class="st">&#39;rows&#39;</span>)</span>
<span id="cb248-5"><a href="proportions.html#cb248-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print out odds ratio and CI</span></span>
<span id="cb248-6"><a href="proportions.html#cb248-6" aria-hidden="true" tabindex="-1"></a>OR<span class="sc">$</span>measure</span></code></pre></div>
<pre><code>     odds ratio with 95% C.I.
Phase estimate     lower    upper
    C 1.000000        NA       NA
    A 0.765143 0.6833239 0.856759</code></pre>
<ul>
<li><p><code>rev='rows'</code> reverses the rows in the data object because we want the odds ratio to be odds<span class="math inline">\(_C\)</span>/odds<span class="math inline">\(_A\)</span>.</p></li>
<li><p><code>method='wald'</code> there are several method for calculating CI. Wald’s method uses the normal approximation as described above.</p></li>
</ul>
</div>
</div>
<div id="final-note-on-odds-ratios" class="section level3" number="11.5.5">
<h3><span class="header-section-number">11.5.5</span> Final note on odds ratios</h3>
<p>The survey example given above would not typically be analysed using odds ratios in real life. Odds ratios are typically employed in case control studies where a typically (rare) disease is being investigated. These studies tend to be retrospective in that ‘cases’ are found (with the disease) and then ‘controls’ and the initial circumstances of the cases and controls are compared<span class="citation">(<a href="#ref-Lewallen&amp;Courtright1998" role="doc-biblioref">Lewallen and Courtright 1998</a>)</span>. Controls are created such that they are matched, in some way, to cases, for example by age, sex, smoker etc. The matching factor is not the variable of interest; if it is, it should not be used as a matching criterion.</p>
<p><strong>Example</strong> A mixed sex group (40 male, 40 female) of patients with a disease X are documented. Another 40 control (without the disease) individuals are matched for age and sex. The numbers with known exposure to, for example, asbestos in each group is determined (see table below).</p>
<table style="width:65%;">
<colgroup>
<col width="25%" />
<col width="13%" />
<col width="18%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Disease</th>
<th align="center">No disease</th>
<th align="center">Sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Asbestos</strong></td>
<td align="center">31</td>
<td align="center">1</td>
<td align="center">32</td>
</tr>
<tr class="even">
<td align="center"><strong>No asbestos</strong></td>
<td align="center">9</td>
<td align="center">39</td>
<td align="center">48</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sum</strong></td>
<td align="center">40</td>
<td align="center">40</td>
<td align="center">80</td>
</tr>
</tbody>
</table>
<p>Hence the proportions with and without exposure to asbestos in each group can be obtained.</p>
<p><span class="math display">\[Pr(\textrm{Asbestos|Disease}) = \frac{31}{40}  = 0.775\]</span>
<span class="math display">\[Pr(\textrm{Asbestos|No disease}) = \frac{1}{40} = 0.025\]</span><br />
<span class="math display">\[Pr(\textrm{No Asbestos|Disease}) = \frac{9}{40} = 0.225\]</span><br />
<span class="math display">\[Pr(\textrm{No Asbestos|No disease}) = \frac{39}{40} = 0.975\]</span></p>
<p>Therefore, the odds of exposure to asbestos for the disease group are:</p>
<p><span class="math display">\[\textrm{Odds}_{\textrm{Disease}} = \frac{Pr(\textrm{Asbestos|Disease})}{Pr(\textrm{Asbestos|No disease})} = \frac{0.775}{0.225} =  3.444\]</span></p>
<p>and for the control group:</p>
<p><span class="math display">\[\textrm{Odds}_{\textrm{No disease}} = \frac{0.025}{0.975} = 0.026\]</span></p>
<p>Hence, the odds ratio is</p>
<p><span class="math display">\[\textrm{Odds ratio} = \frac{3.444}{0.026} = 134.333\]</span></p>
<p>Confidence intervals can be created as before:
<span class="math display">\[\log(134.333)\pm 1.959964 \times \sqrt{\frac{1}{31}+\frac{1}{1}+\frac{1}{9}+\frac{1}{39}}\]</span></p>
<p><span class="math display">\[4.9 \pm  1.959964 \times 1.081\]</span></p>
<p>resulting in values of 2.7812 and 7.0195 which, exponentiated, gives a 95% confidence interval of (16.1, 1118.2) - clear evidence of an association between asbestos and the disease.</p>
<p>These calculations can easily be done in R.</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="proportions.html#cb250-1" aria-hidden="true" tabindex="-1"></a>matrixasbestos <span class="ot">&lt;-</span> <span class="fu">matrix</span> (<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">31</span>,<span class="dv">39</span>,<span class="dv">9</span>), <span class="at">nrow=</span><span class="dv">2</span>, <span class="at">ncol=</span><span class="dv">2</span>, <span class="at">byrow=</span>T) <span class="do">###note order changed of variables</span></span>
<span id="cb250-2"><a href="proportions.html#cb250-2" aria-hidden="true" tabindex="-1"></a>OR <span class="ot">&lt;-</span> <span class="fu">oddsratio</span>(matrixasbestos, <span class="at">method=</span><span class="st">&#39;wald&#39;</span>, <span class="at">rev=</span><span class="st">&#39;rows&#39;</span>)</span>
<span id="cb250-3"><a href="proportions.html#cb250-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Print out odds ratio and CI</span></span>
<span id="cb250-4"><a href="proportions.html#cb250-4" aria-hidden="true" tabindex="-1"></a>OR<span class="sc">$</span>measure</span></code></pre></div>
<pre><code>          odds ratio with 95% C.I.
Predictor  estimate    lower    upper
  Exposed2   1.0000       NA       NA
  Exposed1 134.3333 16.13831 1118.174</code></pre>
<p><strong>Q11.5</strong> Imagine a case-control study looking at the relationship between male pattern baldness and prostate cancer: 101 males with prostate cancer were assessed for the presence or absence of substantial male pattern baldness; 49 were assessed as bald. The control group (n = 98) did not have cancer and 80 were characterised as bald. The question of interest here, is whether baldness predicts prostate cancer? Note that this is NOT an independent sample of counts because the two groups (cancer or no cancer) have been matched in some way (possibly age for example).</p>
<table style="width:57%;">
<colgroup>
<col width="19%" />
<col width="12%" />
<col width="16%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Cancer</th>
<th align="center">No cancer</th>
<th align="center">Sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Bald</strong></td>
<td align="center">49</td>
<td align="center">80</td>
<td align="center">129</td>
</tr>
<tr class="even">
<td align="center"><strong>No bald</strong></td>
<td align="center">52</td>
<td align="center">18</td>
<td align="center">70</td>
</tr>
<tr class="odd">
<td align="center"><strong>Sum</strong></td>
<td align="center">101</td>
<td align="center">98</td>
<td align="center">199</td>
</tr>
</tbody>
</table>
<p>Using the above table, calculate the probability of being bald given cancer (i.e. Pr(bald|cancer) and the probability of being bald given no cancer.</p>
<p><strong>Q11.6</strong> What about the probability of cancer given baldness and the probability of cancer given no baldness? Is it legitimate to compare these proportions? Hint: think about the independence of individuals within the groups being compared.</p>
<p><strong>Q11.7</strong> What method (direct comparison of proportions or odds ratios) would you use to analyse these data and why?</p>
</div>
</div>
<div id="SUMprop" class="section level2" number="11.6">
<h2><span class="header-section-number">11.6</span> Summary</h2>
<p>Proportions are often incorrectly treated in the scientific literature so it is useful to know how to handle such statistics. There are other ways to handle cross classified count data. One of which we will consider in the material on <span class="math inline">\(\chi^{2}\)</span> test.</p>
<div id="learning-outcomes-7" class="section level3" number="11.6.1">
<h3><span class="header-section-number">11.6.1</span> Learning outcomes</h3>
<p>At the end of this chapter you should be able to<br />
1) recognise that a problem involves proportions,<br />
2) construct an appropriate confidence interval for a proportion and a difference between proportions,<br />
3) construct a significance test testing the difference between proportions, and
4) have a basic understanding of odds ratios.</p>
</div>
</div>
<div id="ANSprop" class="section level2" number="11.7">
<h2><span class="header-section-number">11.7</span> Answers</h2>
<p><strong>Q11.1</strong> There are certainly two outcomes for each trial (seen or not seen). Within a phase we can assume there is the same probability of success. There are fixed number of trials (sampling localities) but they may not be independent as sampling locations close to each other may have similar characteristics.</p>
<p><strong>Q11.2</strong> This is sampling situation B, one sample with several mutually exclusive categories, i.e. there is one sample of students and they chose one from many categories of films.</p>
<p><strong>Q11.3</strong> This is sampling situation A, two independent samples; one of first years and the other second years.</p>
<p><strong>Q11.4</strong> This is sampling situation C, one sample with many ‘yes/no’ items, i.e. there is one sample of students and for each film genre listed, they indicate whether they enjoy the genre or not.</p>
<p><strong>Q11.5</strong> The <span class="math inline">\(Pr(\textrm{Bald|Cancer})\)</span> = 49/101 and <span class="math inline">\(Pr(\textrm{Bald|No Cancer})\)</span> = 80/98 (although presumably no one is too concerned about male pattern baldness given a diagnosis of cancer!).</p>
<p><strong>Q11.6</strong> The <span class="math inline">\(Pr(\textrm{Cancer|Bald})\)</span> = 49/129 and <span class="math inline">\(Pr(\textrm{Cancer|Not bald})\)</span> = 52/70 are the statistics of interest. In the previous question the two groups being compared were ‘Cancer’ and ‘No cancer’; individuals were allocated to each of these groups based on their prognosis. In this question, the two groups being compared are ‘Bald’ and ‘Not bald.’ The two proportions cannot be legitimately compared because individuals within the two groups have been matched in some way; for example, there are 129 subjects classed as bald, but this group consists of subjects (with and without cancer) and these individuals have been matched in some way (i.e. they have similar characteristics) and are therefore not independent.</p>
<p><strong>Q11.7</strong> The control group does not reflect the occurrence of cancer in the general population (because they have been chosen by virtue of not having cancer) and so there would be no value in directly comparing the probabilities anyway. However, the odds ratio does allow us to explore the relative odds of getting cancer.</p>

<!-- LB update - 04/08/2020 -->
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Agresti1998" class="csl-entry">
Agresti, A., and B. A. Coull. 1998. <span>“Approximate Is Better Than "Exact" for Interval Estimation of Binomial Proportions.”</span> <em>The American Statistician</em> 52(2): 119–26. <a href="https://www.theguardian.com/society/2005/jun/24/NHS.uknews1">https://www.theguardian.com/society/2005/jun/24/NHS.uknews1</a>.
</div>
<div id="ref-R-epitools" class="csl-entry">
Aragon, Tomas J. 2020. <em>Epitools: Epidemiology Tools</em>. <a href="https://CRAN.R-project.org/package=epitools">https://CRAN.R-project.org/package=epitools</a>.
</div>
<div id="ref-Bacon1696" class="csl-entry">
Bacon, Sir F. 1696. <em>The Essays, or Councils, Civil and Moral</em>. H. Herringman, R. Scot, R. Chiswell, A. Swalle,; R. Bentley.
</div>
<div id="ref-R-Hmisc" class="csl-entry">
Harrell, Frank E, Jr. 2021. <em>Hmisc: Harrell Miscellaneous</em>. <a href="https://CRAN.R-project.org/package=Hmisc">https://CRAN.R-project.org/package=Hmisc</a>.
</div>
<div id="ref-Lewallen&amp;Courtright1998" class="csl-entry">
Lewallen, S., and P. Courtright. 1998. <span>“Epidemiology in Practice: Case-Control Studies.”</span> <em>Community Eye Health</em> 11.28: 57–58.
</div>
<div id="ref-wildgaf" class="csl-entry">
Wild, C. J., and G. A. F. Seber. 1999. <em>Chance Encounters: A First Course in Data Analysis and Inference</em>. Wiley.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="power.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="tableofcounts.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["IntroStats.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

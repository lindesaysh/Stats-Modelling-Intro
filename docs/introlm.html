<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 14 Introduction to the linear model | An Introduction to Statistics</title>
  <meta name="description" content="Chapter 14 Introduction to the linear model | An Introduction to Statistics" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 14 Introduction to the linear model | An Introduction to Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 14 Introduction to the linear model | An Introduction to Statistics" />
  
  
  

<meta name="author" content="Drs C. Paxton, L. Burt, C. Donovan and L. Scott-Hayward" />


<meta name="date" content="2022-01-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="correg.html"/>
<link rel="next" href="modelselection.html"/>
<script src="book_assets/header-attrs-2.11/header-attrs.js"></script>
<script src="book_assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="book_assets/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="book_assets/anchor-sections-1.0.1/anchor-sections.js"></script>
<script language="javascript">
    function toggle(id) {
        var ele = document.getElementById("toggleText" + id);
        var text = document.getElementById("displayText" + id);
        var buttonText = text.innerHTML.replace("Show ", "");
        buttonText = buttonText.replace("Hide ", "");
        if(ele.style.display == "block") {
            ele.style.display = "none";
            text.innerHTML = "Show " + buttonText;
        } else {
            ele.style.display = "block";
            text.innerHTML = "Hide " + buttonText;
        }
    }
</script>

<script language="javascript">
    function openCode(evt, codeName, id) {
        var i, tabcontent, tablinks;
        tabcontent = document.getElementsByClassName("tabcontent" + id);
        for (i = 0; i < tabcontent.length; i++) {
            tabcontent[i].style.display = "none";
        }
        tablinks = document.getElementsByClassName("tablinks" + id);
        for (i = 0; i < tablinks.length; i++) {
            tablinks[i].className = tablinks[i].className.replace(" active", "");
        }
        document.getElementById(codeName).style.display = "block";
        evt.currentTarget.className += " active";
    }
</script>

<script language="javascript">
    function hide(id){
        document.getElementById(id).style.display = "none";
    }
</script>
</script>

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<a href="https://www.st-andrews.ac.uk/mathematics-statistics/"><img src="standard-vertical-black.png" width="180"></a>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#computer-practicals"><i class="fa fa-check"></i>Computer practicals</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introchapt.html"><a href="introchapt.html"><i class="fa fa-check"></i><b>1</b> Thinking About Numbers</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introchapt.html"><a href="introchapt.html#INTintro"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="introchapt.html"><a href="introchapt.html#why-use-statistics"><i class="fa fa-check"></i><b>1.2</b> Why use statistics?</a></li>
<li class="chapter" data-level="1.3" data-path="introchapt.html"><a href="introchapt.html#why-model"><i class="fa fa-check"></i><b>1.3</b> Why model?</a></li>
<li class="chapter" data-level="1.4" data-path="introchapt.html"><a href="introchapt.html#examples-of-statistical-claims"><i class="fa fa-check"></i><b>1.4</b> Examples of statistical claims</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introchapt.html"><a href="introchapt.html#coffee-may-reverse-alzheimers"><i class="fa fa-check"></i><b>1.4.1</b> Coffee ‘may reverse Alzheimer’s’</a></li>
<li class="chapter" data-level="1.4.2" data-path="introchapt.html"><a href="introchapt.html#abundance-of-prized-sturgeon"><i class="fa fa-check"></i><b>1.4.2</b> Abundance of prized sturgeon</a></li>
<li class="chapter" data-level="1.4.3" data-path="introchapt.html"><a href="introchapt.html#extrapolating-sprinting-speed"><i class="fa fa-check"></i><b>1.4.3</b> Extrapolating sprinting speed</a></li>
<li class="chapter" data-level="1.4.4" data-path="introchapt.html"><a href="introchapt.html#mmr-innoculation-and-autism"><i class="fa fa-check"></i><b>1.4.4</b> MMR innoculation and autism</a></li>
<li class="chapter" data-level="1.4.5" data-path="introchapt.html"><a href="introchapt.html#two-sid-deaths-in-same-family"><i class="fa fa-check"></i><b>1.4.5</b> Two SID deaths in same family</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introchapt.html"><a href="introchapt.html#SUMintro"><i class="fa fa-check"></i><b>1.5</b> Summary</a></li>
<li class="chapter" data-level="1.6" data-path="introchapt.html"><a href="introchapt.html#ANSintro"><i class="fa fa-check"></i><b>1.6</b> Answers</a></li>
</ul></li>
<li class="part"><span><b>I Data Collection and Visualisation</b></span></li>
<li class="chapter" data-level="2" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>2</b> Data collection and Sampling</a>
<ul>
<li class="chapter" data-level="2.1" data-path="sampling.html"><a href="sampling.html#INTsamp"><i class="fa fa-check"></i><b>2.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="sampling.html"><a href="sampling.html#terminology"><i class="fa fa-check"></i><b>2.1.1</b> Terminology</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="sampling.html"><a href="sampling.html#what-is-sampling-and-why-do-it"><i class="fa fa-check"></i><b>2.2</b> What is sampling and why do it?</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="sampling.html"><a href="sampling.html#precision-accuracy-and-bias"><i class="fa fa-check"></i><b>2.2.1</b> Precision, accuracy and bias</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="sampling.html"><a href="sampling.html#three-types-of-data-collection"><i class="fa fa-check"></i><b>2.3</b> Three types of data collection</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="sampling.html"><a href="sampling.html#common-but-unwise-data-collection-strategies"><i class="fa fa-check"></i><b>2.3.1</b> Common, but unwise, data collection strategies</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="sampling.html"><a href="sampling.html#simple-sampling-approaches"><i class="fa fa-check"></i><b>2.4</b> Simple sampling approaches</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="sampling.html"><a href="sampling.html#simple-random-sample"><i class="fa fa-check"></i><b>2.4.1</b> Simple random sample</a></li>
<li class="chapter" data-level="2.4.2" data-path="sampling.html"><a href="sampling.html#systematic-samples"><i class="fa fa-check"></i><b>2.4.2</b> Systematic samples</a></li>
<li class="chapter" data-level="2.4.3" data-path="sampling.html"><a href="sampling.html#stratified-random-samples"><i class="fa fa-check"></i><b>2.4.3</b> Stratified random samples</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="sampling.html"><a href="sampling.html#sampling-biases"><i class="fa fa-check"></i><b>2.5</b> Sampling biases</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="sampling.html"><a href="sampling.html#non-sampling-error"><i class="fa fa-check"></i><b>2.5.1</b> Non-sampling error</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="sampling.html"><a href="sampling.html#experiments"><i class="fa fa-check"></i><b>2.6</b> Experiments</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="sampling.html"><a href="sampling.html#randomised-experiments"><i class="fa fa-check"></i><b>2.6.1</b> Randomised experiments</a></li>
<li class="chapter" data-level="2.6.2" data-path="sampling.html"><a href="sampling.html#components-of-an-experimental-design"><i class="fa fa-check"></i><b>2.6.2</b> Components of an experimental design</a></li>
<li class="chapter" data-level="2.6.3" data-path="sampling.html"><a href="sampling.html#controls"><i class="fa fa-check"></i><b>2.6.3</b> Controls</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="sampling.html"><a href="sampling.html#observational-studies"><i class="fa fa-check"></i><b>2.7</b> Observational Studies</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="sampling.html"><a href="sampling.html#types-of-observational-study"><i class="fa fa-check"></i><b>2.7.1</b> Types of observational study</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="sampling.html"><a href="sampling.html#observational-studies-vs-experiments"><i class="fa fa-check"></i><b>2.8</b> Observational studies vs experiments</a></li>
<li class="chapter" data-level="2.9" data-path="sampling.html"><a href="sampling.html#SUMsamp"><i class="fa fa-check"></i><b>2.9</b> Summary</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="sampling.html"><a href="sampling.html#learning-objectives"><i class="fa fa-check"></i><b>2.9.1</b> Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="sampling.html"><a href="sampling.html#ANSsamp"><i class="fa fa-check"></i><b>2.10</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="describedata.html"><a href="describedata.html"><i class="fa fa-check"></i><b>3</b> Describing data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="describedata.html"><a href="describedata.html#INTdata"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="describedata.html"><a href="describedata.html#types-of-data"><i class="fa fa-check"></i><b>3.2</b> Types of data</a></li>
<li class="chapter" data-level="3.3" data-path="describedata.html"><a href="describedata.html#frequency-distributions"><i class="fa fa-check"></i><b>3.3</b> Frequency distributions</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="describedata.html"><a href="describedata.html#doing-this-in-r-2"><i class="fa fa-check"></i><b>3.3.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="describedata.html"><a href="describedata.html#numerical-summaries"><i class="fa fa-check"></i><b>3.4</b> Numerical summaries</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="describedata.html"><a href="describedata.html#population-mean"><i class="fa fa-check"></i><b>3.4.1</b> Population mean</a></li>
<li class="chapter" data-level="3.4.2" data-path="describedata.html"><a href="describedata.html#sample-mean"><i class="fa fa-check"></i><b>3.4.2</b> Sample mean</a></li>
<li class="chapter" data-level="3.4.3" data-path="describedata.html"><a href="describedata.html#sample-median"><i class="fa fa-check"></i><b>3.4.3</b> Sample median</a></li>
<li class="chapter" data-level="3.4.4" data-path="describedata.html"><a href="describedata.html#range"><i class="fa fa-check"></i><b>3.4.4</b> Range</a></li>
<li class="chapter" data-level="3.4.5" data-path="describedata.html"><a href="describedata.html#percentiles"><i class="fa fa-check"></i><b>3.4.5</b> Percentiles</a></li>
<li class="chapter" data-level="3.4.6" data-path="describedata.html"><a href="describedata.html#population-variance"><i class="fa fa-check"></i><b>3.4.6</b> Population variance</a></li>
<li class="chapter" data-level="3.4.7" data-path="describedata.html"><a href="describedata.html#sample-variance-and-standard-deviation"><i class="fa fa-check"></i><b>3.4.7</b> Sample variance and standard deviation</a></li>
<li class="chapter" data-level="3.4.8" data-path="describedata.html"><a href="describedata.html#numerical-summaries-in-r"><i class="fa fa-check"></i><b>3.4.8</b> Numerical summaries in R</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="describedata.html"><a href="describedata.html#visual-summaries"><i class="fa fa-check"></i><b>3.5</b> Visual summaries</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="describedata.html"><a href="describedata.html#bar-charts"><i class="fa fa-check"></i><b>3.5.1</b> Bar charts</a></li>
<li class="chapter" data-level="3.5.2" data-path="describedata.html"><a href="describedata.html#pie-charts"><i class="fa fa-check"></i><b>3.5.2</b> Pie charts</a></li>
<li class="chapter" data-level="3.5.3" data-path="describedata.html"><a href="describedata.html#histograms"><i class="fa fa-check"></i><b>3.5.3</b> Histograms</a></li>
<li class="chapter" data-level="3.5.4" data-path="describedata.html"><a href="describedata.html#boxplots"><i class="fa fa-check"></i><b>3.5.4</b> Boxplots</a></li>
<li class="chapter" data-level="3.5.5" data-path="describedata.html"><a href="describedata.html#basic-plots-in-r"><i class="fa fa-check"></i><b>3.5.5</b> Basic plots in R</a></li>
<li class="chapter" data-level="3.5.6" data-path="describedata.html"><a href="describedata.html#other-plots"><i class="fa fa-check"></i><b>3.5.6</b> Other plots</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="describedata.html"><a href="describedata.html#summarising-the-relationship-between-two-variables"><i class="fa fa-check"></i><b>3.6</b> Summarising the relationship between two variables</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="describedata.html"><a href="describedata.html#cross-tabulation"><i class="fa fa-check"></i><b>3.6.1</b> Cross-tabulation</a></li>
<li class="chapter" data-level="3.6.2" data-path="describedata.html"><a href="describedata.html#side-by-side-boxplots"><i class="fa fa-check"></i><b>3.6.2</b> Side-by-side boxplots</a></li>
<li class="chapter" data-level="3.6.3" data-path="describedata.html"><a href="describedata.html#scatter-plot"><i class="fa fa-check"></i><b>3.6.3</b> Scatter plot</a></li>
<li class="chapter" data-level="3.6.4" data-path="describedata.html"><a href="describedata.html#quilt-plots"><i class="fa fa-check"></i><b>3.6.4</b> Quilt plots</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="describedata.html"><a href="describedata.html#handy-hints-when-including-tables-and-plots-into-reports"><i class="fa fa-check"></i><b>3.7</b> Handy hints when including tables and plots into reports</a></li>
<li class="chapter" data-level="3.8" data-path="describedata.html"><a href="describedata.html#SUMdata"><i class="fa fa-check"></i><b>3.8</b> Summary</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="describedata.html"><a href="describedata.html#learning-outcomes"><i class="fa fa-check"></i><b>3.8.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="describedata.html"><a href="describedata.html#ANSdata"><i class="fa fa-check"></i><b>3.9</b> Answers</a></li>
</ul></li>
<li class="part"><span><b>II Probability and Distributions</b></span></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html#INTprob"><i class="fa fa-check"></i><b>4.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="probability.html"><a href="probability.html#random-phenomena-and-uncertain-outcomes"><i class="fa fa-check"></i><b>4.1.1</b> Random phenomena and uncertain outcomes</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="probability.html"><a href="probability.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>4.2</b> Sample spaces and events</a></li>
<li class="chapter" data-level="4.3" data-path="probability.html"><a href="probability.html#definition-of-probability-and-3-axioms"><i class="fa fa-check"></i><b>4.3</b> Definition of Probability and 3 Axioms</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="probability.html"><a href="probability.html#probability-1"><i class="fa fa-check"></i><b>4.3.1</b> Probability</a></li>
<li class="chapter" data-level="4.3.2" data-path="probability.html"><a href="probability.html#three-axioms"><i class="fa fa-check"></i><b>4.3.2</b> Three Axioms</a></li>
<li class="chapter" data-level="4.3.3" data-path="probability.html"><a href="probability.html#three-results-of-the-axioms"><i class="fa fa-check"></i><b>4.3.3</b> Three results of the Axioms</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="probability.html"><a href="probability.html#independence-and-the-multiplication-rule"><i class="fa fa-check"></i><b>4.4</b> Independence and the Multiplication Rule</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="probability.html"><a href="probability.html#testing-for-independence"><i class="fa fa-check"></i><b>4.4.1</b> Testing for Independence</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="probability.html"><a href="probability.html#conditional-probabilities"><i class="fa fa-check"></i><b>4.5</b> Conditional probabilities</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="probability.html"><a href="probability.html#independence-revisited"><i class="fa fa-check"></i><b>4.5.1</b> Independence revisited</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="probability.html"><a href="probability.html#tree-diagrams"><i class="fa fa-check"></i><b>4.6</b> Tree Diagrams</a></li>
<li class="chapter" data-level="4.7" data-path="probability.html"><a href="probability.html#marginal-and-joint-probabilities"><i class="fa fa-check"></i><b>4.7</b> Marginal and joint probabilities</a></li>
<li class="chapter" data-level="4.8" data-path="probability.html"><a href="probability.html#SUMprob"><i class="fa fa-check"></i><b>4.8</b> Summary</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="probability.html"><a href="probability.html#learning-outcomes-1"><i class="fa fa-check"></i><b>4.8.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="probability.html"><a href="probability.html#ANSprob"><i class="fa fa-check"></i><b>4.9</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discreterv.html"><a href="discreterv.html"><i class="fa fa-check"></i><b>5</b> Discrete random variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discreterv.html"><a href="discreterv.html#INTdiscrv"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="discreterv.html"><a href="discreterv.html#discrete-random-variables"><i class="fa fa-check"></i><b>5.2</b> Discrete random variables</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="discreterv.html"><a href="discreterv.html#probability-mass-function"><i class="fa fa-check"></i><b>5.2.1</b> Probability mass function</a></li>
<li class="chapter" data-level="5.2.2" data-path="discreterv.html"><a href="discreterv.html#cumulative-distribution-function"><i class="fa fa-check"></i><b>5.2.2</b> Cumulative distribution function</a></li>
<li class="chapter" data-level="5.2.3" data-path="discreterv.html"><a href="discreterv.html#expectation"><i class="fa fa-check"></i><b>5.2.3</b> Expectation</a></li>
<li class="chapter" data-level="5.2.4" data-path="discreterv.html"><a href="discreterv.html#variance"><i class="fa fa-check"></i><b>5.2.4</b> Variance</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="discreterv.html"><a href="discreterv.html#special-discrete-distributions"><i class="fa fa-check"></i><b>5.3</b> Special discrete distributions</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="discreterv.html"><a href="discreterv.html#bernoulli-distribution"><i class="fa fa-check"></i><b>5.3.1</b> Bernoulli distribution</a></li>
<li class="chapter" data-level="5.3.2" data-path="discreterv.html"><a href="discreterv.html#binomial-distribution"><i class="fa fa-check"></i><b>5.3.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="5.3.3" data-path="discreterv.html"><a href="discreterv.html#poisdist"><i class="fa fa-check"></i><b>5.3.3</b> Poisson distribution</a></li>
<li class="chapter" data-level="5.3.4" data-path="discreterv.html"><a href="discreterv.html#comparison-of-binomial-and-poisson-distributions"><i class="fa fa-check"></i><b>5.3.4</b> Comparison of binomial and Poisson distributions</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="discreterv.html"><a href="discreterv.html#SUMdiscrv"><i class="fa fa-check"></i><b>5.4</b> Summary</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="discreterv.html"><a href="discreterv.html#learning-outcomes-2"><i class="fa fa-check"></i><b>5.4.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="discreterv.html"><a href="discreterv.html#ANSdiscrv"><i class="fa fa-check"></i><b>5.5</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="contrv.html"><a href="contrv.html"><i class="fa fa-check"></i><b>6</b> Continuous random variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="contrv.html"><a href="contrv.html#INTcontrv"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="contrv.html"><a href="contrv.html#continuous-random-variables"><i class="fa fa-check"></i><b>6.2</b> Continuous random variables</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="contrv.html"><a href="contrv.html#probability-density-function"><i class="fa fa-check"></i><b>6.2.1</b> Probability density function</a></li>
<li class="chapter" data-level="6.2.2" data-path="contrv.html"><a href="contrv.html#cumulative-distribution-function-1"><i class="fa fa-check"></i><b>6.2.2</b> Cumulative distribution function</a></li>
<li class="chapter" data-level="6.2.3" data-path="contrv.html"><a href="contrv.html#expectation-and-variance-1"><i class="fa fa-check"></i><b>6.2.3</b> Expectation and variance</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="contrv.html"><a href="contrv.html#special-continuous-distributions"><i class="fa fa-check"></i><b>6.3</b> Special continuous distributions</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="contrv.html"><a href="contrv.html#normal-distribution"><i class="fa fa-check"></i><b>6.3.1</b> Normal distribution</a></li>
<li class="chapter" data-level="6.3.2" data-path="contrv.html"><a href="contrv.html#standard-normal-distribution"><i class="fa fa-check"></i><b>6.3.2</b> Standard normal distribution</a></li>
<li class="chapter" data-level="6.3.3" data-path="contrv.html"><a href="contrv.html#simple-transformations-of-random-variables"><i class="fa fa-check"></i><b>6.3.3</b> Simple transformations of random variables</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="contrv.html"><a href="contrv.html#SUMcontrv"><i class="fa fa-check"></i><b>6.4</b> Summary</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="contrv.html"><a href="contrv.html#learning-outcomes-3"><i class="fa fa-check"></i><b>6.4.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="contrv.html"><a href="contrv.html#ANScontrv"><i class="fa fa-check"></i><b>6.5</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="CIformean.html"><a href="CIformean.html"><i class="fa fa-check"></i><b>7</b> Confidence intervals for sample means</a>
<ul>
<li class="chapter" data-level="7.1" data-path="CIformean.html"><a href="CIformean.html#INTci"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="CIformean.html"><a href="CIformean.html#uncertainty-of-the-sample-mean"><i class="fa fa-check"></i><b>7.2</b> Uncertainty of the sample mean</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="CIformean.html"><a href="CIformean.html#precision-of-the-sample-mean"><i class="fa fa-check"></i><b>7.2.1</b> Precision of the sample mean</a></li>
<li class="chapter" data-level="7.2.2" data-path="CIformean.html"><a href="CIformean.html#confidence-interval-with-known-sigma"><i class="fa fa-check"></i><b>7.2.2</b> Confidence interval with known <span class="math inline">\(\sigma\)</span></a></li>
<li class="chapter" data-level="7.2.3" data-path="CIformean.html"><a href="CIformean.html#confidence-interval-with-unknown-sigma"><i class="fa fa-check"></i><b>7.2.3</b> Confidence interval with unknown <span class="math inline">\(\sigma\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="CIformean.html"><a href="CIformean.html#difference-between-two-group-means"><i class="fa fa-check"></i><b>7.3</b> Difference between two group means</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="CIformean.html"><a href="CIformean.html#assuming-equal-standard-deviations-of-the-two-groups"><i class="fa fa-check"></i><b>7.3.1</b> Assuming equal standard deviations of the two groups</a></li>
<li class="chapter" data-level="7.3.2" data-path="CIformean.html"><a href="CIformean.html#assuming-unequal-standard-deviations-of-the-two-groups"><i class="fa fa-check"></i><b>7.3.2</b> Assuming unequal standard deviations of the two groups</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="CIformean.html"><a href="CIformean.html#empirical-bootstrap-based-confidence-intervals"><i class="fa fa-check"></i><b>7.4</b> Empirical (bootstrap-based) confidence intervals</a></li>
<li class="chapter" data-level="7.5" data-path="CIformean.html"><a href="CIformean.html#confidence-intervals-for-other-sample-statistics"><i class="fa fa-check"></i><b>7.5</b> Confidence intervals for other sample statistics</a></li>
<li class="chapter" data-level="7.6" data-path="CIformean.html"><a href="CIformean.html#SUMci"><i class="fa fa-check"></i><b>7.6</b> Summary</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="CIformean.html"><a href="CIformean.html#learning-outcomes-4"><i class="fa fa-check"></i><b>7.6.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="CIformean.html"><a href="CIformean.html#ANSci"><i class="fa fa-check"></i><b>7.7</b> Answers</a></li>
</ul></li>
<li class="part"><span><b>III Hypothesis Testing</b></span></li>
<li class="chapter" data-level="8" data-path="hypothtests.html"><a href="hypothtests.html"><i class="fa fa-check"></i><b>8</b> Hypothesis Tests</a>
<ul>
<li class="chapter" data-level="8.1" data-path="hypothtests.html"><a href="hypothtests.html#INThyp"><i class="fa fa-check"></i><b>8.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="hypothtests.html"><a href="hypothtests.html#types-of-hypotheses"><i class="fa fa-check"></i><b>8.1.1</b> Types of hypotheses</a></li>
<li class="chapter" data-level="8.1.2" data-path="hypothtests.html"><a href="hypothtests.html#how-do-hypothesis-tests-work"><i class="fa fa-check"></i><b>8.1.2</b> How do hypothesis tests work?</a></li>
<li class="chapter" data-level="8.1.3" data-path="hypothtests.html"><a href="hypothtests.html#one-sample-t-test"><i class="fa fa-check"></i><b>8.1.3</b> One sample <span class="math inline">\(t\)</span> test</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="hypothtests.html"><a href="hypothtests.html#two-sample-t-test"><i class="fa fa-check"></i><b>8.2</b> Two sample <span class="math inline">\(t\)</span> test</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="hypothtests.html"><a href="hypothtests.html#doing-this-in-r-13"><i class="fa fa-check"></i><b>8.2.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="hypothtests.html"><a href="hypothtests.html#paired-t-test"><i class="fa fa-check"></i><b>8.3</b> Paired <span class="math inline">\(t\)</span> test</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="hypothtests.html"><a href="hypothtests.html#doing-this-in-r-14"><i class="fa fa-check"></i><b>8.3.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="hypothtests.html"><a href="hypothtests.html#t-test-assumptions"><i class="fa fa-check"></i><b>8.4</b> <span class="math inline">\(t\)</span> test assumptions</a></li>
<li class="chapter" data-level="8.5" data-path="hypothtests.html"><a href="hypothtests.html#non-parametric-alternative-to-t-tests"><i class="fa fa-check"></i><b>8.5</b> Non-parametric alternative to <span class="math inline">\(t\)</span> tests</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="hypothtests.html"><a href="hypothtests.html#mann-whitney-wilcoxon-test"><i class="fa fa-check"></i><b>8.5.1</b> Mann-Whitney-Wilcoxon test</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="hypothtests.html"><a href="hypothtests.html#practical-significance-versus-statistical-significance"><i class="fa fa-check"></i><b>8.6</b> Practical significance versus statistical significance</a></li>
<li class="chapter" data-level="8.7" data-path="hypothtests.html"><a href="hypothtests.html#SUMhyp"><i class="fa fa-check"></i><b>8.7</b> Summary</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="hypothtests.html"><a href="hypothtests.html#learning-outcomes-5"><i class="fa fa-check"></i><b>8.7.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="hypothtests.html"><a href="hypothtests.html#ANShyp"><i class="fa fa-check"></i><b>8.8</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>9</b> Analysis of Variance</a>
<ul>
<li class="chapter" data-level="9.1" data-path="anova.html"><a href="anova.html#INTanova"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="anova.html"><a href="anova.html#multiple-comparisons"><i class="fa fa-check"></i><b>9.2</b> Multiple comparisons</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="anova.html"><a href="anova.html#type-i-and-type-ii-error"><i class="fa fa-check"></i><b>9.2.1</b> Type I and Type II error</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="anova.html"><a href="anova.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>9.3</b> ANalysis Of VAriance (ANOVA)</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="anova.html"><a href="anova.html#f-test-statistic-for-anova"><i class="fa fa-check"></i><b>9.3.1</b> <span class="math inline">\(F\)</span> test statistic for ANOVA</a></li>
<li class="chapter" data-level="9.3.2" data-path="anova.html"><a href="anova.html#calculating-an-anova-table"><i class="fa fa-check"></i><b>9.3.2</b> Calculating an ANOVA table</a></li>
<li class="chapter" data-level="9.3.3" data-path="anova.html"><a href="anova.html#f-distribution"><i class="fa fa-check"></i><b>9.3.3</b> <span class="math inline">\(F\)</span> distribution</a></li>
<li class="chapter" data-level="9.3.4" data-path="anova.html"><a href="anova.html#doing-this-in-r-16"><i class="fa fa-check"></i><b>9.3.4</b> Doing this in R</a></li>
<li class="chapter" data-level="9.3.5" data-path="anova.html"><a href="anova.html#assumptions"><i class="fa fa-check"></i><b>9.3.5</b> Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="anova.html"><a href="anova.html#identifying-differences-and-more-on-multiple-comparisons"><i class="fa fa-check"></i><b>9.4</b> Identifying differences (and more on multiple comparisons)</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="anova.html"><a href="anova.html#sidak-correction"><i class="fa fa-check"></i><b>9.4.1</b> Sidak correction</a></li>
<li class="chapter" data-level="9.4.2" data-path="anova.html"><a href="anova.html#bonferroni-correction"><i class="fa fa-check"></i><b>9.4.2</b> Bonferroni correction</a></li>
<li class="chapter" data-level="9.4.3" data-path="anova.html"><a href="anova.html#tukeys-honest-significant-difference-hsd"><i class="fa fa-check"></i><b>9.4.3</b> Tukey’s Honest Significant Difference (HSD)</a></li>
<li class="chapter" data-level="9.4.4" data-path="anova.html"><a href="anova.html#multiple-comparison-dilema"><i class="fa fa-check"></i><b>9.4.4</b> Multiple comparison dilema</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="anova.html"><a href="anova.html#two-way-anova"><i class="fa fa-check"></i><b>9.5</b> Two-way ANOVA</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="anova.html"><a href="anova.html#calculating-a-two-way-anova-table"><i class="fa fa-check"></i><b>9.5.1</b> Calculating a two-way ANOVA table</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="anova.html"><a href="anova.html#alternative-tests-to-anova"><i class="fa fa-check"></i><b>9.6</b> Alternative tests to ANOVA</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="anova.html"><a href="anova.html#doing-this-in-r-18"><i class="fa fa-check"></i><b>9.6.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="anova.html"><a href="anova.html#SUManova"><i class="fa fa-check"></i><b>9.7</b> Summary</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="anova.html"><a href="anova.html#learning-outcomes-6"><i class="fa fa-check"></i><b>9.7.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="anova.html"><a href="anova.html#ANSanova"><i class="fa fa-check"></i><b>9.8</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="power.html"><a href="power.html"><i class="fa fa-check"></i><b>10</b> Statistical Power</a>
<ul>
<li class="chapter" data-level="10.1" data-path="power.html"><a href="power.html#INTpower"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="power.html"><a href="power.html#a-motivating-example---environmental-impact-assessment"><i class="fa fa-check"></i><b>10.2</b> A motivating example - Environmental impact assessment</a></li>
<li class="chapter" data-level="10.3" data-path="power.html"><a href="power.html#calculating-power"><i class="fa fa-check"></i><b>10.3</b> Calculating power</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="power.html"><a href="power.html#increasing-the-power"><i class="fa fa-check"></i><b>10.3.1</b> Increasing the power</a></li>
<li class="chapter" data-level="10.3.2" data-path="power.html"><a href="power.html#power-by-simulation"><i class="fa fa-check"></i><b>10.3.2</b> Power by simulation</a></li>
<li class="chapter" data-level="10.3.3" data-path="power.html"><a href="power.html#multiple-comparisons-1"><i class="fa fa-check"></i><b>10.3.3</b> Multiple comparisons</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="power.html"><a href="power.html#SUMpower"><i class="fa fa-check"></i><b>10.4</b> Summary</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="power.html"><a href="power.html#learning-objectives-1"><i class="fa fa-check"></i><b>10.4.1</b> Learning Objectives</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="power.html"><a href="power.html#ANSpower"><i class="fa fa-check"></i><b>10.5</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="proportions.html"><a href="proportions.html"><i class="fa fa-check"></i><b>11</b> Proportions</a>
<ul>
<li class="chapter" data-level="11.1" data-path="proportions.html"><a href="proportions.html#INTprop"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="proportions.html"><a href="proportions.html#confidence-intervals"><i class="fa fa-check"></i><b>11.2</b> Confidence intervals</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="proportions.html"><a href="proportions.html#motivating-example"><i class="fa fa-check"></i><b>11.2.1</b> Motivating example</a></li>
<li class="chapter" data-level="11.2.2" data-path="proportions.html"><a href="proportions.html#confidence-intervals-large-sample-sizes"><i class="fa fa-check"></i><b>11.2.2</b> Confidence intervals: large sample sizes</a></li>
<li class="chapter" data-level="11.2.3" data-path="proportions.html"><a href="proportions.html#confidence-intervals-small-sample-sizes"><i class="fa fa-check"></i><b>11.2.3</b> Confidence intervals: small sample sizes</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="proportions.html"><a href="proportions.html#comparing-two-proportions-the-z-test"><i class="fa fa-check"></i><b>11.3</b> Comparing two proportions: the <span class="math inline">\(z\)</span> test</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="proportions.html"><a href="proportions.html#testing-for-no-difference-between-groups"><i class="fa fa-check"></i><b>11.3.1</b> Testing for ‘no difference’ between groups</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="proportions.html"><a href="proportions.html#ci-for-the-difference-between-population-proportions-p_1-p_2"><i class="fa fa-check"></i><b>11.4</b> CI for the difference between population proportions, (<span class="math inline">\(p_1-p_2\)</span>)</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="proportions.html"><a href="proportions.html#choosing-the-appropriate-standard-error-when-comparing-proportions"><i class="fa fa-check"></i><b>11.4.1</b> Choosing the appropriate standard error when comparing proportions</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="proportions.html"><a href="proportions.html#odds-ratios"><i class="fa fa-check"></i><b>11.5</b> Odds ratios</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="proportions.html"><a href="proportions.html#calculating-the-odds-of-success"><i class="fa fa-check"></i><b>11.5.1</b> Calculating the odds of success</a></li>
<li class="chapter" data-level="11.5.2" data-path="proportions.html"><a href="proportions.html#calculating-the-odds-of-success-for-2-x-2-tables"><i class="fa fa-check"></i><b>11.5.2</b> Calculating the odds of success for 2 x 2 tables</a></li>
<li class="chapter" data-level="11.5.3" data-path="proportions.html"><a href="proportions.html#calculating-the-odds-ratio"><i class="fa fa-check"></i><b>11.5.3</b> Calculating the odds ratio</a></li>
<li class="chapter" data-level="11.5.4" data-path="proportions.html"><a href="proportions.html#confidence-intervals-for-odds-ratios"><i class="fa fa-check"></i><b>11.5.4</b> Confidence intervals for odds ratios</a></li>
<li class="chapter" data-level="11.5.5" data-path="proportions.html"><a href="proportions.html#final-note-on-odds-ratios"><i class="fa fa-check"></i><b>11.5.5</b> Final note on odds ratios</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="proportions.html"><a href="proportions.html#SUMprop"><i class="fa fa-check"></i><b>11.6</b> Summary</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="proportions.html"><a href="proportions.html#learning-outcomes-7"><i class="fa fa-check"></i><b>11.6.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="proportions.html"><a href="proportions.html#ANSprop"><i class="fa fa-check"></i><b>11.7</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="tableofcounts.html"><a href="tableofcounts.html"><i class="fa fa-check"></i><b>12</b> Tables of counts</a>
<ul>
<li class="chapter" data-level="12.1" data-path="tableofcounts.html"><a href="tableofcounts.html#introduction"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="tableofcounts.html"><a href="tableofcounts.html#chi2-goodness-of-fit-test"><i class="fa fa-check"></i><b>12.2</b> <span class="math inline">\(\chi^2\)</span> goodness-of-fit test</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="tableofcounts.html"><a href="tableofcounts.html#doing-this-in-r-22"><i class="fa fa-check"></i><b>12.2.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="tableofcounts.html"><a href="tableofcounts.html#chi2-test-of-independence"><i class="fa fa-check"></i><b>12.3</b> <span class="math inline">\(\chi^2\)</span> test of independence</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="tableofcounts.html"><a href="tableofcounts.html#doing-this-in-r-23"><i class="fa fa-check"></i><b>12.3.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="tableofcounts.html"><a href="tableofcounts.html#test-assumptions"><i class="fa fa-check"></i><b>12.4</b> Test assumptions</a></li>
<li class="chapter" data-level="12.5" data-path="tableofcounts.html"><a href="tableofcounts.html#summary"><i class="fa fa-check"></i><b>12.5</b> Summary</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="tableofcounts.html"><a href="tableofcounts.html#learning-outcomes-8"><i class="fa fa-check"></i><b>12.5.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="tableofcounts.html"><a href="tableofcounts.html#answers"><i class="fa fa-check"></i><b>12.6</b> Answers</a></li>
</ul></li>
<li class="part"><span><b>IV Regression and Linear Models</b></span></li>
<li class="chapter" data-level="13" data-path="correg.html"><a href="correg.html"><i class="fa fa-check"></i><b>13</b> Correlation and Regression</a>
<ul>
<li class="chapter" data-level="13.1" data-path="correg.html"><a href="correg.html#introcorreg"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="correg.html"><a href="correg.html#correlation"><i class="fa fa-check"></i><b>13.2</b> Correlation</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="correg.html"><a href="correg.html#significance-of-r"><i class="fa fa-check"></i><b>13.2.1</b> Significance of <span class="math inline">\(r\)</span></a></li>
<li class="chapter" data-level="13.2.2" data-path="correg.html"><a href="correg.html#correlation-and-causation"><i class="fa fa-check"></i><b>13.2.2</b> Correlation and causation</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="correg.html"><a href="correg.html#regression"><i class="fa fa-check"></i><b>13.3</b> Regression</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="correg.html"><a href="correg.html#exploratory-data-analysis"><i class="fa fa-check"></i><b>13.3.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="13.3.2" data-path="correg.html"><a href="correg.html#model-specification"><i class="fa fa-check"></i><b>13.3.2</b> Model specification</a></li>
<li class="chapter" data-level="13.3.3" data-path="correg.html"><a href="correg.html#which-straight-line-to-choose"><i class="fa fa-check"></i><b>13.3.3</b> Which straight line to choose?</a></li>
<li class="chapter" data-level="13.3.4" data-path="correg.html"><a href="correg.html#fitting-the-model-the-details"><i class="fa fa-check"></i><b>13.3.4</b> Fitting the model: the details</a></li>
<li class="chapter" data-level="13.3.5" data-path="correg.html"><a href="correg.html#predictions"><i class="fa fa-check"></i><b>13.3.5</b> Predictions</a></li>
<li class="chapter" data-level="13.3.6" data-path="correg.html"><a href="correg.html#the-variance-estimate"><i class="fa fa-check"></i><b>13.3.6</b> The variance estimate</a></li>
<li class="chapter" data-level="13.3.7" data-path="correg.html"><a href="correg.html#introduction-to-the-matrix-form"><i class="fa fa-check"></i><b>13.3.7</b> Introduction to the matrix form</a></li>
<li class="chapter" data-level="13.3.8" data-path="correg.html"><a href="correg.html#fitting-a-simple-regression-model"><i class="fa fa-check"></i><b>13.3.8</b> Fitting a simple regression model</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="correg.html"><a href="correg.html#SUMcorreg"><i class="fa fa-check"></i><b>13.4</b> Summary</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="correg.html"><a href="correg.html#learning-outcomes-9"><i class="fa fa-check"></i><b>13.4.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="correg.html"><a href="correg.html#ANScorreg"><i class="fa fa-check"></i><b>13.5</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="introlm.html"><a href="introlm.html"><i class="fa fa-check"></i><b>14</b> Introduction to the linear model</a>
<ul>
<li class="chapter" data-level="14.1" data-path="introlm.html"><a href="introlm.html#INTlm"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="introlm.html"><a href="introlm.html#the-linear-model-as-a-t-test"><i class="fa fa-check"></i><b>14.2</b> The linear model as a <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="14.3" data-path="introlm.html"><a href="introlm.html#the-linear-model-as-analysis-of-variance"><i class="fa fa-check"></i><b>14.3</b> The linear model as analysis of variance</a></li>
<li class="chapter" data-level="14.4" data-path="introlm.html"><a href="introlm.html#simple-linear-regression-again"><i class="fa fa-check"></i><b>14.4</b> Simple linear regression (again)</a></li>
<li class="chapter" data-level="14.5" data-path="introlm.html"><a href="introlm.html#model-performance"><i class="fa fa-check"></i><b>14.5</b> Model performance</a></li>
<li class="chapter" data-level="14.6" data-path="introlm.html"><a href="introlm.html#multiple-regression"><i class="fa fa-check"></i><b>14.6</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="introlm.html"><a href="introlm.html#the-eia-data-again"><i class="fa fa-check"></i><b>14.6.1</b> The EIA data again</a></li>
<li class="chapter" data-level="14.6.2" data-path="introlm.html"><a href="introlm.html#model-specification-1"><i class="fa fa-check"></i><b>14.6.2</b> Model specification</a></li>
<li class="chapter" data-level="14.6.3" data-path="introlm.html"><a href="introlm.html#types-of-covariates"><i class="fa fa-check"></i><b>14.6.3</b> Types of covariates</a></li>
<li class="chapter" data-level="14.6.4" data-path="introlm.html"><a href="introlm.html#model-fitting"><i class="fa fa-check"></i><b>14.6.4</b> Model fitting</a></li>
<li class="chapter" data-level="14.6.5" data-path="introlm.html"><a href="introlm.html#parameter-interpretation"><i class="fa fa-check"></i><b>14.6.5</b> Parameter Interpretation</a></li>
<li class="chapter" data-level="14.6.6" data-path="introlm.html"><a href="introlm.html#parameter-uncertainty"><i class="fa fa-check"></i><b>14.6.6</b> Parameter uncertainty</a></li>
<li class="chapter" data-level="14.6.7" data-path="introlm.html"><a href="introlm.html#confidence-intervals-cis-on-parameters"><i class="fa fa-check"></i><b>14.6.7</b> Confidence intervals (CIs) on parameters</a></li>
<li class="chapter" data-level="14.6.8" data-path="introlm.html"><a href="introlm.html#hypothesis-testing"><i class="fa fa-check"></i><b>14.6.8</b> Hypothesis testing</a></li>
<li class="chapter" data-level="14.6.9" data-path="introlm.html"><a href="introlm.html#model-performance-1"><i class="fa fa-check"></i><b>14.6.9</b> Model performance</a></li>
<li class="chapter" data-level="14.6.10" data-path="introlm.html"><a href="introlm.html#more-covariates-of-mixed-types"><i class="fa fa-check"></i><b>14.6.10</b> More covariates of mixed types</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="introlm.html"><a href="introlm.html#the-matrix-interpretation-of-a-linear-model"><i class="fa fa-check"></i><b>14.7</b> The matrix interpretation of a linear model</a>
<ul>
<li class="chapter" data-level="14.7.1" data-path="introlm.html"><a href="introlm.html#dummy-variables"><i class="fa fa-check"></i><b>14.7.1</b> Dummy variables</a></li>
<li class="chapter" data-level="14.7.2" data-path="introlm.html"><a href="introlm.html#combining-factors-and-continuous-variables"><i class="fa fa-check"></i><b>14.7.2</b> Combining factors and continuous variables</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="introlm.html"><a href="introlm.html#SUMlm"><i class="fa fa-check"></i><b>14.8</b> Summary</a>
<ul>
<li class="chapter" data-level="14.8.1" data-path="introlm.html"><a href="introlm.html#learning-objectives-2"><i class="fa fa-check"></i><b>14.8.1</b> Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="14.9" data-path="introlm.html"><a href="introlm.html#ANSlm"><i class="fa fa-check"></i><b>14.9</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="modelselection.html"><a href="modelselection.html"><i class="fa fa-check"></i><b>15</b> Model selection</a>
<ul>
<li class="chapter" data-level="15.1" data-path="modelselection.html"><a href="modelselection.html#INTmodsel"><i class="fa fa-check"></i><b>15.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="modelselection.html"><a href="modelselection.html#criteria-for-model-selection"><i class="fa fa-check"></i><b>15.1.1</b> Criteria for model selection</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="modelselection.html"><a href="modelselection.html#collinearity"><i class="fa fa-check"></i><b>15.2</b> Collinearity</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="modelselection.html"><a href="modelselection.html#variance-inflation-factors"><i class="fa fa-check"></i><b>15.2.1</b> Variance inflation factors</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="modelselection.html"><a href="modelselection.html#p-value-based-model-selection-the-f-test"><i class="fa fa-check"></i><b>15.3</b> <span class="math inline">\(p\)</span>-value based model selection: the <span class="math inline">\(F\)</span> test</a></li>
<li class="chapter" data-level="15.4" data-path="modelselection.html"><a href="modelselection.html#relative-model-fit"><i class="fa fa-check"></i><b>15.4</b> Relative model fit</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="modelselection.html"><a href="modelselection.html#akaikes-information-criterion-aic"><i class="fa fa-check"></i><b>15.4.1</b> Akaike’s Information Criterion (AIC)</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="modelselection.html"><a href="modelselection.html#other-methods-of-model-selection"><i class="fa fa-check"></i><b>15.5</b> Other methods of model selection</a></li>
<li class="chapter" data-level="15.6" data-path="modelselection.html"><a href="modelselection.html#automated-variable-selection"><i class="fa fa-check"></i><b>15.6</b> Automated variable selection</a>
<ul>
<li class="chapter" data-level="15.6.1" data-path="modelselection.html"><a href="modelselection.html#stepwise-selection"><i class="fa fa-check"></i><b>15.6.1</b> Stepwise selection</a></li>
<li class="chapter" data-level="15.6.2" data-path="modelselection.html"><a href="modelselection.html#all-possible-subsets-selection"><i class="fa fa-check"></i><b>15.6.2</b> All possible subsets selection</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="modelselection.html"><a href="modelselection.html#example-model-selection-with-the-medical-data"><i class="fa fa-check"></i><b>15.7</b> Example: model selection with the medical data</a>
<ul>
<li class="chapter" data-level="15.7.1" data-path="modelselection.html"><a href="modelselection.html#model-specification-3"><i class="fa fa-check"></i><b>15.7.1</b> Model specification</a></li>
<li class="chapter" data-level="15.7.2" data-path="modelselection.html"><a href="modelselection.html#interpreting-the-parameter-estimates"><i class="fa fa-check"></i><b>15.7.2</b> Interpreting the parameter estimates</a></li>
<li class="chapter" data-level="15.7.3" data-path="modelselection.html"><a href="modelselection.html#what-should-be-in-the-model"><i class="fa fa-check"></i><b>15.7.3</b> What ‘should’ be in the model?</a></li>
<li class="chapter" data-level="15.7.4" data-path="modelselection.html"><a href="modelselection.html#what-terms-are-significant"><i class="fa fa-check"></i><b>15.7.4</b> What terms are significant?</a></li>
<li class="chapter" data-level="15.7.5" data-path="modelselection.html"><a href="modelselection.html#more-automated-methods"><i class="fa fa-check"></i><b>15.7.5</b> More automated methods</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="modelselection.html"><a href="modelselection.html#SUMmodsel"><i class="fa fa-check"></i><b>15.8</b> Summary</a>
<ul>
<li class="chapter" data-level="15.8.1" data-path="modelselection.html"><a href="modelselection.html#learning-objectives-3"><i class="fa fa-check"></i><b>15.8.1</b> Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="15.9" data-path="modelselection.html"><a href="modelselection.html#ANSmodsel"><i class="fa fa-check"></i><b>15.9</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="interac.html"><a href="interac.html"><i class="fa fa-check"></i><b>16</b> Interactions and the Linear Model</a>
<ul>
<li class="chapter" data-level="16.1" data-path="interac.html"><a href="interac.html#INTinterac"><i class="fa fa-check"></i><b>16.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="interac.html"><a href="interac.html#fitting-different-models"><i class="fa fa-check"></i><b>16.1.1</b> Fitting different models</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="interac.html"><a href="interac.html#fitting-interaction-terms"><i class="fa fa-check"></i><b>16.2</b> Fitting interaction terms</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="interac.html"><a href="interac.html#specifying-interactions-in-model-formulae"><i class="fa fa-check"></i><b>16.2.1</b> Specifying interactions in model formulae</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="interac.html"><a href="interac.html#interactions-in-practise"><i class="fa fa-check"></i><b>16.3</b> Interactions in practise</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="interac.html"><a href="interac.html#medical-data"><i class="fa fa-check"></i><b>16.3.1</b> Medical data</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="interac.html"><a href="interac.html#model-selection-and-interactions"><i class="fa fa-check"></i><b>16.4</b> Model selection and interactions</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="interac.html"><a href="interac.html#backwards-selection-in-the-eia-data-set"><i class="fa fa-check"></i><b>16.4.1</b> Backwards selection in the EIA data set</a></li>
<li class="chapter" data-level="16.4.2" data-path="interac.html"><a href="interac.html#backwards-selection-in-the-medical-data-set"><i class="fa fa-check"></i><b>16.4.2</b> Backwards selection in the medical data set</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="interac.html"><a href="interac.html#SUMinterac"><i class="fa fa-check"></i><b>16.5</b> Summary</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="interac.html"><a href="interac.html#learning-objectives-4"><i class="fa fa-check"></i><b>16.5.1</b> Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="interac.html"><a href="interac.html#ANSinterac"><i class="fa fa-check"></i><b>16.6</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>17</b> Prediction from the linear model</a>
<ul>
<li class="chapter" data-level="17.1" data-path="prediction.html"><a href="prediction.html#INTpred"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="prediction.html"><a href="prediction.html#prediction-1"><i class="fa fa-check"></i><b>17.2</b> Prediction</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="prediction.html"><a href="prediction.html#doing-this-in-r-27"><i class="fa fa-check"></i><b>17.2.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="prediction.html"><a href="prediction.html#uncertainty-in-the-prediction"><i class="fa fa-check"></i><b>17.3</b> Uncertainty in the prediction</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="prediction.html"><a href="prediction.html#doing-this-in-r-28"><i class="fa fa-check"></i><b>17.3.1</b> Doing this in R</a></li>
<li class="chapter" data-level="17.3.2" data-path="prediction.html"><a href="prediction.html#confidence-intervals-for-the-line"><i class="fa fa-check"></i><b>17.3.2</b> Confidence intervals for the line</a></li>
<li class="chapter" data-level="17.3.3" data-path="prediction.html"><a href="prediction.html#prediction-intervals"><i class="fa fa-check"></i><b>17.3.3</b> Prediction intervals</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="prediction.html"><a href="prediction.html#prediction-in-multiple-regression"><i class="fa fa-check"></i><b>17.4</b> Prediction in multiple regression</a></li>
<li class="chapter" data-level="17.5" data-path="prediction.html"><a href="prediction.html#SUMpred"><i class="fa fa-check"></i><b>17.5</b> Summary</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="prediction.html"><a href="prediction.html#learning-objectives-5"><i class="fa fa-check"></i><b>17.5.1</b> Learning objectives</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="prediction.html"><a href="prediction.html#ANSpred"><i class="fa fa-check"></i><b>17.6</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="diagnostics.html"><a href="diagnostics.html"><i class="fa fa-check"></i><b>18</b> Linear model diagnostics</a>
<ul>
<li class="chapter" data-level="18.1" data-path="diagnostics.html"><a href="diagnostics.html#INTdiag"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="diagnostics.html"><a href="diagnostics.html#predictive-power"><i class="fa fa-check"></i><b>18.2</b> Predictive power</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="diagnostics.html"><a href="diagnostics.html#signal-versus-noise"><i class="fa fa-check"></i><b>18.2.1</b> Signal versus noise</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="diagnostics.html"><a href="diagnostics.html#model-assumptions"><i class="fa fa-check"></i><b>18.3</b> Model assumptions</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="diagnostics.html"><a href="diagnostics.html#normality-assumption"><i class="fa fa-check"></i><b>18.3.1</b> Normality assumption</a></li>
<li class="chapter" data-level="18.3.2" data-path="diagnostics.html"><a href="diagnostics.html#assessing-constant-error-variance"><i class="fa fa-check"></i><b>18.3.2</b> Assessing constant error variance</a></li>
<li class="chapter" data-level="18.3.3" data-path="diagnostics.html"><a href="diagnostics.html#assessing-independence"><i class="fa fa-check"></i><b>18.3.3</b> Assessing independence</a></li>
<li class="chapter" data-level="18.3.4" data-path="diagnostics.html"><a href="diagnostics.html#pseudoreplication"><i class="fa fa-check"></i><b>18.3.4</b> Pseudoreplication</a></li>
<li class="chapter" data-level="18.3.5" data-path="diagnostics.html"><a href="diagnostics.html#linearity-in-the-model-for-the-signal"><i class="fa fa-check"></i><b>18.3.5</b> Linearity in the model for the signal</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="diagnostics.html"><a href="diagnostics.html#example-diagnostics-with-the-medical-data"><i class="fa fa-check"></i><b>18.4</b> Example: Diagnostics with the medical data</a></li>
<li class="chapter" data-level="18.5" data-path="diagnostics.html"><a href="diagnostics.html#partial-residual-plots"><i class="fa fa-check"></i><b>18.5</b> Partial residual plots</a>
<ul>
<li class="chapter" data-level="18.5.1" data-path="diagnostics.html"><a href="diagnostics.html#doing-this-in-r-30"><i class="fa fa-check"></i><b>18.5.1</b> Doing this in R</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="diagnostics.html"><a href="diagnostics.html#interaction-terms"><i class="fa fa-check"></i><b>18.6</b> Interaction Terms</a></li>
<li class="chapter" data-level="18.7" data-path="diagnostics.html"><a href="diagnostics.html#SUMdiag"><i class="fa fa-check"></i><b>18.7</b> Summary</a>
<ul>
<li class="chapter" data-level="18.7.1" data-path="diagnostics.html"><a href="diagnostics.html#learning-outcomes-10"><i class="fa fa-check"></i><b>18.7.1</b> Learning outcomes</a></li>
</ul></li>
<li class="chapter" data-level="18.8" data-path="diagnostics.html"><a href="diagnostics.html#ANSdiag"><i class="fa fa-check"></i><b>18.8</b> Answers</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="nextsteps.html"><a href="nextsteps.html"><i class="fa fa-check"></i><b>19</b> The Next Steps</a>
<ul>
<li class="chapter" data-level="19.1" data-path="nextsteps.html"><a href="nextsteps.html#INTnext"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="nextsteps.html"><a href="nextsteps.html#solving-the-assumptional-problems"><i class="fa fa-check"></i><b>19.2</b> Solving the assumptional problems</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="nextsteps.html"><a href="nextsteps.html#example-the-eia-data"><i class="fa fa-check"></i><b>19.2.1</b> Example: The EIA data</a></li>
<li class="chapter" data-level="19.2.2" data-path="nextsteps.html"><a href="nextsteps.html#oddly-distributed-residuals"><i class="fa fa-check"></i><b>19.2.2</b> Oddly distributed residuals</a></li>
<li class="chapter" data-level="19.2.3" data-path="nextsteps.html"><a href="nextsteps.html#non-independence"><i class="fa fa-check"></i><b>19.2.3</b> Non-independence</a></li>
<li class="chapter" data-level="19.2.4" data-path="nextsteps.html"><a href="nextsteps.html#non-linearity"><i class="fa fa-check"></i><b>19.2.4</b> Non-linearity</a></li>
<li class="chapter" data-level="19.2.5" data-path="nextsteps.html"><a href="nextsteps.html#bootstrapping"><i class="fa fa-check"></i><b>19.2.5</b> Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="nextsteps.html"><a href="nextsteps.html#summary-1"><i class="fa fa-check"></i><b>19.3</b> Summary</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="nextsteps.html"><a href="nextsteps.html#learning-outcomes-11"><i class="fa fa-check"></i><b>19.3.1</b> Learning outcomes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="notation.html"><a href="notation.html"><i class="fa fa-check"></i><b>20</b> Notation</a>
<ul>
<li class="chapter" data-level="20.1" data-path="notation.html"><a href="notation.html#summation"><i class="fa fa-check"></i><b>20.1</b> Summation</a></li>
<li class="chapter" data-level="20.2" data-path="notation.html"><a href="notation.html#factorial"><i class="fa fa-check"></i><b>20.2</b> Factorial</a></li>
<li class="chapter" data-level="20.3" data-path="notation.html"><a href="notation.html#combinations"><i class="fa fa-check"></i><b>20.3</b> Combinations</a></li>
<li class="chapter" data-level="20.4" data-path="notation.html"><a href="notation.html#multiplication"><i class="fa fa-check"></i><b>20.4</b> Multiplication</a></li>
<li class="chapter" data-level="20.5" data-path="notation.html"><a href="notation.html#integration"><i class="fa fa-check"></i><b>20.5</b> Integration</a></li>
<li class="chapter" data-level="20.6" data-path="notation.html"><a href="notation.html#matrix-multiplication"><i class="fa fa-check"></i><b>20.6</b> Matrix multiplication</a></li>
<li class="chapter" data-level="20.7" data-path="notation.html"><a href="notation.html#absolute-values"><i class="fa fa-check"></i><b>20.7</b> Absolute values</a></li>
<li class="chapter" data-level="20.8" data-path="notation.html"><a href="notation.html#pi"><i class="fa fa-check"></i><b>20.8</b> <span class="math inline">\(\pi\)</span></a></li>
<li class="chapter" data-level="20.9" data-path="notation.html"><a href="notation.html#exponential-function-e"><i class="fa fa-check"></i><b>20.9</b> Exponential function, <span class="math inline">\(e\)</span></a></li>
<li class="chapter" data-level="20.10" data-path="notation.html"><a href="notation.html#scientific-notation"><i class="fa fa-check"></i><b>20.10</b> Scientific notation</a></li>
<li class="chapter" data-level="20.11" data-path="notation.html"><a href="notation.html#intervals"><i class="fa fa-check"></i><b>20.11</b> Intervals</a></li>
<li class="chapter" data-level="20.12" data-path="notation.html"><a href="notation.html#axes-on-plots"><i class="fa fa-check"></i><b>20.12</b> Axes on plots</a></li>
<li class="chapter" data-level="20.13" data-path="notation.html"><a href="notation.html#probability-2"><i class="fa fa-check"></i><b>20.13</b> Probability</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introlm" class="section level1" number="14">
<h1><span class="header-section-number">Chapter 14</span> Introduction to the linear model</h1>
<div id="INTlm" class="section level2" number="14.1">
<h2><span class="header-section-number">14.1</span> Introduction</h2>
<p>The linear model is a generalisation of various tests and modelling techniques we have already encountered in this module. Essentially the <span class="math inline">\(t\)</span> test, one-way analysis of variance and regression can all be integrated into a single modelling framework. The linear model really developed from a method called ANCOVA (analysis of covariance) developed by the famous geneticist/statistician Ronald Fisher and his co-workers <span class="citation">(<a href="#ref-Eden&amp;Fisher1927" role="doc-biblioref">1927</a>)</span> which allowed analysis of variance (using categorical variables) and regression to be combined into one analysis. Here we show how the linear model can be used to perform some of the tests from earlier in the module.</p>
</div>
<div id="the-linear-model-as-a-t-test" class="section level2" number="14.2">
<h2><span class="header-section-number">14.2</span> The linear model as a <span class="math inline">\(t\)</span> test</h2>
<p>The linear model can be used to undertake <span class="math inline">\(t\)</span> tests but the data has to be thought of in a slightly different manner.</p>
<p><strong>Example</strong> Consider the TEON medical dataset; it was data collected to investigate causes of Tanzanian Endemic Optic Neuropathy (TEON) a degenerative disease of the eyes. There is a hypothesis that TEON may be due to vitamin deficiencies.</p>
<p>As a reminder of the data, the first six records of the data are shown below:</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="introlm.html#cb303-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(meddata)</span></code></pre></div>
<pre><code>    gend age vitdresul         vitdc vit.12  vitbc folate TEON teonpres
1 female  50     10.98 insufficiency  310.0 normal  19.17  Yes        1
2 female  39     13.46 insufficiency  238.0 normal   8.16  Yes        1
3 female  39     15.36 insufficiency  361.0 normal   5.55  Yes        1
4   male  28     11.32           low  113.4    low   4.58  Yes        1
5   male  17      5.88   defficiency  313.0 normal   3.18  Yes        1
7   male  26     12.21 insufficiency  986.0   high  16.41  Yes        1</code></pre>
<p>Consider a <span class="math inline">\(t\)</span> test; we want to explore the difference between vitamin D levels in the two TEON groups (presence or absence of TEON). In the commands below, two new objects are created for coding convenience: vitamin D levels where TEON is present (<code>yesteonvitD</code>) and vitamin D where TEON is absent (<code>noteonvitD</code>).</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="introlm.html#cb305-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(tidyverse)</span>
<span id="cb305-2"><a href="introlm.html#cb305-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb305-3"><a href="introlm.html#cb305-3" aria-hidden="true" tabindex="-1"></a>yesteonvitD<span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">filter</span>(meddata, TEON<span class="sc">==</span><span class="st">&#39;Yes&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb305-4"><a href="introlm.html#cb305-4" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(vitdresul)</span>
<span id="cb305-5"><a href="introlm.html#cb305-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb305-6"><a href="introlm.html#cb305-6" aria-hidden="true" tabindex="-1"></a>noteonvitD<span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">filter</span>(meddata, TEON<span class="sc">==</span><span class="st">&#39;No&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb305-7"><a href="introlm.html#cb305-7" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(vitdresul)</span>
<span id="cb305-8"><a href="introlm.html#cb305-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb305-9"><a href="introlm.html#cb305-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Equivalent to:</span></span>
<span id="cb305-10"><a href="introlm.html#cb305-10" aria-hidden="true" tabindex="-1"></a><span class="co"># noteonvitD&lt;- meddata$vitdresul[meddata$TEON==&#39;No&#39;]</span></span></code></pre></div>
<p>Note here we’re using <em>pipes</em> from <code>tidyr</code> using the <code>tidyverse</code> package <span class="citation">(<a href="#ref-R-tidyr" role="doc-biblioref">Wickham 2021</a>)</span> and tools from the <code>dplyr</code> libraries using the <code>tidyverse</code> package <span class="citation">(<a href="#ref-R-dplyr" role="doc-biblioref">Wickham et al. 2021</a>)</span> (both loaded using the <code>tidyverse</code> package) to create the two new objects. They’re very good for data wrangling.</p>
<p>Having the data in the required form, we perform a two sample (two-tailed) <span class="math inline">\(t\)</span> test (assuming equal variances):</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="introlm.html#cb306-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(<span class="at">x =</span> yesteonvitD, <span class="at">y =</span> noteonvitD, <span class="at">var.equal=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>
    Two Sample t-test

data:  yesteonvitD and noteonvitD
t = -6.1878, df = 58, p-value = 6.666e-08
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -11.764534  -6.013488
sample estimates:
mean of x mean of y 
 10.69714  19.58615 </code></pre>
<p>The results indicate:</p>
<ul>
<li>We have a significant difference ( <em>p</em>-value = <span class="math inline">\(6.6e^{-10}\)</span>)</li>
<li>Group <code>yes</code> is <span class="math inline">\(19.58-10.697=8.883\)</span> units lower than group <code>no</code> on average</li>
<li>The 95% CI for this is about -11.76 to -6.01.</li>
</ul>
<p>We can write the same a little differently to emphasize the similarity of a two sample <span class="math inline">\(t\)</span> test with linear models - we can think of this as a very general statement of the form:</p>
<p><span class="math display">\[y=f(x)\]</span></p>
<p>This is interpreted as <span class="math inline">\(y\)</span> is a function of <span class="math inline">\(x\)</span>. In our example, <span class="math inline">\(y\)</span> is the vitamin D level and this can be written as a function of the TEON group. The alternative syntax used below highlights this interpretation:</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="introlm.html#cb308-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Order TEON levels for comparability</span></span>
<span id="cb308-2"><a href="introlm.html#cb308-2" aria-hidden="true" tabindex="-1"></a>meddata<span class="sc">$</span>TEON <span class="ot">&lt;-</span> <span class="fu">relevel</span>(<span class="fu">as.factor</span>(meddata<span class="sc">$</span>TEON), <span class="at">ref=</span><span class="st">&quot;Yes&quot;</span>)</span>
<span id="cb308-3"><a href="introlm.html#cb308-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Two sample t test as a model</span></span>
<span id="cb308-4"><a href="introlm.html#cb308-4" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(vitdresul <span class="sc">~</span> TEON, <span class="at">data=</span>meddata, <span class="at">var.equal=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>
    Two Sample t-test

data:  vitdresul by TEON
t = -6.1878, df = 58, p-value = 6.666e-08
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -11.764534  -6.013488
sample estimates:
mean in group Yes  mean in group No 
         10.69714          19.58615 </code></pre>
<p>Instead of treating the data as two distinct data sets, we have instead used <code>meddata</code> with <code>vitdresul</code> in one column and the group <code>TEON</code> in another column.
We get the same results, but were more explicit by stating <span class="math inline">\(y = f(x)\)</span>.</p>
<p><em>Note</em>:</p>
<ul>
<li>We are making sure the groups are ordered to produce the same sign estimates (not very important)</li>
<li>We are also not using the Welch-Satterthwaite variant (of the two sample <span class="math inline">\(t\)</span> test), so we can compare to the next model.</li>
</ul>
<div id="using-a-linear-model" class="section level4" number="14.2.0.1">
<h4><span class="header-section-number">14.2.0.1</span> Using a linear model</h4>
<p>The same model can be fitted as a simple linear regression model and now we try the same analysis using the <code>lm</code> function.</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="introlm.html#cb310-1" aria-hidden="true" tabindex="-1"></a>meddata<span class="sc">$</span>TEON <span class="ot">&lt;-</span> <span class="fu">relevel</span>(meddata<span class="sc">$</span>TEON, <span class="at">ref=</span><span class="st">&#39;No&#39;</span>)</span>
<span id="cb310-2"><a href="introlm.html#cb310-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb310-3"><a href="introlm.html#cb310-3" aria-hidden="true" tabindex="-1"></a>TEON_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(vitdresul <span class="sc">~</span> TEON, <span class="at">data=</span>meddata)</span>
<span id="cb310-4"><a href="introlm.html#cb310-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb310-5"><a href="introlm.html#cb310-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(TEON_lm)</span></code></pre></div>
<ul>
<li>I have set the baseline level to be the <code>no</code> group, for comparability with previous analysis (i.e. the intercept)</li>
<li>The <code>yes</code> group is then estimated relative to the baseline i.e. the mean value for <code>yes</code> is the baseline plus the <code>coefficient</code> given for <code>yes</code> (19.5862 + -8.8890)</li>
<li>The model structure is like before <span class="math inline">\(y=f(x)\)</span> (or <code>y ~ x</code> in R code).</li>
<li>The <em>signal</em> (<span class="math inline">\(f\)</span>) in this example is very simple - just <em>means</em> based on group membership.</li>
</ul>
<pre><code>
Call:
lm(formula = vitdresul ~ TEON, data = meddata)

Residuals:
     Min       1Q   Median       3Q      Max 
-10.1262  -3.7462  -0.2462   2.4929  20.3938 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  19.5862     0.8499  23.046  &lt; 2e-16 ***
TEONYes      -8.8890     1.4365  -6.188 6.67e-08 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 5.307 on 58 degrees of freedom
Multiple R-squared:  0.3976,    Adjusted R-squared:  0.3873 
F-statistic: 38.29 on 1 and 58 DF,  p-value: 6.666e-08</code></pre>
<p>The 95% confidence intervals for the estimated regression coefficients are given by:</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="introlm.html#cb312-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(TEON_lm)</span></code></pre></div>
<pre><code>                2.5 %    97.5 %
(Intercept)  17.88497 21.287336
TEONYes     -11.76453 -6.013488</code></pre>
<p>Scanning through all the results, notice that some values are common:</p>
<ul>
<li>t test statistic and the regression coefficient for ’TEONYes` are the same (-6.1878)</li>
<li>the same <em>p</em>-value (<span class="math inline">\(6.67e^{-08}\)</span>) for each statistic</li>
<li>the same estimates (19.586) and confidence intervals (-11.76, -6.01).</li>
</ul>
<p>Note that the <span class="math inline">\(t\)</span> test can do one thing the linear model cannot. One assumption of the linear model (which we will discuss in detail later) is that the variance of the two groups (in the case of the <span class="math inline">\(t\)</span> test analogue) are the same. The linear model can only undertake the equivalent of the pooled <span class="math inline">\(t\)</span> test (i.e. standard deviations of the two groups are assumed equal) not the unpooled <span class="math inline">\(t\)</span> test (i.e. standard deviations are not equal).</p>
<p><strong>Q14.1</strong> Considering the model that has just been fitted, what is the dependent, or response, variable in the model?</p>
<p><strong>Q14.2</strong> What is the predictor, or explanatory, variable in the model?</p>
<p><strong>Q14.3</strong> Comment on the direction of causality implied in these models. Is the latter analysis necessarily appropriate?</p>
<p><strong>Q14.4</strong> For the <span class="math inline">\(t\)</span> tests, the argument <code>var.equal=TRUE</code> is specified. The same argument is not required to be specified for a linear model. What do you think this might imply about the underlying assumptions of the linear model?</p>
<p><strong>Q14.5</strong> Write down the equation of the linear model being fitted and explain each of the terms in the model.</p>
<p><strong>Q14.6</strong> Explain the columns <code>Estimate</code>, <code>Std. Error</code>, <code>t value</code> and <code>Pr(&gt;|t|)</code>. How is the <code>t value</code> calculated?</p>
<p><strong>Q14.7</strong> What do the <code>***</code> indicate after <code>Pr(&gt;|t|)</code> values?</p>
<p><strong>Q14.8</strong> Using the values in the output, write down the fitted equations (i.e for TEON=No and TEON=Yes).</p>
<p><strong>Q14.9</strong> What is the estimated vitamin D level for a person with TEON?</p>
<p><strong>Q14.10</strong> If the degrees of freedom associated with the residuals is 58, what was the number of observations?</p>
<p><strong>Q14.11</strong> Show how the confidence interval for the parameter associated with TEON = Yes is calculated given the following information:<br />
<code>&gt; qt(0.025, df=58)</code><br />
<code>[1] -2.001717</code></p>
<p><strong>Q14.12</strong> How would you calculate the <span class="math inline">\(p\)</span>-value for the <span class="math inline">\(t\)</span> test statistic for the slope using the <code>pt</code> function?</p>
</div>
</div>
<div id="the-linear-model-as-analysis-of-variance" class="section level2" number="14.3">
<h2><span class="header-section-number">14.3</span> The linear model as analysis of variance</h2>
<p>Recall one-way analysis of variance where there are more than two groups. We can create a variable in the medical data called <code>ageTEON</code> with four groups; this tells us whether each patient is:</p>
<ul>
<li>Without TEON and young (age less than the median age of 36)</li>
<li>Without TEON and old (age equal to or greater than the median age of 36)</li>
<li>With TEON and young (as above)</li>
<li>With TEON and old (as above)</li>
</ul>
<p>The output of an <span class="math inline">\(F\)</span> test as in ANOVA to determine any group-based estimate differences in vitamin D levels is shown below:</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="introlm.html#cb314-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">aov</span>(vitdresul <span class="sc">~</span> ageTEON, <span class="at">data=</span>meddata))</span></code></pre></div>
<pre><code>            Df Sum Sq Mean Sq F value   Pr(&gt;F)    
ageTEON      3   1115   371.5   13.02 1.46e-06 ***
Residuals   56   1598    28.5                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div id="fitting-aov-as-a-linear-model" class="section level4" number="14.3.0.1">
<h4><span class="header-section-number">14.3.0.1</span> Fitting <code>aov</code> as a linear model</h4>
<p>We can again model this relationship as <span class="math inline">\(y = f(x)\)</span> using <code>lm</code> where <span class="math inline">\(x\)</span> is a categorical variable with more than 2 levels.</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="introlm.html#cb316-1" aria-hidden="true" tabindex="-1"></a>ageTEON_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(vitdresul <span class="sc">~</span> ageTEON, <span class="at">data=</span>meddata)</span>
<span id="cb316-2"><a href="introlm.html#cb316-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ageTEON_lm)</span></code></pre></div>
<pre><code>
Call:
lm(formula = vitdresul ~ ageTEON, data = meddata)

Residuals:
    Min      1Q  Median      3Q     Max 
-10.262  -3.697  -0.345   1.869  20.570 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)      19.7223     1.1388  17.319  &lt; 2e-16 ***
ageTEONNoYoung   -0.3123     1.7248  -0.181 0.856985    
ageTEONYesOld   -10.3823     2.0371  -5.097 4.23e-06 ***
ageTEONYesYoung  -7.7914     1.9724  -3.950 0.000221 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 5.341 on 56 degrees of freedom
Multiple R-squared:  0.411, Adjusted R-squared:  0.3794 
F-statistic: 13.02 on 3 and 56 DF,  p-value: 1.456e-06</code></pre>
<p>Observe:</p>
<ul>
<li>The matching degrees of freedom (3 and 56), <span class="math inline">\(F\)</span> test statistic (13.02) and <span class="math inline">\(p\)</span>-value (<span class="math inline">\(1.465e^{-06}\)</span>)</li>
<li>We get estimated differences between factor levels and a baseline level (which is <code>NoOld</code>).</li>
</ul>
</div>
</div>
<div id="simple-linear-regression-again" class="section level2" number="14.4">
<h2><span class="header-section-number">14.4</span> Simple linear regression (again)</h2>
<p>We now try another simple regression with the medical data and model vitamin D levels as a function of a continuous covariate, folate. The model we want to fit is:</p>
<p><span class="math display">\[\textrm{vitdresul} = \beta_0 + \beta_1\textrm{folate} + \epsilon\]</span></p>
<p>Remember for a simple linear regression model:</p>
<ul>
<li>The model for signal is a simple straight line.</li>
<li>The model for noise is a normal distribution.</li>
</ul>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="introlm.html#cb318-1" aria-hidden="true" tabindex="-1"></a>simpleReg <span class="ot">&lt;-</span> <span class="fu">lm</span>(vitdresul <span class="sc">~</span> folate, <span class="at">data=</span>meddata)</span>
<span id="cb318-2"><a href="introlm.html#cb318-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simpleReg)</span></code></pre></div>
<pre><code>
Call:
lm(formula = vitdresul ~ folate, data = meddata)

Residuals:
     Min       1Q   Median       3Q      Max 
-13.1034  -4.4947  -0.3768   3.8585  23.2495 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 15.44131    1.61776   9.545 1.69e-13 ***
folate       0.09022    0.11856   0.761     0.45    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 6.805 on 58 degrees of freedom
Multiple R-squared:  0.009884,  Adjusted R-squared:  -0.007187 
F-statistic: 0.579 on 1 and 58 DF,  p-value: 0.4498</code></pre>
<p>From the output, we can construct the fitted equation:</p>
<p><span class="math display">\[\hat {\textrm{vitdresul}} = 15.4413 + 0.0902 \times\textrm{folate}\]</span></p>
<p>What does this equation tell us? We can see that:</p>
<ul>
<li><p>When folate levels are 0, we estimate mean vitamin D level as 15.44.</p></li>
<li><p>For each unit increase of folate, we estimate an average increase in Vitamin D as 0.0902.</p></li>
<li><p>There isn’t a statistically significant (linear) relationship between folate and Vitamin D levels ( <em>p</em>-value = 0.45)</p></li>
<li><p>The amount of variance in the data explained by this model is just about 1.0% (from the Multiple R-squared value)</p></li>
<li><p>Overall, the model doesn’t really explain a significant amount of the variation ( <em>p</em>-value = 0.4498)</p></li>
</ul>
<div id="looking-at-the-fitted-model" class="section level4" number="14.4.0.1">
<h4><span class="header-section-number">14.4.0.1</span> Looking at the fitted model</h4>
<p>Let’s look at the fitted model - we assume a simple straight line relationship between the response and covariate:</p>
<ul>
<li>We can plot the data (it’s a simple case) and overlay the fitted model (Figure <a href="introlm.html#fig:VitD">14.1</a>).</li>
</ul>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="introlm.html#cb320-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(meddata<span class="sc">$</span>folate, meddata<span class="sc">$</span>vitdresul, <span class="at">xlab=</span><span class="st">&quot;Folate&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Vit. D level&quot;</span>)</span>
<span id="cb320-2"><a href="introlm.html#cb320-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a fitted line using the correlation coefficients</span></span>
<span id="cb320-3"><a href="introlm.html#cb320-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">coefficients</span>(simpleReg), <span class="at">col=</span><span class="st">&#39;blue&#39;</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:VitD"></span>
<img src="IntroStats_files/figure-html/VitD-1.png" alt="Scatterplot of vitamin D against folate levels and fitted regression line (blue line). " width="480" />
<p class="caption">
Figure 14.1: Scatterplot of vitamin D against folate levels and fitted regression line (blue line).
</p>
</div>
<p>We can also look at an ANOVA table for this model</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="introlm.html#cb321-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(simpleReg)</span></code></pre></div>
<pre><code>Analysis of Variance Table

Response: vitdresul
          Df  Sum Sq Mean Sq F value Pr(&gt;F)
folate     1   26.81  26.809   0.579 0.4498
Residuals 58 2685.50  46.302               </code></pre>
<p>We can do a lot with <code>lm</code>!</p>
</div>
</div>
<div id="model-performance" class="section level2" number="14.5">
<h2><span class="header-section-number">14.5</span> Model performance</h2>
<p>As we have seen, it is easy to fit a linear model (especially in R) but have we fitted a good model? What does “good” even mean? Here we look at methods for assessing the goodness of fit of the fitted line.</p>
<div id="goodness-of-fit-r2" class="section level4" number="14.5.0.1">
<h4><span class="header-section-number">14.5.0.1</span> Goodness of fit, <span class="math inline">\(R^2\)</span></h4>
<p>One criterion for assessing goodness of fit might be whether the model accurately predicts the observed values. Another way of putting this might be “how much of variation observed in the data is explained by the model?” To answer this question, we consider the regression as an analysis of variance problem. The variability observed in the data can be partitioned in to the variability explained by model and the variability not explained by the model. We want to know how much of the total observed variation has been explained by the model?</p>
<p>The easiest way to do this is to work out the proportion of unexplained variation and subtract from one.</p>
<p><span class="math display">\[R^2=1- \frac{\sum_{i=1}^{n}(y_i-\hat{y})^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2}\]</span></p>
<ul>
<li>the numerator is the square error or residual sum of squares <span class="math inline">\(SS_{Res}\)</span></li>
<li>the denominator is known as the total sum of squares (<span class="math inline">\(SS_{Total}\)</span>).
So here to determine the proportion of explained variation we have determined the proportion of the unexplained variation and subtracted it from one.</li>
</ul>
<p>In the summary of <code>depthModel</code>, we see that the multiple R-sq is 0.6903. We can use the <code>anova</code> function output for the <code>depthModel</code> to illustrate the calculation:</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="introlm.html#cb323-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a regression using lm (linear model)</span></span>
<span id="cb323-2"><a href="introlm.html#cb323-2" aria-hidden="true" tabindex="-1"></a>depthModel <span class="ot">&lt;-</span> <span class="fu">lm</span>(depth <span class="sc">~</span> DistCoast,  <span class="at">data=</span>workingData)</span>
<span id="cb323-3"><a href="introlm.html#cb323-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb323-4"><a href="introlm.html#cb323-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary of model</span></span>
<span id="cb323-5"><a href="introlm.html#cb323-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(depthModel)</span></code></pre></div>
<pre><code>
Call:
lm(formula = depth ~ DistCoast, data = workingData)

Residuals:
     Min       1Q   Median       3Q      Max 
-12.5152  -2.7239   0.1013   2.1208  14.7857 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 2.298e+00  1.064e-01    21.6   &lt;2e-16 ***
DistCoast   1.244e-06  1.087e-08   114.5   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 4.322 on 5882 degrees of freedom
Multiple R-squared:  0.6903,    Adjusted R-squared:  0.6903 
F-statistic: 1.311e+04 on 1 and 5882 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="introlm.html#cb325-1" aria-hidden="true" tabindex="-1"></a><span class="co"># anova table</span></span>
<span id="cb325-2"><a href="introlm.html#cb325-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(depthModel)</span></code></pre></div>
<pre><code>Analysis of Variance Table

Response: depth
            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
DistCoast    1 244936  244936   13112 &lt; 2.2e-16 ***
Residuals 5882 109881      19                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Just as in the case of the one-way analysis of variance, the variation (sum of the square differences) is broken down in terms of</p>
<ul>
<li>the explained sum of squares portion (by <code>Distcoast</code>) and</li>
<li>the residual unexplained variation <code>Residuals</code> (<span class="math inline">\(SS_{Res}\)</span>).</li>
</ul>
<p>As in ANOVA seen previously, the <span class="math inline">\(F\)</span> value is the ratio of explained variation (now turned into a variance by dividing by the degrees of freedom) to the unexplained variation (also considered as a variance.)</p>
<p>Using the output, <span class="math inline">\(R^2\)</span> is given by:</p>
<p><span class="math display">\[R^2 = 1- \frac{\textrm{Residual Sum of Squares}}{\textrm{Total Sum of Squares}} = 1- \frac{109881}{244936+109881} = 0.6903\]</span>
Another way of writing <span class="math inline">\(R^2\)</span> is the proportion of variation (measured as sum of squares) explained:</p>
<p><span class="math display">\[R^2 = \frac{\textrm{Model Sum of Squares}}{\textrm{Total Sum of Squares}} =\frac{244936}{244936+109881} = 0.6903\]</span></p>
<p>We mentioned before the connection between the <code>t</code> and <code>F</code> statistics in the <code>summary</code> table
but there are other connections too. If the residual standard error of the summary table (i.e. <span class="math inline">\(4.322\)</span>) is squared, this gives the Mean sum of squares associated with the residuals in the <code>anova</code> table i.e.<span class="math display">\[ 4.322^2 = 18.7 \approx 19\]</span>.</p>
<p>We can also look at an ANOVA table for regression of vitamin D levels by folate using the medical data to illustrate another calculation of R-sq:</p>
<pre><code>Analysis of Variance Table

Response: vitdresul
          Df  Sum Sq Mean Sq F value Pr(&gt;F)
folate     1   26.81  26.809   0.579 0.4498
Residuals 58 2685.50  46.302               </code></pre>
<p>Let’s calculate the <span class="math inline">\(R^2\)</span> from the ANOVA table. First, let’s see the structure of the ANOVA table object using <code>str</code>:</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="introlm.html#cb328-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Stucture of ANOVA table</span></span>
<span id="cb328-2"><a href="introlm.html#cb328-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(<span class="fu">anova</span>(simpleReg))</span></code></pre></div>
<pre><code>Classes &#39;anova&#39; and &#39;data.frame&#39;:   2 obs. of  5 variables:
 $ Df     : int  1 58
 $ Sum Sq : num  26.8 2685.5
 $ Mean Sq: num  26.8 46.3
 $ F value: num  0.579 NA
 $ Pr(&gt;F) : num  0.45 NA
 - attr(*, &quot;heading&quot;)= chr [1:2] &quot;Analysis of Variance Table\n&quot; &quot;Response: vitdresul&quot;</code></pre>
<p>There are two components to the sum of squares related to the slope and the error. If we add these we get the total sum of squares.</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="introlm.html#cb330-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save ANOVA object</span></span>
<span id="cb330-2"><a href="introlm.html#cb330-2" aria-hidden="true" tabindex="-1"></a>anova.simpleReg <span class="ot">&lt;-</span> <span class="fu">anova</span>(simpleReg)</span>
<span id="cb330-3"><a href="introlm.html#cb330-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb330-4"><a href="introlm.html#cb330-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Total sum of squares</span></span>
<span id="cb330-5"><a href="introlm.html#cb330-5" aria-hidden="true" tabindex="-1"></a>tss <span class="ot">&lt;-</span> <span class="fu">sum</span>(anova.simpleReg[,<span class="dv">2</span>])</span>
<span id="cb330-6"><a href="introlm.html#cb330-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum of squares for slope</span></span>
<span id="cb330-7"><a href="introlm.html#cb330-7" aria-hidden="true" tabindex="-1"></a>folatess <span class="ot">&lt;-</span> anova.simpleReg[<span class="dv">1</span>,<span class="dv">2</span>]</span>
<span id="cb330-8"><a href="introlm.html#cb330-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Goodness of fit</span></span>
<span id="cb330-9"><a href="introlm.html#cb330-9" aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">&lt;-</span> folatess<span class="sc">/</span>tss</span>
<span id="cb330-10"><a href="introlm.html#cb330-10" aria-hidden="true" tabindex="-1"></a>R2</span></code></pre></div>
<pre><code>[1] 0.009884201</code></pre>
</div>
</div>
<div id="multiple-regression" class="section level2" number="14.6">
<h2><span class="header-section-number">14.6</span> Multiple regression</h2>
<p>Previously we have considered just one explanatory (predictor) variable, be it categorical (like <code>Phase</code> in the environmental data set) or continuous (like <code>folate</code> in the medical data set). However, many systems presumably have multiple inputs so it would be useful to have models that can consider multiple predictors at the same time, both for efficiency <em>and</em> to take into account the relationships those variables might have with each other.</p>
<p>In this section we are going to describe multiple linear regression models and illustrate the methods by examining and quantify relationships between the response (density) and the other covariates available in the EIA data set.
We will fit some preliminary models, carry out model selection, diagnose model problems and interpret some results (in light of any problems).</p>
<div id="the-eia-data-again" class="section level3" number="14.6.1">
<h3><span class="header-section-number">14.6.1</span> The EIA data again</h3>
<p>We’ll return to the EIA dataset seen previously. To analyse these data properly would require some more advanced methods, but we can illustrate the basic principles of multiple regression with these data.</p>
<p>Recall that data were collected during three different construction phases (A, B and C):</p>
<ul>
<li><p>We could fit an ANOVA and determine whether there are differences in average densities across phases.</p></li>
<li><p>If we see compelling (and reliable) differences across average densities in each phase, we would want to be sure that any differences seen across phases are not due to other variables (apart from phase).</p>
<ul>
<li><p>For instance, if a bird species avoids deep waters and locations with deep water were over-represented in phase C, this could return a lower average density in phase C (compared with the other phases) for this reason alone.</p></li>
<li><p>Ignoring imbalances like these could lead us to incorrectly conclude that differences across phases are due to the wind farm construction.</p></li>
</ul></li>
</ul>
<p>Therefore, we want to include multiple explanatory variables (covariates) in a linear model:</p>
<ul>
<li><p>For these (and other) reasons, it makes sense to consider the relationship between density and several covariates simultaneously, even if the primary interest solely lies in changes due to construction phases.</p></li>
<li><p>We might also gain valuable insights about variables which influence density.</p></li>
</ul>
<div id="exploratory-data-analysis-1" class="section level4" number="14.6.1.1">
<h4><span class="header-section-number">14.6.1.1</span> Exploratory Data Analysis</h4>
<p>Scatterplots can be a good way to explore relationships between variables, but over-plotting (several points on top of each other) can make patterns difficult to see and so we might want to use the <code>qplot</code> function in the <code>ggplot2</code> library:</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="introlm.html#cb332-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(ggplot2)</span>
<span id="cb332-2"><a href="introlm.html#cb332-2" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(gridExtra)</span>
<span id="cb332-3"><a href="introlm.html#cb332-3" aria-hidden="true" tabindex="-1"></a>a<span class="ot">&lt;-</span><span class="fu">qplot</span>(Depth, Density, <span class="at">data=</span>workingData, <span class="at">xlab=</span><span class="st">&quot;Depth (m)&quot;</span>,</span>
<span id="cb332-4"><a href="introlm.html#cb332-4" aria-hidden="true" tabindex="-1"></a><span class="at">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="at">geom =</span> <span class="fu">c</span>(<span class="st">&quot;point&quot;</span>), <span class="at">alpha =</span> <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="dv">5</span>))</span>
<span id="cb332-5"><a href="introlm.html#cb332-5" aria-hidden="true" tabindex="-1"></a>b<span class="ot">&lt;-</span><span class="fu">qplot</span>(XPos, Density, <span class="at">data=</span>workingData,<span class="at">xlab=</span><span class="st">&quot;X co-ordinate&quot;</span>,</span>
<span id="cb332-6"><a href="introlm.html#cb332-6" aria-hidden="true" tabindex="-1"></a><span class="at">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="at">geom =</span> <span class="fu">c</span>(<span class="st">&quot;point&quot;</span>), <span class="at">alpha =</span> <span class="fu">I</span>(<span class="dv">1</span> <span class="sc">/</span> <span class="dv">5</span>))</span>
<span id="cb332-7"><a href="introlm.html#cb332-7" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(a, b, <span class="at">nrow=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:realscatterplots14a"></span>
<img src="IntroStats_files/figure-html/realscatterplots14a-1.png" alt="Scatterplots for potential model covariates and estimated densities." width="672" />
<p class="caption">
Figure 14.2: Scatterplots for potential model covariates and estimated densities.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:realscatterplots14b"></span>
<img src="IntroStats_files/figure-html/realscatterplots14b-1.png" alt="Scatterplots for potential model covariates and estimated densities." width="672" />
<p class="caption">
Figure 14.3: Scatterplots for potential model covariates and estimated densities.
</p>
</div>
<p>Using Figures <a href="introlm.html#fig:realscatterplots14a">14.2</a> and <a href="introlm.html#fig:realscatterplots14b">14.3</a>, it is very difficult to tell which covariates affect density due to the very large numbers of observations, but speculatively the highest densities seem to be associated with:</p>
<ul>
<li>moderate depths</li>
<li>large values of the X-coordinate</li>
<li>central values of the Y-coordinate</li>
<li>locations near the coast.</li>
</ul>
</div>
</div>
<div id="model-specification-1" class="section level3" number="14.6.2">
<h3><span class="header-section-number">14.6.2</span> Model specification</h3>
<p>We are going to use multiple covariates to predict density in the survey area
using linear regression. There are two main reasons why we may want to do this:</p>
<ul>
<li><strong>Explanation</strong>: We may be genuinely interested in finding the relationship between such variables (e.g. what, if any, is the relationship between density and depth?)</li>
<li><strong>Prediction</strong>: If there is a relationship between the variables under study, then knowledge of some variables will help us predict others (e.g., if we know that density changes with depth on the transects, then knowing the depth of a site will help us predict density off the transects).</li>
</ul>
<div id="candidate-covariates" class="section level4" number="14.6.2.1">
<h4><span class="header-section-number">14.6.2.1</span> Candidate covariates</h4>
<p>Linear models with continuous explanatory variables assume constantly increasing or decreasing relationships between each explanatory variable and the response. We are going to consider the following covariates in the model(s):</p>
<ul>
<li>X-coordinate: the easting co-ordinate of each location (UTM)</li>
<li>Y-coordinate: the northing co-ordinate of each location (UTM)</li>
<li>Distance from coast: how far each location is from the nearest coast</li>
<li>Depth: the depth of the water at each location</li>
<li>month: calendar month</li>
</ul>
<p>Since we are also interested in potential changes across phases, we also include:</p>
<ul>
<li><p>Phase: construction status of the site:</p>
<ul>
<li>baseline (phase=A),</li>
<li>installation/operation of the first windfarm (phase=B),</li>
<li>installation/operation of the second windfarm (phase=C)</li>
</ul></li>
</ul>
<p>It is worth looking at the relationships between pairs of explanatory variables to see if there are any correlations between them (Figure <a href="introlm.html#fig:exploratory">14.4</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:exploratory"></span>
<img src="IntroStats_files/figure-html/exploratory-1.png" alt="Scatterplots showing the relationships between explanatory variables. The plots are symmetrical above and below the diagonal." width="480" />
<p class="caption">
Figure 14.4: Scatterplots showing the relationships between explanatory variables. The plots are symmetrical above and below the diagonal.
</p>
</div>
</div>
<div id="the-model-for-the-signal" class="section level4" number="14.6.2.2">
<h4><span class="header-section-number">14.6.2.2</span> The model for the signal</h4>
<p>Multiple linear regression models use at least two explanatory variables to predict the response of interest and can be written as:</p>
<p><span class="math display" id="eq:lreg">\[
y_{i} =  \beta_0 +
\beta_1x_{1i} + \beta_2x_{2i} + \cdots +\beta_px_{pi} +\epsilon_{i}
\tag{14.1}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(y_{i}\)</span> is the response (density for time point <span class="math inline">\(i\)</span> in the EIA case),</li>
<li><span class="math inline">\(\beta_0\)</span>, is the intercept parameter,</li>
<li><span class="math inline">\(\beta_1,\beta_2\)</span>,…,<span class="math inline">\(\beta_p\)</span> are slope coefficients and</li>
<li><span class="math inline">\(x_{1i}, x_{2i},...,x_{pi}\)</span> are the explanatory variables for each time point (<span class="math inline">\(i\)</span>)</li>
<li><span class="math inline">\(\epsilon_i\)</span> is the error for time point <span class="math inline">\(i\)</span>.</li>
</ul>
</div>
<div id="the-model-for-the-noise" class="section level4" number="14.6.2.3">
<h4><span class="header-section-number">14.6.2.3</span> The model for the noise</h4>
<p>While the linear combination of covariates (<span class="math inline">\(\beta_0 + \beta_1x_{1i} + \beta_2x_{2i} +,...,+\beta_px_{pi}\)</span>) might describe the relationship between the response and covariates well, it will never describe the response exactly. For this reason, we need to consider the differences between the response and values predicted by the model (the errors; <span class="math inline">\(\epsilon_{i}\)</span>).</p>
<p>For these models, we will assume the collection of these differences (<span class="math inline">\(\boldsymbol{\epsilon}\)</span>) are well described by a normal distribution with zero mean and some variance, <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{\epsilon} \sim N(0,\sigma^2).
\end{equation}\]</span></p>
</div>
</div>
<div id="types-of-covariates" class="section level3" number="14.6.3">
<h3><span class="header-section-number">14.6.3</span> Types of covariates</h3>
<p>There can be two types of variable in a linear model. Variables that are continuous and those that are factors with different levels. The latter can be ordered if there are more than two levels.</p>
<div id="continuous-covariates" class="section level4" number="14.6.3.1">
<h4><span class="header-section-number">14.6.3.1</span> Continuous covariates</h4>
<p>If we fit a model with <code>XPos</code>, <code>YPos</code>, <code>DistCoast</code>, <code>Depth</code> and <code>Month</code> all as continuous covariates, we have the following model:</p>
<p><span class="math display" id="eq:linregdata">\[
y_{i} =  \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} +\beta_3x_{3i} +\beta_4x_{4i}+\beta_5x_{5i}+\epsilon_{i}
\tag{14.2}
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(y_{i}\)</span> represents <code>Density</code> at point <span class="math inline">\(i\)</span>,</p></li>
<li><p><span class="math inline">\(x_{1i}\)</span> represents <code>XPos</code>,</p></li>
<li><p><span class="math inline">\(x_{2i}\)</span> represents <code>YPos</code>,</p></li>
<li><p><span class="math inline">\(x_{3i}\)</span> represents <code>DistCoast</code>,</p></li>
<li><p><span class="math inline">\(x_{4i}\)</span> represents <code>Depth</code> and</p></li>
<li><p><span class="math inline">\(x_{5i}\)</span> represents <code>Month</code>.</p></li>
<li><p>Each slope coefficient (<span class="math inline">\(\beta_1,...,\beta_5\)</span>) relates to the expected change in density for a one-unit increase in the covariate.</p></li>
<li><p>The intercept coefficient (<span class="math inline">\(\beta_0\)</span>) relates to the expected density when all covariates are equal to zero (which doesn’t make sense in this context) as for example <code>Depth</code> cannot be zero.</p></li>
</ul>
</div>
<div id="factor-covariates" class="section level4" number="14.6.3.2">
<h4><span class="header-section-number">14.6.3.2</span> Factor covariates</h4>
<p>In this example, month can either be considered as a continuous covariate, since it is coded as values 1 to 4, or a categorical (factor) covariate since it contains many repeated values.</p>
<ul>
<li>As it turns out, fitting variables as factors permits the response to vary with the covariate in a nonlinear way so that, in this example, the fitted relationship between density and month can vary by month.<br />
</li>
<li>As a consequence, this requires more parameters to be estimated because we are no longer estimating just one regression coefficient.The number of parameters is related to the number of factor levels.</li>
</ul>
<p>Factor variables are typically fitted using ‘treatment contrasts’; one level of the factor variable forms the <em>baseline</em> and the remaining levels of the factor have corresponding coefficients that need to be estimated which are calculated as differences from the baseline.</p>
<ul>
<li>For example, one `level’ of month (e.g. the first level) forms the baseline, while the remaining levels have associated coefficients which quantify the difference in the expected value of the response in each month compared with the baseline month (all else being equal).</li>
</ul>
<p>Factors in linear models are implemented in practise using ‘dummy’ variables which switch</p>
<ul>
<li>on (<span class="math inline">\(x=1\)</span>) or</li>
<li>off (<span class="math inline">\(x=0\)</span>)</li>
</ul>
<p>depending on the level of the factor variable.</p>
<p>For instance, if we modify the model in Equation <a href="introlm.html#eq:linregdata">(14.2)</a> to include month as a factor (instead of a linear term),</p>
<ul>
<li>month now has three coefficients (month has four values: 1–4) and</li>
<li>the first month forms the baseline:</li>
</ul>
<p><span class="math display" id="eq:linregdata2">\[\begin{equation}
y_{i} =  \beta_0 +
\beta_1x_{1i} + \beta_2x_{2i} +\beta_3x_{3i} +\beta_4x_{4i}+\beta_5x_{5i}+\beta_6x_{6i}+\beta_7x_{7i}+\epsilon_{i}
\tag{14.3}
\end{equation}\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(x_{1i}\)</span> represents <code>XPos</code>,</p></li>
<li><p><span class="math inline">\(x_{2i}\)</span> represents <code>YPos</code>,<br />
</p></li>
<li><p><span class="math inline">\(x_{3i}\)</span> represents <code>DistCoast</code>,</p></li>
<li><p><span class="math inline">\(x_{4i}\)</span> represents <code>Depth</code>,<br />
</p></li>
<li><p><span class="math inline">\(x_{5i}=1\)</span> when Month=2 and <span class="math inline">\(x_{5i}=0\)</span> otherwise (i.e. for any other month),</p></li>
<li><p><span class="math inline">\(x_{6i}=1\)</span> when Month=3 and <span class="math inline">\(x_{6i}=0\)</span> otherwise</p></li>
<li><p><span class="math inline">\(x_{7i}=1\)</span> when Month=4 and <span class="math inline">\(x_{7i}=0\)</span> otherwise.</p></li>
<li><p>the intercept coefficient (<span class="math inline">\(\beta_0\)</span>) represents average density in <code>Month=1</code> when <code>XPos</code>, <code>YPos</code>, <code>DistCoast</code> and <code>Depth</code> are equal to zero.</p></li>
</ul>
<p>The fitted model for January is:</p>
<p><span class="math display">\[\hat{y_{i}}=\hat{\beta}_0+\hat{\beta}_1x_{1i}+\hat{\beta}_2x_{2i}+\hat{\beta}_3x_{3i}+\hat{\beta}_4x_{4i}\]</span></p>
<p>The fitted model for February is:</p>
<p><span class="math display">\[\hat{y_{i}}=\hat{\beta}_0+\hat{\beta}_1x_{1i}+\hat{\beta}_2x_{2i}+\hat{\beta}_3x_{3i}+\hat{\beta}_4x_{4i}+\hat{\beta}_{5}x_{5i}\]</span></p>
<p>When <code>month</code>=2, <span class="math inline">\(x_{5i}=1\)</span> and when <code>month</code>= 1, 3 or 4, <span class="math inline">\(x_{5i}=0\)</span> .</p>
<p>Similarly, the fitted model for April is:</p>
<p><span class="math display">\[\hat{y_{i}}=\hat{\beta}_0+\hat{\beta}_1x_{1i}+\hat{\beta}_2x_{2i}+\hat{\beta}_3x_{3i}+\hat{\beta}_4x_{4i}+\hat{\beta}_{7}x_{7i}\]</span>
where <span class="math inline">\(x_{7i}=1\)</span> (since <code>month</code>=4 and <span class="math inline">\(x_{7i}=0\)</span> otherwise).</p>
</div>
</div>
<div id="model-fitting" class="section level3" number="14.6.4">
<h3><span class="header-section-number">14.6.4</span> Model fitting</h3>
<p>Similar to a simple linear regression model, the regression coefficients are estimated from the data using least-squares (LS).</p>
<div id="least-squares" class="section level4" number="14.6.4.1">
<h4><span class="header-section-number">14.6.4.1</span> Least-Squares</h4>
<p>Estimating linear model parameters is straightforward using least-squares:</p>
<ul>
<li><p>We find estimates for <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>,…, <span class="math inline">\(\beta_p\)</span> that `best’ fit the data.</p></li>
<li><p>We do this by finding values for the parameters that give us model predictions/fitted values (<span class="math inline">\(\hat{y}_{i}\)</span>) which are closest to our response data (<span class="math inline">\({y}_{i}\)</span>) over all observations.</p></li>
<li><p>This happens by minimising the sum of the squared difference between the observed data and the values returned by the model:</p></li>
</ul>
<p><span class="math display">\[\begin{align}
\textrm{LS} &amp; = \sum_{i=1}^{n_i}(y_{i}-\hat{y}_{i})^2 \\
&amp;=\sum_{i=1}^{n_i}(y_{i}-(\hat{\beta}_0 + \hat{\beta}_1x_{1i},...,\hat{\beta}_px_{pi}))^2 \\
\end{align}\]</span></p>
</div>
<div id="fitting-linear-models-in-r" class="section level4" number="14.6.4.2">
<h4><span class="header-section-number">14.6.4.2</span> Fitting linear models in R</h4>
<p>Multiple regression models are easily fitted in R with the <code>lm</code> function.</p>
<p>For example, Equation <a href="introlm.html#eq:linregdata">(14.2)</a> defined a model with only continuous variables (<code>month</code> is treated here as continuous). It is fitted using the following command:</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="introlm.html#cb333-1" aria-hidden="true" tabindex="-1"></a>linearStart<span class="ot">&lt;-</span> <span class="fu">lm</span>(Density <span class="sc">~</span> XPos <span class="sc">+</span> YPos <span class="sc">+</span> DistCoast <span class="sc">+</span> Depth <span class="sc">+</span> Month, <span class="at">data=</span>wfdata)</span>
<span id="cb333-2"><a href="introlm.html#cb333-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linearStart)</span></code></pre></div>
<pre><code>
Call:
lm(formula = Density ~ XPos + YPos + DistCoast + Depth + Month, 
    data = wfdata)

Residuals:
    Min      1Q  Median      3Q     Max 
 -10.26   -5.14   -3.23   -0.12 1716.69 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 3272.47592  269.07482  12.162  &lt; 2e-16 ***
XPos           0.11900    0.01197   9.944  &lt; 2e-16 ***
YPos          -0.55280    0.04444 -12.440  &lt; 2e-16 ***
DistCoast     -0.31923    0.06935  -4.603 4.18e-06 ***
Depth         -0.45189    0.04080 -11.075  &lt; 2e-16 ***
Month          0.25340    0.14210   1.783   0.0746 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 27.87 on 31496 degrees of freedom
Multiple R-squared:  0.01264,   Adjusted R-squared:  0.01248 
F-statistic: 80.62 on 5 and 31496 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Thus, the fitted equation is:</p>
<p><span class="math display">\[\begin{align}
\widehat{\textrm{Density}} = &amp; 3272 + 0.119\textrm{XPos}\\
&amp; - 0.553\textrm{YPos} - 0.3198\textrm{DistCoast} \\
&amp; - 0.452 \textrm{Depth} + 0.253 \textrm{Month}\\
\end{align}\]</span></p>
</div>
<div id="continuous-and-factor-level-covariates" class="section level4" number="14.6.4.3">
<h4><span class="header-section-number">14.6.4.3</span> Continuous and factor-level covariates</h4>
<p>When month is fitted as <strong>factor</strong> variable (Equation <a href="introlm.html#eq:linregdata2">(14.3)</a> instead of a continuous variable, we find month now has three coefficients (i.e. the number of levels minus the baseline). By default, R will treat a variable containing numbers as a continuous variable and so we need to explicitly state that <code>Month</code> is a factor if the levels are designated by numbers. Note but if <code>Month</code> was coded as Feb, Mar etc then the default fit would be as a factor.</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="introlm.html#cb335-1" aria-hidden="true" tabindex="-1"></a>linearFactor<span class="ot">&lt;-</span> <span class="fu">lm</span>(Density <span class="sc">~</span> XPos <span class="sc">+</span> YPos <span class="sc">+</span> DistCoast <span class="sc">+</span> Depth <span class="sc">+</span> <span class="fu">as.factor</span>(Month), <span class="at">data=</span>wfdata)</span>
<span id="cb335-2"><a href="introlm.html#cb335-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linearFactor)</span></code></pre></div>
<pre><code>
Call:
lm(formula = Density ~ XPos + YPos + DistCoast + Depth + as.factor(Month), 
    data = wfdata)

Residuals:
    Min      1Q  Median      3Q     Max 
 -11.89   -5.30   -2.96   -0.25 1714.99 

Coefficients:
                    Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)       3287.57866  268.86594  12.228  &lt; 2e-16 ***
XPos                 0.11850    0.01196   9.909  &lt; 2e-16 ***
YPos                -0.55529    0.04440 -12.505  &lt; 2e-16 ***
DistCoast           -0.32135    0.06931  -4.636 3.56e-06 ***
Depth               -0.45316    0.04077 -11.115  &lt; 2e-16 ***
as.factor(Month)2    0.24030    0.52499   0.458    0.647    
as.factor(Month)3    2.79114    0.44722   6.241 4.40e-10 ***
as.factor(Month)4    0.30828    0.44748   0.689    0.491    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 27.85 on 31494 degrees of freedom
Multiple R-squared:  0.01441,   Adjusted R-squared:  0.01419 
F-statistic: 65.76 on 7 and 31494 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Thus, the fitted equation will change depending on the value of month because some terms will disappear.</p>
<p>The fitted equation for January (baseline) is:</p>
<p><span class="math display">\[\begin{align}
\widehat{\textrm{Density}} = &amp; 3288 + 0.119\textrm{XPos} -0.555\textrm{YPos} \\
&amp; - 0.321\textrm{DistCoast} - 0.453 \textrm{Depth}\\
\end{align}\]</span></p>
<p>The other months are relative to the baseline and so we add on additional terms (which adjust the intercept). The fitted equation for February is:</p>
<p><span class="math display">\[\begin{align}
\widehat{\textrm{Density}} = &amp; 3288 + 0.119\textrm{XPos} \\
&amp; -0.555\textrm{YPos} - 0.321\textrm{DistCoast} \\
&amp; - 0.453 \textrm{Depth} + 0.240\\
\end{align}\]</span></p>
<p>The fitted equation for March is:</p>
<p><span class="math display">\[\begin{align}
\widehat{\textrm{Density}} = &amp; 3288 + 0.119\textrm{XPos} \\
&amp; -0.555\textrm{YPos} - 0.321\textrm{DistCoast} \\
&amp; - 0.453 \textrm{Depth} + 2.791\\
\end{align}\]</span></p>
<p>and lastly, for April is</p>
<p><span class="math display">\[\begin{align}
\widehat{\textrm{Density}} = &amp; 3288 + 0.119\textrm{XPos} \\
&amp; -0.555\textrm{YPos} - 0.321\textrm{DistCoast} \\
&amp; - 0.453 \textrm{Depth} + 0.308\\
\end{align}\]</span></p>
</div>
</div>
<div id="parameter-interpretation" class="section level3" number="14.6.5">
<h3><span class="header-section-number">14.6.5</span> Parameter Interpretation</h3>
<p>In our example, we are interested in the potential changes across phases and so we add <code>Phase</code> to the model. This adds two coefficients (because there are two phases). The variable <code>Phase</code> is coded as A, B or C and so R interprets this as a factor by default .</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="introlm.html#cb337-1" aria-hidden="true" tabindex="-1"></a>linearAll<span class="ot">&lt;-</span> <span class="fu">lm</span>(Density <span class="sc">~</span> XPos <span class="sc">+</span> YPos <span class="sc">+</span> DistCoast <span class="sc">+</span> Depth <span class="sc">+</span> <span class="fu">as.factor</span>(Month) <span class="sc">+</span> Phase, <span class="at">data=</span>wfdata)</span>
<span id="cb337-2"><a href="introlm.html#cb337-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linearAll)</span></code></pre></div>
<pre><code>
Call:
lm(formula = Density ~ XPos + YPos + DistCoast + Depth + as.factor(Month) + 
    Phase, data = wfdata)

Residuals:
    Min      1Q  Median      3Q     Max 
 -12.31   -5.31   -3.00   -0.21 1714.54 

Coefficients:
                    Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)       3285.86992  268.82312  12.223  &lt; 2e-16 ***
XPos                 0.11748    0.01196   9.822  &lt; 2e-16 ***
YPos                -0.55489    0.04440 -12.498  &lt; 2e-16 ***
DistCoast           -0.31521    0.06932  -4.547 5.47e-06 ***
Depth               -0.45436    0.04076 -11.146  &lt; 2e-16 ***
as.factor(Month)2    0.54786    0.53628   1.022 0.306977    
as.factor(Month)3    3.15909    0.46245   6.831 8.57e-12 ***
as.factor(Month)4    0.65758    0.45871   1.434 0.151712    
PhaseB              -0.18549    0.36145  -0.513 0.607826    
PhaseC              -1.53604    0.46315  -3.316 0.000913 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 27.84 on 31492 degrees of freedom
Multiple R-squared:  0.01479,   Adjusted R-squared:  0.0145 
F-statistic: 52.51 on 9 and 31492 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Typically we wouldn’t proceed with interpreting model output until we were happy with our model, however, we will do so now for illustration.</p>
<p>The model coefficients (<span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>) for the <code>linearAll</code> model can be interpreted as follows:</p>
<ul>
<li><p><code>XPos</code> increases by one kilometre, we expect density to increase by 0.117 animals per km<span class="math inline">\(^2\)</span></p></li>
<li><p><code>YPos</code> increases by one kilometre, we expect density to decrease by 0.555 animals per km<span class="math inline">\(^2\)</span></p></li>
<li><p><code>DistCoast</code> increases by one kilometre, we expect density to decrease by 0.315 animals per km<span class="math inline">\(^2\)</span></p></li>
<li><p><code>Depth</code> increases by 1 metre (i.e. becomes 1m deeper) then density is expected to decrease by 0.454 animals per km<span class="math inline">\(^2\)</span></p></li>
<li><p><code>Month</code> is February, rather than January, then density is expected to increase
by 0.547 animals per km<span class="math inline">\(^2\)</span></p></li>
<li><p><code>Month</code> is March, rather than January, then density is expected to increase by 3.159 animals per km<span class="math inline">\(^2\)</span></p></li>
<li><p><code>Month</code> is April, rather than January, then density is expected to increase by 0.658 animals per km<span class="math inline">\(^2\)</span></p></li>
<li><p><code>Phase</code> is Phase B, rather than Phase A, then density is expected to decrease by 0.185 animals per km<span class="math inline">\(^2\)</span></p></li>
<li><p><code>Phase</code> is Phase C, rather than Phase A, then density is expected to decrease by 1.536 animals per km<span class="math inline">\(^2\)</span></p></li>
<li><p>The intercept in this case includes two baseline levels - the baseline month and the baseline phase and so reflects the expected density for <code>XPos=0</code>, <code>YPos=0</code>, <code>DistCoast=0</code>, <code>Depth=0</code> in January and Phase A.</p></li>
</ul>
<p>A nice film about interpreting regression coefficients can found <a href="http://www.youtube.com/watch?v=JwGaos2Y9bM">here</a>.</p>
</div>
<div id="parameter-uncertainty" class="section level3" number="14.6.6">
<h3><span class="header-section-number">14.6.6</span> Parameter uncertainty</h3>
<p>There is uncertainty in the parameter estimates (of course). We have estimates for each regression coefficient (each <span class="math inline">\(\beta_p\)</span>, where <span class="math inline">\(p=1,...P\)</span>) but each time we take a sample (and hence fit a new model), we obtain different estimates (because the data going into the estimators will be different).</p>
<p>If there was no genuine relationship between the response and a covariate, we might expect that the estimated value of the regression coefficient would be very close to zero (i.e. hardly any change in the response for a unit increase in the covariate).</p>
<ul>
<li>However, even if there is <strong>no</strong> genuine relationship between the response and each covariate, the estimate is unlikely to ever be <strong>exactly</strong> zero.</li>
</ul>
<p>In order to make general statements about model parameters, we can generate ranges of plausible values for these parameters (e.g. confidence intervals) and perform hypothesis tests for these parameters.</p>
</div>
<div id="confidence-intervals-cis-on-parameters" class="section level3" number="14.6.7">
<h3><span class="header-section-number">14.6.7</span> Confidence intervals (CIs) on parameters</h3>
<p>Building CIs for model parameters is very similar to CIs for means, and we will use the <span class="math inline">\(t\)</span> distribution (with <span class="math inline">\(df=n-P-1\)</span>) to give us our multiplier. (The Residual degrees of freedom in the R summary output also gives this df). The information to construct these CIs is provided in the <code>R</code> output, excepting the <span class="math inline">\(t\)</span> multiplier:</p>
<p><span class="math display">\[
\hat{\beta}_p \pm t_{(\alpha/2, df=n-P-1)} \times SE_{\beta_p}
\]</span></p>
<ul>
<li>For example, the 95% confidence interval (<span class="math inline">\(\alpha=0.05\)</span>) for the coefficient associated with <code>phaseB</code> is
<span class="math display">\[ -0.185 \pm t_{(0.025, 31492)}\times 0.361\]</span>
The <span class="math inline">\(t\)</span> multiplier is -1.96 (the <span class="math inline">\(t\)</span> distribution is going to be like the normal distribution because of the high degrees of freedom):</li>
</ul>
<p><span class="math display">\[ -0.185 \pm 1.96\times 0.361\]</span></p>
<p>(-0.894, 0.523)</p>
<ul>
<li>Note this interval contains zero and so even though the estimate is positive, we cannot say whether average density in phase B is higher, lower, or the same as in phase A (all other things being equal.)</li>
</ul>
</div>
<div id="hypothesis-testing" class="section level3" number="14.6.8">
<h3><span class="header-section-number">14.6.8</span> Hypothesis testing</h3>
<p>The two-sided hypothesis test of <strong>no relationship</strong> for each covariate (i.e.. <span class="math inline">\(H_0: \beta_p=0\)</span>, <span class="math inline">\(H_1: \beta_p \neq 0\)</span>) is performed in the familiar way:</p>
<p><span class="math display">\[
\textrm{test statistic} = \frac{\textrm{data-estimate - hypothesised value}}{ {\textrm{standard error}}}
\]</span></p>
<ul>
<li>Data-estimates which are more than about 2 standard errors from the hypothesized value
(<span class="math inline">\(\beta_p=0\)</span> in this case, no real underlying relationship) provide compelling evidence against <span class="math inline">\(H_0\)</span>.</li>
</ul>
<p><strong>Example</strong> We can test the hypothesis that the coefficient for phase B is equal to 0. Therefore, the test statistic for <code>phaseB</code> coefficient is:
<span class="math display">\[
\textrm{test statistic} = \frac{-0.18549-0}{0.36145}=-0.513
\]</span></p>
<ul>
<li>We can quantify the evidence for the null hypothesis by obtaining an exact <span class="math inline">\(p\)</span>-value for the test statistic:</li>
</ul>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="introlm.html#cb339-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">pt</span>(<span class="at">q=</span><span class="sc">-</span><span class="fl">1.916</span>, <span class="at">df=</span><span class="dv">31492</span>)</span></code></pre></div>
<pre><code>[1] 0.05537414</code></pre>
<p>This <span class="math inline">\(p\)</span>-value suggests we have no/weak evidence against <span class="math inline">\(H_0\)</span> - under repeated sampling we would obtain a test statistic at least this large about 85% of the time even if there is no genuine difference between phases A and B.</p>
<p>Testing at a significance level of 5%, we fail to reject the null hypothesis that the coefficient for phase B is different from 0 (since the <span class="math inline">\(p\)</span>-value is larger than 5%). As this coefficient represents the difference between the mean of phase A and phase B then is is effectively a test of the difference between phase A and B.</p>
<p>Similar hypothesis tests can be done for all regression coefficients and that is what <code>R</code> has done in the summary output although it may be necessary to relevel categorical variables. These are the <code>t</code> values and <code>Pr(&gt;|t|)</code> values.</p>
<div id="the-importance-of-considering-multiple-covariates" class="section level4" number="14.6.8.1">
<h4><span class="header-section-number">14.6.8.1</span> The importance of considering multiple covariates</h4>
<p>Based on the <code>linearAll</code> model, we have no evidence that average density is different in phase B (or phase C) compared with phase A, but this result depends on the other covariates included in the model.</p>
<p>In this case, if we consider <code>Phase</code> alone in the model (see below), the average density is still not significantly higher in phase B compared with phase A.</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="introlm.html#cb341-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(Density <span class="sc">~</span> Phase, <span class="at">data=</span>EIAData))</span></code></pre></div>
<pre><code>
Call:
lm(formula = Density ~ Phase, data = EIAData)

Residuals:
    Min      1Q  Median      3Q     Max 
  -3.89   -3.89   -3.50   -2.48 1721.40 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   3.4985     0.2618  13.365   &lt;2e-16 ***
PhaseB        0.3879     0.3524   1.101   0.2710    
PhaseC       -1.0224     0.4494  -2.275   0.0229 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 28.04 on 31499 degrees of freedom
Multiple R-squared:  0.0003341, Adjusted R-squared:  0.0002706 
F-statistic: 5.263 on 2 and 31499 DF,  p-value: 0.005182</code></pre>
<p>To show the importance of covariates can depend on other covariates included in the model the following example shows an extreme case of this.</p>
<p>Imagine we are interested in understanding the contribution of leg length to human height. We measure left leg length (LLL) and right leg length (RLL) and total height in a sample of men.</p>
<p>As one might expect there appears to be a relationship between all 3 variables (Figure <a href="introlm.html#fig:anothergraph">14.5</a>) and as might be expected, there appears to be a significant contribution of leg length to human height.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:anothergraph"></span>
<img src="IntroStats_files/figure-html/anothergraph-1.png" alt="Scatterplots of LLL, RLL and total height. " width="480" />
<p class="caption">
Figure 14.5: Scatterplots of LLL, RLL and total height.
</p>
</div>
<p>LLL is included in a simple regression model:</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="introlm.html#cb343-1" aria-hidden="true" tabindex="-1"></a>modelLLL <span class="ot">&lt;-</span> <span class="fu">lm</span> (TotalHeight<span class="sc">~</span>LLL)</span>
<span id="cb343-2"><a href="introlm.html#cb343-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span> (modelLLL)</span></code></pre></div>
<pre><code>
Call:
lm(formula = TotalHeight ~ LLL)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.6892 -2.0397 -0.1175  2.4317  8.7109 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.37066   10.39322   0.036    0.972    
LLL          1.63305    0.09456  17.270   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.515 on 98 degrees of freedom
Multiple R-squared:  0.7527,    Adjusted R-squared:  0.7502 
F-statistic: 298.3 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="introlm.html#cb345-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span> (modelLLL)</span></code></pre></div>
<pre><code>Analysis of Variance Table

Response: TotalHeight
          Df Sum Sq Mean Sq F value    Pr(&gt;F)    
LLL        1 3685.6  3685.6  298.27 &lt; 2.2e-16 ***
Residuals 98 1211.0    12.4                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Similarly, RLL is included in a simple regression model:</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="introlm.html#cb347-1" aria-hidden="true" tabindex="-1"></a>modelRLL <span class="ot">&lt;-</span> <span class="fu">lm</span> (TotalHeight<span class="sc">~</span>RLL)</span>
<span id="cb347-2"><a href="introlm.html#cb347-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span> (modelRLL)</span></code></pre></div>
<pre><code>
Call:
lm(formula = TotalHeight ~ RLL)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.6909 -2.0331 -0.0485  2.4452  8.7845 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.44999   10.34181   0.044    0.965    
RLL          1.63236    0.09409  17.349   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.503 on 98 degrees of freedom
Multiple R-squared:  0.7544,    Adjusted R-squared:  0.7519 
F-statistic:   301 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="introlm.html#cb349-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span> (modelRLL)</span></code></pre></div>
<pre><code>Analysis of Variance Table

Response: TotalHeight
          Df Sum Sq Mean Sq F value    Pr(&gt;F)    
RLL        1 3693.9  3693.9  300.97 &lt; 2.2e-16 ***
Residuals 98 1202.8    12.3                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>But see what happens when both variables are in the model:</p>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb351-1"><a href="introlm.html#cb351-1" aria-hidden="true" tabindex="-1"></a>modelBoth <span class="ot">&lt;-</span> <span class="fu">lm</span> (TotalHeight<span class="sc">~</span>LLL<span class="sc">+</span>RLL)</span>
<span id="cb351-2"><a href="introlm.html#cb351-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span> (modelBoth)</span></code></pre></div>
<pre><code>
Call:
lm(formula = TotalHeight ~ LLL + RLL)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.7350 -1.9141  0.1564  2.4205  9.2282 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)    2.148     10.379   0.207    0.836
LLL           -9.408      7.036  -1.337    0.184
RLL           11.025      7.026   1.569    0.120

Residual standard error: 3.489 on 97 degrees of freedom
Multiple R-squared:  0.7588,    Adjusted R-squared:  0.7538 
F-statistic: 152.6 on 2 and 97 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="introlm.html#cb353-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span> (modelBoth)</span></code></pre></div>
<pre><code>Analysis of Variance Table

Response: TotalHeight
          Df Sum Sq Mean Sq  F value Pr(&gt;F)    
LLL        1 3685.6  3685.6 302.7187 &lt;2e-16 ***
RLL        1   30.0    30.0   2.4627 0.1198    
Residuals 97 1181.0    12.2                    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Not only have the regression coefficients changed for each variable but neither are associated with a significant probability in the <code>summary</code> table and only LLL, is associated with a significant probability in the ANOVA table.</p>
<p>See what happens if the order of presentation of the variables is reversed.</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="introlm.html#cb355-1" aria-hidden="true" tabindex="-1"></a>modelBoth2 <span class="ot">&lt;-</span> <span class="fu">lm</span> (TotalHeight<span class="sc">~</span>RLL<span class="sc">+</span>LLL)</span>
<span id="cb355-2"><a href="introlm.html#cb355-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span> (modelBoth2)</span></code></pre></div>
<pre><code>
Call:
lm(formula = TotalHeight ~ RLL + LLL)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.7350 -1.9141  0.1564  2.4205  9.2282 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)    2.148     10.379   0.207    0.836
RLL           11.025      7.026   1.569    0.120
LLL           -9.408      7.036  -1.337    0.184

Residual standard error: 3.489 on 97 degrees of freedom
Multiple R-squared:  0.7588,    Adjusted R-squared:  0.7538 
F-statistic: 152.6 on 2 and 97 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="introlm.html#cb357-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span> (modelBoth2)</span></code></pre></div>
<pre><code>Analysis of Variance Table

Response: TotalHeight
          Df Sum Sq Mean Sq  F value Pr(&gt;F)    
RLL        1 3693.9  3693.9 303.3936 &lt;2e-16 ***
LLL        1   21.8    21.8   1.7877 0.1843    
Residuals 97 1181.0    12.2                    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The summary table output is the same as before, but the ANOVA table now has RLL as significant, but LLL not.</p>
<p>What is the explanation? The estimated regression coefficients are the slopes <em>given the other terms in the model</em>. In this case, the extra effect of RLL, given LLL is already in the model, is negligible and vice versa. If one knows LLL, RLL tells us nothing because the two variables are so similar (or more precisely correlated). Hence, neither term is significant. We will return to this correlation of the predictors later.</p>
<p>In the case of the ANOVA table, the sum of squares act <em>sequentially</em>, so the variation in <code>modelBoth</code> is parcelled out to LLL first and then RLL. In this case LLL is significant, but RLL is not. In the case of <code>modelBoth2</code>, RLL is significant and LLL is not.</p>
<p>What is the solution? Perhaps to consider a model with LLL, or RLL, only but not both. Nothing is lost by only including one of these variables in this case, because they really explain the same thing. If RLL and LLL were not closely correlated, then explanative power could be lost by not including them in the model. We shall return to this topic.</p>
<hr />
</div>
</div>
<div id="model-performance-1" class="section level3" number="14.6.9">
<h3><span class="header-section-number">14.6.9</span> Model performance</h3>
<p>Previously, we calculated <span class="math inline">\(R^2\)</span> value to obtain a measure of goodness of fit. The ordinary <span class="math inline">\(R^2\)</span> (called <code>Multiple R-squared</code> in summary output) should be used cautiously in multiple regression:</p>
<ul>
<li>When adding covariates to a model the (absolute) fit to the data will always improve, even if just a little.<br />
</li>
<li>So goodness of fit scores (e.g. the squared correlation between the observed and fitted values; the <span class="math inline">\(R^2\)</span>) which ignore the number of parameters used to fit the model should not form the basis for comparison across models with different numbers of covariate.</li>
</ul>
<div id="adjusted-r2" class="section level4" number="14.6.9.1">
<h4><span class="header-section-number">14.6.9.1</span> Adjusted <span class="math inline">\(R^2\)</span></h4>
<p>In a multiple linear regression model, an adjusted <span class="math inline">\(R^2\)</span> value is often more appropriate than the ordinary <span class="math inline">\(R^2\)</span> value because it takes into account the number of parameters estimated in the model:</p>
<p><span class="math display">\[
\textrm{Adjusted } R^2 = 1-\frac{(n-1)(1-R^2)}{n-P-1}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(R^2\)</span> is the squared correlation between the observed (<span class="math inline">\({y}_{i}\)</span>) and fitted values (<span class="math inline">\(\hat{y}_{i}\)</span>),</li>
<li><span class="math inline">\(n\)</span> is the total number of observations, and</li>
<li><span class="math inline">\(P\)</span> is the number of explanatory variables fitted in the model.</li>
</ul>
<p>An adjusted <span class="math inline">\(R^2\)</span> closer to 1 indicates better predictive power and is shown in the <code>lm</code> output.For more, check out a 4 minute clip on the subject <a href="http://www.youtube.com/watch?v=8W2fGkU5LYU">here</a></p>
<p>However, there is a problem with adjusted <span class="math inline">\(R^2\)</span> in that it no longer has a ready interpretation as it can take a value outside of 0 or 1 and no longer relates directly to the explained variation.</p>
</div>
</div>
<div id="more-covariates-of-mixed-types" class="section level3" number="14.6.10">
<h3><span class="header-section-number">14.6.10</span> More covariates of mixed types</h3>
<p>Let’s consider adding more covariates - mixing the types and return to the medical data. Specifically we’ll look at vitamin D levels as a function of <code>folate</code> and <code>TEON</code>.</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="introlm.html#cb359-1" aria-hidden="true" tabindex="-1"></a>prettierPlot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(meddata) <span class="sc">+</span> </span>
<span id="cb359-2"><a href="introlm.html#cb359-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(folate, vitdresul, <span class="at">colour =</span> agecat), <span class="at">size=</span><span class="dv">3</span>, <span class="at">alpha=</span><span class="fl">0.5</span>) <span class="sc">+</span> </span>
<span id="cb359-3"><a href="introlm.html#cb359-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>TEON)</span>
<span id="cb359-4"><a href="introlm.html#cb359-4" aria-hidden="true" tabindex="-1"></a>prettierPlot</span></code></pre></div>
<p><img src="IntroStats_files/figure-html/unnamed-chunk-191-1.png" width="480" style="display: block; margin: auto;" /></p>
<div id="model-specification-2" class="section level4" number="14.6.10.1">
<h4><span class="header-section-number">14.6.10.1</span> Model specification</h4>
<p>Fitting models in the <code>lm</code> function is straight-forward. We specify <span class="math inline">\(y\)</span> as a function of several <span class="math inline">\(x\)</span> - here <code>vitdresul</code> is a function of <code>TEON</code> (categorical) and <code>folate</code> (numeric).</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="introlm.html#cb360-1" aria-hidden="true" tabindex="-1"></a>multiReg_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(vitdresul <span class="sc">~</span> TEON <span class="sc">+</span> folate, <span class="at">data=</span>meddata)</span></code></pre></div>
<p>We request a summary, as for other <code>lm</code> objects:</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="introlm.html#cb361-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(multiReg_lm)</span></code></pre></div>
<pre><code>
Call:
lm(formula = vitdresul ~ TEON + folate, data = meddata)

Residuals:
     Min       1Q   Median       3Q      Max 
-10.2918  -3.4911  -0.5681   1.5921  20.0186 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 18.24054    1.33086  13.706  &lt; 2e-16 ***
TEONYes     -8.98669    1.42974  -6.286 4.88e-08 ***
folate       0.12042    0.09204   1.308    0.196    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 5.275 on 57 degrees of freedom
Multiple R-squared:  0.4152,    Adjusted R-squared:  0.3947 
F-statistic: 20.24 on 2 and 57 DF,  p-value: 2.288e-07</code></pre>
<p>95% CIs for the parameter estimates:</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="introlm.html#cb363-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(multiReg_lm)</span></code></pre></div>
<pre><code>                   2.5 %     97.5 %
(Intercept)  15.57553052 20.9055409
TEONYes     -11.84969934 -6.1236813
folate       -0.06387951  0.3047254</code></pre>
<p>From this output, we can say that:</p>
<ul>
<li>There is an estimated average difference of 8.99 units between the <code>TEON</code> yes and no groups.</li>
<li>For each unit increase of <code>folate</code> there is a 0.12 unit increase of <code>vitdresul</code>.</li>
<li>The TEON effect is statistically significant.</li>
<li>The relationship with <code>folate</code> is not significant.</li>
<li>The intercept mean is between 15.58 and 20.9 with 95% confidence.</li>
<li>The slope parameter (for <code>folate</code>) is between -0.064 and 0.305 units with 95% confidence (noting 0 is a plausible value here).</li>
</ul>
<p><strong>Q14.14</strong> Write down the two fitted equations of this model (i.e for TEON=No and TEON=Yes).</p>
<p><strong>Q14.15</strong> Assume that this is an appropriate model. What is the expected vitamin D level of a subject without TEON and with two units of folate?</p>
<p><strong>Q14.16</strong> What is the expected vitamin D level for a subject with TEON and 3 units of folate?</p>
</div>
</div>
</div>
<div id="the-matrix-interpretation-of-a-linear-model" class="section level2" number="14.7">
<h2><span class="header-section-number">14.7</span> The matrix interpretation of a linear model</h2>
<p>We have already encountered the matrix form for regression, which can be used to generate fitted values.</p>
<p><span class="math display">\[ \hat{\mathbf{y}} = \mathbf{X} \hat{\boldsymbol{\beta}} \]</span>
which in turn was</p>
<p><span class="math display">\[\hat{\mathbf{y}} = 
\left[\begin{array}
{r}
\hat{\beta_0}+\hat{\beta_1} X_1 \\
 \hat{\beta_0}+\hat{\beta_1} X_2 \\  
...\\
\hat{\beta_0}+\hat{\beta_1} X_n
\end{array}\right]
\]</span>
Additional covariates can readily be added to this frame work</p>
<p><span class="math display">\[
\hat{\mathbf{y}} =
\left[\begin{array}
{r}
\hat{\beta_0}+\hat{\beta_1} X_{1,1}+ \hat{\beta_2} X_{2,1}\\
 \hat{\beta_0}+\hat{\beta_1} X_{1,2} + \hat{\beta_2} X_{2,2}\\  
...\\
\hat{\beta_0}+\hat{\beta_1} X_{i,n}+ \hat{\beta_2} X_{2,n} 
\end{array}\right]
\]</span></p>
<p>N.B. The subscripts refer to the variable number first, followed by the row number. This can in turn be re-written as</p>
<p><span class="math display">\[\hat{\mathbf{y}} = 
\left[\begin{array}
{ccc}
1 &amp; X_{1,1} &amp;  X_{2,1}\\
 1 &amp; X_{1,2} &amp;  X_{2,2}\\  
...\\
1 &amp; X_{i,n} &amp; X_{2,n} 
\end{array}\right]
\left[\begin{array}
{r}
\hat{\beta_0}  \\
\hat{\beta_1}  \\
\hat{\beta_2}
\end{array}\right]
\]</span></p>
<p>The first matrix on the right hand side is called a <em>design matrix</em> and consists of a column of ones for the intercept and the continuous covariate values in the other columns.</p>
<div id="dummy-variables" class="section level3" number="14.7.1">
<h3><span class="header-section-number">14.7.1</span> Dummy variables</h3>
<p>We have already hinted at the form that the categorical variables must take.
We just need to augment the design matrix.
We create a binary matrix made up of zeros and ones. The 0/1 codings indicate which level of the factor variable (our categorical covariate) each observation belongs to. Each level therefore gets a parameter in the parameter vector.
So, say <span class="math inline">\(X\)</span> has 3 levels, with the first 9 values being A,A,A, B,B,B, C,C,C, we might encode the design matrix as:</p>
<p><span class="math display">\[
\left[\begin{array}
{ccc}
1 &amp; 0 &amp; 0\\
 1 &amp; 0 &amp;  0\\  
1 &amp; 0 &amp; 0\\ 
0 &amp; 1 &amp;  0\\
 0 &amp; 1 &amp;  0\\  
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp;  1\\
 0 &amp; 0 &amp;  1\\  
0 &amp; 0 &amp; 1
\end{array}\right]
\]</span></p>
<p>The default condition is zero, a “1” in the first column means level A, a “1” in the second column means level B and a “1” in the third column means level C.</p>
<p>So a simple one-way ANOVA would become</p>
<p><span class="math display">\[
\hat{\mathbf{y}} = 
\left[\begin{array}
{ccc}
1 &amp; 0 &amp; 0\\
 1 &amp; 0 &amp;  0\\  
1 &amp; 0 &amp; 0\\ 
0 &amp; 1 &amp;  0\\
 0 &amp; 1 &amp;  0\\  
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp;  1\\
 0 &amp; 0 &amp;  1\\  
0 &amp; 0 &amp; 1
\end{array}\right]
\left[\begin{array}
{r}
\hat{\beta_0}  \\
\hat{\beta_1}  \\
\hat{\beta_2}
\end{array}\right]
= 
\left[\begin{array}
{r}
\hat{\beta_0}  \\
\hat{\beta_0}  \\
\hat{\beta_0}  \\
\hat{\beta_1}  \\
 \hat{\beta_1} \\
 \hat{\beta_1} \\ \hat{\beta_2} \\
 \hat{\beta_2} \\
 \hat{\beta_2} 
\end{array}\right]
\]</span></p>
<p>However, in practice (especially when using the linear model) as we have seen we fit regression coefficients relative to a baseline, such that the other parameters are intercept modifiers. In this example, <span class="math inline">\(\hat{\beta_1}\)</span> +<span class="math inline">\(\hat{\beta_2}\)</span> are intercept modifiers.</p>
<p>So <span class="math inline">\(\hat{\beta_0}\)</span> might be the mean of the baseline factor (A) , <span class="math inline">\(\hat{\beta_1}\)</span> might be the mean difference between baseline and level 2 (B - A), <span class="math inline">\(\hat{\beta_2}\)</span> might be the mean difference between baseline and level 3 (C - A).</p>
</div>
<div id="combining-factors-and-continuous-variables" class="section level3" number="14.7.2">
<h3><span class="header-section-number">14.7.2</span> Combining factors and continuous variables</h3>
<p>A continuous variable combined with a factor variable (with 3 levels) then becomes:</p>
<p><span class="math display">\[
\hat{\mathbf{y}} = 
\left[\begin{array}
{cccc}
1 &amp; 0 &amp; 0 &amp; x_{2,2}\\ 
1 &amp; 0 &amp; 0 &amp; x_{2,1}\\
1 &amp; 0 &amp; 0 &amp; x_{2,1}\\
1 &amp; 0 &amp; 0 &amp; x_{2,2}\\  
1 &amp; 0 &amp; 0 &amp; x_{2,3}\\ 
1 &amp; 1 &amp; 0 &amp; x_{2,4}\\
1 &amp; 1 &amp; 0 &amp; x_{2,5}\\  
1 &amp; 1 &amp; 0 &amp; x_{2,6}\\
1 &amp; 0 &amp; 1 &amp; x_{2,7}\\
1 &amp; 0 &amp; 1 &amp; x_{2,8}\\  
1 &amp; 0 &amp; 1 &amp; x_{2,9}
\end{array}\right]
\left[\begin{array}
{r}
\hat{\beta_0}  \\
\hat{\beta_1}  \\
\hat{\beta_2} \\
\hat{\beta_3}
\end{array}\right]=
\left[\begin{array}
{c}
\hat{\beta_0} +     \hat{\beta_3} x_{2,1}\\
\hat{\beta_0} +   \hat{\beta_3} x_{2,2}\\
\hat{\beta_0} + \hat{\beta_3} x_{2,3}\\
\hat{\beta_0} + \hat{\beta_1}  + \hat{\beta_3} x_{2,4}\\
\hat{\beta_0} + \hat{\beta_1}  + \hat{\beta_3} x_{2,5}\\
\hat{\beta_0} + \hat{\beta_1}  + \hat{\beta_3} x_{2,6}\\
\hat{\beta_0} + \hat{\beta_2}  + \hat{\beta_3} x_{2,7}\\
\hat{\beta_0} + \hat{\beta_2}  + \hat{\beta_3} x_{2,8}\\
\hat{\beta_0} + \hat{\beta_2}  + \hat{\beta_3} x_{2,9} 
\end{array}\right]
\]</span></p>
<p>With an appropriate fitting object, we now estimate a straight line relationship between <span class="math inline">\(x_2\)</span> and some adjustment for each factor level of <span class="math inline">\(x_2\)</span> just as we did in the cases above.</p>
<p>Here is a linear model equivalent to the above using some randomly generated data:</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="introlm.html#cb365-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">101</span>)</span>
<span id="cb365-2"><a href="introlm.html#cb365-2" aria-hidden="true" tabindex="-1"></a>X1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;A&quot;</span>,<span class="st">&quot;A&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>,<span class="st">&quot;B&quot;</span>,<span class="st">&quot;B&quot;</span>,<span class="st">&quot;C&quot;</span>,<span class="st">&quot;C&quot;</span>,<span class="st">&quot;C&quot;</span>)</span>
<span id="cb365-3"><a href="introlm.html#cb365-3" aria-hidden="true" tabindex="-1"></a>X2 <span class="ot">&lt;-</span> <span class="fu">rpois</span> (<span class="dv">9</span>,<span class="dv">7</span>) </span>
<span id="cb365-4"><a href="introlm.html#cb365-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">3</span><span class="sc">*</span>X2 <span class="sc">+</span> <span class="fu">rnorm</span> (<span class="dv">9</span>)</span>
<span id="cb365-5"><a href="introlm.html#cb365-5" aria-hidden="true" tabindex="-1"></a><span class="do">### The baseline level A is on average 1 unit higher than levels B &amp; C</span></span>
<span id="cb365-6"><a href="introlm.html#cb365-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">ifelse</span> (X1<span class="sc">==</span><span class="st">&quot;A&quot;</span>, y<span class="sc">+</span><span class="dv">1</span>, y) </span>
<span id="cb365-7"><a href="introlm.html#cb365-7" aria-hidden="true" tabindex="-1"></a>df1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span> (y, X1, X2)</span>
<span id="cb365-8"><a href="introlm.html#cb365-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span> (df1)</span></code></pre></div>
<pre><code>         y X1 X2
1 19.11513  A  6
2 10.54428  A  3
3 26.48807  A  8
4 24.22837  B  8
5 14.24164  B  5
6 13.23296  B  5
7 22.71511  C  7
8 18.41536  C  6
9 24.82643  C  8</code></pre>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="introlm.html#cb367-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model </span></span>
<span id="cb367-2"><a href="introlm.html#cb367-2" aria-hidden="true" tabindex="-1"></a>modeldemo <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> X1<span class="sc">+</span>X2, <span class="at">data=</span>df1)</span>
<span id="cb367-3"><a href="introlm.html#cb367-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb367-4"><a href="introlm.html#cb367-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract coefficients</span></span>
<span id="cb367-5"><a href="introlm.html#cb367-5" aria-hidden="true" tabindex="-1"></a>coeffs <span class="ot">&lt;-</span> <span class="fu">coefficients</span> (modeldemo)</span>
<span id="cb367-6"><a href="introlm.html#cb367-6" aria-hidden="true" tabindex="-1"></a>coeffs</span></code></pre></div>
<pre><code>(Intercept)         X1B         X1C          X2 
  0.2208288  -2.5694457  -1.0819577   3.2638232 </code></pre>
<p>We need to make the design matrix.</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="introlm.html#cb369-1" aria-hidden="true" tabindex="-1"></a>design.matrix <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">matrix</span> (<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>),</span>
<span id="cb369-2"><a href="introlm.html#cb369-2" aria-hidden="true" tabindex="-1"></a>                               <span class="at">nrow=</span><span class="dv">9</span>, <span class="at">ncol=</span><span class="dv">3</span>, <span class="at">byrow=</span><span class="cn">TRUE</span>), X2)</span>
<span id="cb369-3"><a href="introlm.html#cb369-3" aria-hidden="true" tabindex="-1"></a>design.matrix</span></code></pre></div>
<pre><code>            X2
 [1,] 1 0 0  6
 [2,] 1 0 0  3
 [3,] 1 0 0  8
 [4,] 1 1 0  8
 [5,] 1 1 0  5
 [6,] 1 1 0  5
 [7,] 1 0 1  7
 [8,] 1 0 1  6
 [9,] 1 0 1  8</code></pre>
<p>The design matrix multiplied with the coefficients gives the fitted values. Compare the calculated ones below, with the ‘official’ fitted values.</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="introlm.html#cb371-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span> (design.matrix)</span></code></pre></div>
<pre><code>[1] 9 4</code></pre>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="introlm.html#cb373-1" aria-hidden="true" tabindex="-1"></a>ourfitted <span class="ot">&lt;-</span> design.matrix<span class="sc">%*%</span>coeffs <span class="co"># matrix multiplication</span></span>
<span id="cb373-2"><a href="introlm.html#cb373-2" aria-hidden="true" tabindex="-1"></a>ourfitted</span></code></pre></div>
<pre><code>          [,1]
 [1,] 19.80377
 [2,] 10.01230
 [3,] 26.33141
 [4,] 23.76197
 [5,] 13.97050
 [6,] 13.97050
 [7,] 21.98563
 [8,] 18.72181
 [9,] 25.24946</code></pre>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="introlm.html#cb375-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitted values from model object</span></span>
<span id="cb375-2"><a href="introlm.html#cb375-2" aria-hidden="true" tabindex="-1"></a><span class="fu">fitted</span> (modeldemo)</span></code></pre></div>
<pre><code>       1        2        3        4        5        6        7        8        9 
19.80377 10.01230 26.33141 23.76197 13.97050 13.97050 21.98563 18.72181 25.24946 </code></pre>
<p>N.B. The model matrix can be extracted from the model object by the <code>model.matrix</code> command.</p>
</div>
</div>
<div id="SUMlm" class="section level2" number="14.8">
<h2><span class="header-section-number">14.8</span> Summary</h2>
<p>The linear model is a very powerful tool. It is a method to explain the variation in a continuous variable in terms of other variables.</p>
<p>The linear model can fit</p>
<ul>
<li>simple and multiple linear regression,</li>
<li>comparison of two means and</li>
<li>one way analysis of variance.</li>
</ul>
<p>The linear model can be extended to include multiple explanatory variables:</p>
<ul>
<li>these can be continuous or (categorical) factors (implemented using dummy variables) or both.</li>
<li>Interpreting coefficients for factor variables requires care - they are <em>average differences from some baseline level</em></li>
</ul>
<p>Goodness of fit of a fitted model can be measured as the proportion of variation explained and its predicted power…but by itself there may be a flaw in using this solely as the index of model quality (see further chapters).</p>
<p>The linear model is a useful tool for exploring variation in univariate data (that is, a single vector of dependent data) potentially influenced by other variables and can be extended in lots of ways. However, with great power comes great responsibility and it is important to make sure linear models are used appropriately. We have not yet considered the assumptions of linear models, nor uncertainty in the predictions, nor what to do when explanatory variables are correlated (which can cause problems in interpretation). These issues are covered in following chapters.
<!-- LB - update - 12/01/2022 --></p>
<div id="learning-objectives-2" class="section level3" number="14.8.1">
<h3><span class="header-section-number">14.8.1</span> Learning objectives</h3>
<p>Having worked through this chapter, you should now understand</p>
<ol style="list-style-type: decimal">
<li>the linear model as a generalisation of other parametric models,</li>
<li>how to combine factor and continuous variables into the same analysis,</li>
<li><span class="math inline">\(R^2\)</span> as a measure of goodness of fit,</li>
<li>the matrix interpretation of a linear model, and</li>
<li>the distinction between sequential and adjusted sums of squares.</li>
</ol>
</div>
</div>
<div id="ANSlm" class="section level2" number="14.9">
<h2><span class="header-section-number">14.9</span> Answers</h2>
<p><strong>Q14.1</strong> The response variable is <code>vitdresul</code>, i.e. the vitamin D level.</p>
<p><strong>Q14.2</strong> The predictor, or explanatory, variable is <code>TEON</code>, the presence or absence of the TEON condition.</p>
<p><strong>Q14.3</strong> The latter two analyses assume that the variable <code>TEON</code> explains vitamin D levels. However, it seems more likely that vitamin D levels would explain TEON condition (indeed, that is what we assumed previously). Under these circumstances, TEON should be the response variable and vitamin D level, the explanatory variable. TEON consists of 0 and 1 values (to represent presence/absence of the TEON condition), hence, we would like a form of regression that allowed for binary outcomes (i.e. only two possibilities) to be the response variable: such regression is possible but beyond the remit of this module.</p>
<p><strong>Q14.4</strong>The linear model assumes a common error variation for all levels of the explanatory factor variable and, in fact, for all levels of continuous variables as well (if there were any). We will explore this later.</p>
<p><strong>Q14.5</strong> <span class="math inline">\(VitD =\beta_0+\beta_1+TEON +\epsilon\)</span>
where</p>
<ul>
<li><span class="math inline">\(VitD\)</span> is the dependent variable (response),</li>
<li>TEON is the categorical predictor,</li>
<li><span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are the fitted means for the different TEON levels (and the mean and slope respectively) and</li>
<li><span class="math inline">\(\epsilon\)</span> is the error term.</li>
</ul>
<p><strong>Q14.6</strong> The columns in the table are:
Estimate - estimated regression coefficients for each term in the model.<br />
Std. Error - estimated standard errors for each term in the model<br />
t value - <span class="math inline">\(t\)</span> test statistics for each term, t value = Estimate/Std. Error<br />
Pr(&gt;|t|) - Probability associated with the <span class="math inline">\(t\)</span> test statistics for each term in the model.</p>
<p><strong>Q14.7</strong> They are a visual indication an interval level of significance associated with the t-tests for each term in the model. The intervals are:</p>
<p><code>***</code> 0 - 0.001
<code>**</code> 0.001 - 0.01
`<code>*0.01 - 0.05</code>.` 0.05 - 0.1
Blank 0.1 - 1.0
In this example, the <span class="math inline">\(p\)</span>-values for both the intercept and slope are small (between 0 and 0.001) and so there are three asterisks.</p>
<p><strong>Q14.8</strong> TEON = No: = 19.5862; TEON = Yes: 19.5862-8.889 = 10.6972.</p>
<p><strong>Q14.9</strong> TEON = Yes, therefore estimated VitD is 19.5862 - 8.8890
= 10.6972 units.</p>
<p><strong>Q14.10</strong> The degrees of freedom of the residuals are given by <span class="math inline">\(n - P - 1 = 58\)</span>, where <span class="math inline">\(n\)</span> = number of observations, <span class="math inline">\(P\)</span> = number of coefficients in the model (excluding the intercept). Therefore, <span class="math inline">\(n = 58 + P + 1\)</span>. In this model, there is only one explanatory variable and so <span class="math inline">\(P = 1\)</span>, hence <span class="math inline">\(n = 60\)</span>.</p>
<p><strong>Q14.11</strong> The confidence interval for the TEON=Yes parameter is given by:</p>
<p><span class="math display">\[\beta_1 \pm \alpha_0.025 \times s.e.\]</span><br />
<span class="math display">\[ -8.889 \pm  2.001717 \times 1.4365\]</span>
<span class="math display">\[ -8.889 \pm 2.875467\]</span>
(-11.7645,-6.0135)</p>
<p><strong>Q14.13</strong> There are several options:</p>
<p>We need to obtain the probability associated with values less than -6.188 (i.e. left hand tail of the distribution) and values greater than 6.188 (i.e. right hand tail).<br />
<code>pt(q=-6.188, df=58) +  pt(q=6.188, df=58, lower.tail=FALSE)</code><br />
Alternatively, the area in each tail could just be multiplied by two because the t-distribution is symmetric.<br />
<code>2*pt(q=-6.188, df=58)</code> or <code>2*pt(q=6.188, df=58, lower.tail=FALSE</code></p>
<p><strong>Q14.14</strong> The fitted equations are:
TEON = No: <span class="math display">\[-18.24054 + 0.12042.\textrm{TEON}\]</span><br />
TEON = Yes: <span class="math display">\[-18.24054 -8.98669 + 0.12042.\textrm{TEON}  = 
- 9.25385 + 0.12042.\textrm{TEON} \]</span></p>
<p><strong>Q14.15</strong> TEON = No and folate = 2, therefore, estimated VitD = 18.24054 + 0.12042 = 18.48 units</p>
<p><strong>Q14.16</strong> TEON = 1 and folate = 3, therefore, estimated VitD = 9.25385 + 0.12042*3 = 9.62 units</p>
<!-- # Bibliography -->

<!-- LB - update - 12/01/2022 -->
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Eden&amp;Fisher1927" class="csl-entry">
Eden, T., and R. A. Fisher. 1927. <span>“Studies in Crop Variation: <span>IV</span>. <span>T</span>he Experimental Determination of the Value of Top Dressings with Cereals.”</span> <em>Journal of Agricultural Science</em> 17: 548–62.
</div>
<div id="ref-R-tidyr" class="csl-entry">
Wickham, Hadley. 2021. <em>Tidyr: Tidy Messy Data</em>. <a href="https://CRAN.R-project.org/package=tidyr">https://CRAN.R-project.org/package=tidyr</a>.
</div>
<div id="ref-R-dplyr" class="csl-entry">
Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2021. <em>Dplyr: A Grammar of Data Manipulation</em>. <a href="https://CRAN.R-project.org/package=dplyr">https://CRAN.R-project.org/package=dplyr</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="correg.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modelselection.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["IntroStats.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
